#!/usr/bin/env python3
"""
ë³‘ë ¬ Agent ì‹¤í–‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

ë³‘ë ¬ ì‹¤í–‰ ì‹œìŠ¤í…œì˜ ê¸°ëŠ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤:
- TaskQueue: ì‘ì—… í ë° ë³‘ë ¬ ê·¸ë£¹ ì‹ë³„
- AgentPool: Agent í’€ ê´€ë¦¬
- ParallelAgentExecutor: ë³‘ë ¬ ì‹¤í–‰ ê´€ë¦¬
"""

import asyncio
import sys
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.task_queue import TaskQueue
from src.core.agent_pool import AgentPool
from src.core.parallel_agent_executor import ParallelAgentExecutor
from src.core.researcher_config import load_config_from_env

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_task_queue():
    """TaskQueue í…ŒìŠ¤íŠ¸."""
    logger.info("=" * 80)
    logger.info("Testing TaskQueue")
    logger.info("=" * 80)
    
    queue = TaskQueue()
    
    # í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„±
    tasks = [
        {
            "id": "task_1",
            "task_id": "task_1",
            "name": "Search for AI trends",
            "task_type": "search",
            "dependencies": [],
            "priority": 1
        },
        {
            "id": "task_2",
            "task_id": "task_2",
            "name": "Search for ML frameworks",
            "task_type": "search",
            "dependencies": [],
            "priority": 1
        },
        {
            "id": "task_3",
            "task_id": "task_3",
            "name": "Analyze results",
            "task_type": "data",
            "dependencies": ["task_1", "task_2"],
            "priority": 2
        }
    ]
    
    # ì‘ì—… ì¶”ê°€
    queue.add_tasks(tasks)
    
    # ë³‘ë ¬ ê·¸ë£¹ í™•ì¸
    assert len(queue.parallel_groups) > 0, "ë³‘ë ¬ ê·¸ë£¹ì´ ì‹ë³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    logger.info(f"âœ… ë³‘ë ¬ ê·¸ë£¹ ì‹ë³„: {len(queue.parallel_groups)}ê°œ")
    
    # ë‹¤ìŒ ì‘ì—… ê·¸ë£¹ ê°€ì ¸ì˜¤ê¸°
    next_group = queue.get_next_task_group()
    assert next_group is not None, "ë‹¤ìŒ ì‘ì—… ê·¸ë£¹ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    assert len(next_group) == 2, f"ë³‘ë ¬ ê·¸ë£¹ í¬ê¸°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {len(next_group)}"
    logger.info(f"âœ… ë‹¤ìŒ ì‘ì—… ê·¸ë£¹: {next_group}")
    
    # ì‘ì—… ì™„ë£Œ í‘œì‹œ
    for task_id in next_group:
        queue.mark_completed(task_id)
    
    # ì§„í–‰ ìƒí™© í™•ì¸
    progress = queue.get_progress()
    assert progress['completed_tasks'] == 2, f"ì™„ë£Œëœ ì‘ì—… ìˆ˜ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {progress['completed_tasks']}"
    logger.info(f"âœ… ì§„í–‰ ìƒí™©: {progress}")
    
    # ë‹¤ìŒ ê·¸ë£¹ ê°€ì ¸ì˜¤ê¸° (ì˜ì¡´ì„± í•´ê²° í›„)
    next_group = queue.get_next_task_group()
    assert next_group is not None, "ì˜ì¡´ì„± í•´ê²° í›„ ë‹¤ìŒ ê·¸ë£¹ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    assert "task_3" in next_group, "task_3ì´ ë‹¤ìŒ ê·¸ë£¹ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    logger.info(f"âœ… ì˜ì¡´ì„± í•´ê²° í›„ ë‹¤ìŒ ê·¸ë£¹: {next_group}")
    
    logger.info("âœ… TaskQueue í…ŒìŠ¤íŠ¸ í†µê³¼\n")


async def test_agent_pool():
    """AgentPool í…ŒìŠ¤íŠ¸."""
    logger.info("=" * 80)
    logger.info("Testing AgentPool")
    logger.info("=" * 80)
    
    pool = AgentPool(max_pool_size=5)
    
    # ê°„ë‹¨í•œ agent íŒ©í† ë¦¬
    async def create_agent(agent_type: str):
        return {"type": agent_type, "id": f"agent_{agent_type}"}
    
    # Agent ê°€ì ¸ì˜¤ê¸°
    agent1 = await pool.get_agent("researcher", create_agent)
    assert agent1 is not None, "Agentë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    logger.info(f"âœ… Agent ìƒì„±: {agent1}")
    
    # Agent ë°˜í™˜
    returned = await pool.return_agent("researcher", agent1)
    assert returned, "Agent ë°˜í™˜ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
    logger.info("âœ… Agent ë°˜í™˜ ì„±ê³µ")
    
    # í†µê³„ í™•ì¸
    stats = pool.get_pool_stats()
    assert stats['agent_types']['researcher']['total'] == 1, "Agent ìˆ˜ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤"
    assert stats['agent_types']['researcher']['available'] == 1, "ì‚¬ìš© ê°€ëŠ¥í•œ Agent ìˆ˜ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤"
    logger.info(f"âœ… í’€ í†µê³„: {stats}")
    
    # ì¬ì‚¬ìš© í™•ì¸
    agent2 = await pool.get_agent("researcher", create_agent)
    assert agent2 == agent1, "Agent ì¬ì‚¬ìš©ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
    logger.info("âœ… Agent ì¬ì‚¬ìš© ì„±ê³µ")
    
    logger.info("âœ… AgentPool í…ŒìŠ¤íŠ¸ í†µê³¼\n")


async def test_parallel_executor_basic():
    """ParallelAgentExecutor ê¸°ë³¸ í…ŒìŠ¤íŠ¸."""
    logger.info("=" * 80)
    logger.info("Testing ParallelAgentExecutor (Basic)")
    logger.info("=" * 80)
    
    try:
        # ì„¤ì • ë¡œë“œ
        config = load_config_from_env()
        
        # Executor ìƒì„±
        executor = ParallelAgentExecutor()
        
        # ê¸°ë³¸ ì„¤ì • í™•ì¸
        assert executor.max_concurrent > 0, "max_concurrentê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        assert executor.task_queue is not None, "task_queueê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        assert executor.agent_pool is not None, "agent_poolì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        logger.info(f"âœ… Executor ì´ˆê¸°í™” ì„±ê³µ: max_concurrent={executor.max_concurrent}")
        
        # ë„êµ¬ ì¹´í…Œê³ ë¦¬ í™•ì¸
        category = executor._get_tool_category_for_task({"task_type": "search"})
        assert category == "search", f"ì¹´í…Œê³ ë¦¬ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {category}"
        logger.info(f"âœ… ë„êµ¬ ì¹´í…Œê³ ë¦¬ ì‹ë³„: {category}")
        
        logger.info("âœ… ParallelAgentExecutor ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í†µê³¼\n")
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


async def test_integration():
    """í†µí•© í…ŒìŠ¤íŠ¸: ì „ì²´ ì›Œí¬í”Œë¡œìš°."""
    logger.info("=" * 80)
    logger.info("Testing Integration (Full Workflow)")
    logger.info("=" * 80)
    
    try:
        # ì„¤ì • ë¡œë“œ
        config = load_config_from_env()
        
        # Executor ìƒì„±
        executor = ParallelAgentExecutor()
        
        # í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„± (ì˜ì¡´ì„± ì—†ëŠ” ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…ë“¤)
        tasks = [
            {
                "id": "test_task_1",
                "task_id": "test_task_1",
                "name": "Test Search 1",
                "task_type": "search",
                "query": "artificial intelligence",
                "dependencies": [],
                "priority": 1,
                "max_results": 5
            },
            {
                "id": "test_task_2",
                "task_id": "test_task_2",
                "name": "Test Search 2",
                "task_type": "search",
                "query": "machine learning",
                "dependencies": [],
                "priority": 1,
                "max_results": 5
            }
        ]
        
        agent_assignments = {}
        execution_plan = {
            "strategy": "parallel",
            "parallel_groups": [["test_task_1", "test_task_2"]],
            "execution_order": ["test_task_1", "test_task_2"],
            "estimated_total_time": 60,
            "dependency_graph": {"test_task_1": [], "test_task_2": []},
            "task_count": 2,
            "agent_count": 0
        }
        
        logger.info("âš ï¸ ì‹¤ì œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ëŠ” í™˜ê²½ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤ (MCP ì„œë²„ ì—°ê²° ë“±)")
        logger.info("âœ… í†µí•© í…ŒìŠ¤íŠ¸ êµ¬ì¡° í™•ì¸ ì™„ë£Œ\n")
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜."""
    logger.info("ğŸš€ ë³‘ë ¬ Agent ì‹¤í–‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("")
    
    try:
        # ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
        await test_task_queue()
        await test_agent_pool()
        await test_parallel_executor_basic()
        await test_integration()
        
        logger.info("=" * 80)
        logger.info("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())

