#!/usr/bin/env python3
"""
ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ì‹¤í–‰ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent))

from benchmark_runner import BenchmarkRunner

def test_benchmark_runner_init():
    """BenchmarkRunner ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ” Benchmark Runner ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    try:
        config_path = project_root / "tests" / "benchmark" / "benchmark_config.yaml"
        thresholds_path = project_root / "benchmark" / "benchmark_thresholds.yaml"
        
        if not thresholds_path.exists():
            thresholds_path = project_root / "tests" / "benchmark" / "benchmark_thresholds.yaml"
        
        runner = BenchmarkRunner(
            str(project_root),
            str(config_path),
            str(thresholds_path)
        )
        
        print("âœ… BenchmarkRunner ì´ˆê¸°í™” ì„±ê³µ")
        print(f"   Config íŒŒì¼: {config_path}")
        print(f"   Thresholds íŒŒì¼: {thresholds_path}")
        print()
        
        # Config í™•ì¸
        agent_tasks = runner.config.get('agent_tasks', [])
        print(f"ğŸ“‹ Agent Tasks: {len(agent_tasks)}ê°œ")
        for task in agent_tasks[:3]:  # ì²˜ìŒ 3ê°œë§Œ
            print(f"   - {task.get('id')}: {task.get('category')} - {task.get('query')[:50]}...")
        print()
        
        # CLI Executor í™•ì¸
        print("ğŸ”§ CLI Executor í™•ì¸:")
        env_valid, issues = runner.cli_executor.validate_environment()
        if env_valid:
            print("   âœ… í™˜ê²½ ê²€ì¦ í†µê³¼")
        else:
            print(f"   âŒ í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨: {issues}")
        print()
        
        return runner
        
    except Exception as e:
        print(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_single_task_execution(runner):
    """ë‹¨ì¼ íƒœìŠ¤í¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸš€ ë‹¨ì¼ íƒœìŠ¤í¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    if not runner:
        print("âŒ Runnerê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    agent_tasks = runner.config.get('agent_tasks', [])
    if not agent_tasks:
        print("âŒ Agent tasksê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # ì²« ë²ˆì§¸ íƒœìŠ¤í¬ë§Œ í…ŒìŠ¤íŠ¸
    test_task = agent_tasks[0]
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ íƒœìŠ¤í¬: {test_task.get('id')}")
    print(f"   Category: {test_task.get('category')}")
    print(f"   Query: {test_task.get('query')}")
    print()
    
    try:
        print("â³ ì‹¤í–‰ ì¤‘...")
        result = runner._run_single_agent_task_comprehensive(test_task)
        
        print(f"âœ… ì‹¤í–‰ ì™„ë£Œ")
        print(f"   Test ID: {result.test_id}")
        print(f"   Category: {result.category}")
        print(f"   Execution Time: {result.execution_time:.2f}s")
        print(f"   Overall Score: {result.overall_score:.2%}")
        print(f"   Passed: {result.passed}")
        print(f"   Metrics: {len(result.metrics)}ê°œ")
        
        if result.metrics:
            print()
            print("ğŸ“Š ë©”íŠ¸ë¦­:")
            for metric in result.metrics[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                print(f"   - {metric.name}: {metric.value:.2%} (threshold: {metric.threshold:.2%}, passed: {metric.passed})")
        
        return result
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_score_calculation(runner):
    """ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    print()
    print("=" * 80)
    print("ğŸ“Š ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print()
    
    if not runner:
        return
    
    agent_tasks = runner.config.get('agent_tasks', [])
    
    category_scores = {}
    category_counts = {}
    
    for task in agent_tasks:
        category = task.get('category', 'Unknown')
        
        try:
            result = runner._run_single_agent_task_comprehensive(task)
            
            if category not in category_scores:
                category_scores[category] = []
                category_counts[category] = 0
            
            category_scores[category].append(result.overall_score)
            category_counts[category] += 1
            
            print(f"âœ… {task.get('id')}: {result.overall_score:.2%}")
            
        except Exception as e:
            print(f"âŒ {task.get('id')}: ì‹¤íŒ¨ - {e}")
    
    print()
    print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì ìˆ˜:")
    category_mapping = {
        'WebNavigation': 'Web Navigation',
        'ToolUsage': 'Tool Usage',
        'MultiAgent': 'Multi-Agent',
        'Reasoning': 'Reasoning'
    }
    
    for category, scores in category_scores.items():
        if scores:
            avg = sum(scores) / len(scores)
            name = category_mapping.get(category, category)
            print(f"   {name}: {avg:.2%} ({len(scores)}ê°œ í…ŒìŠ¤íŠ¸)")
    
    # Overall ê³„ì‚°
    all_scores = []
    for scores in category_scores.values():
        all_scores.extend(scores)
    
    if all_scores:
        overall = sum(all_scores) / len(all_scores)
        print()
        print(f"ğŸ“Š Overall Score: {overall:.2%}")
        
        return {
            'Web Navigation': category_scores.get('WebNavigation', [0])[0] * 100 if category_scores.get('WebNavigation') else 0,
            'Tool Usage': category_scores.get('ToolUsage', [0])[0] * 100 if category_scores.get('ToolUsage') else 0,
            'Multi-Agent': category_scores.get('MultiAgent', [0])[0] * 100 if category_scores.get('MultiAgent') else 0,
            'Reasoning': category_scores.get('Reasoning', [0])[0] * 100 if category_scores.get('Reasoning') else 0,
            'Overall': overall * 100
        }
    
    return None


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸ§ª ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ë° ì¸¡ì • ë°©ë²• ì ê²€")
    print("=" * 80)
    print()
    
    # 1. ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    runner = test_benchmark_runner_init()
    
    if not runner:
        print("âŒ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
        return
    
    # 2. ë‹¨ì¼ íƒœìŠ¤í¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    test_single_task_execution(runner)
    
    print()
    print("=" * 80)
    print("ğŸ’¡ ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰í•˜ë ¤ë©´:")
    print("   python tests/benchmark/run_benchmarks.py")
    print("=" * 80)


if __name__ == "__main__":
    main()

