#!/usr/bin/env python3
"""
AgentBench ì ìˆ˜ ê³„ì‚° - ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì¶”ì¶œ
"""

import sys
import json
from pathlib import Path
from typing import Dict, List
from collections import defaultdict

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent))

def calculate_category_scores_from_results(results: List) -> Dict[str, float]:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ê³„ì‚°"""
    category_scores = defaultdict(list)
    
    category_mapping = {
        'WebNavigation': 'Web Navigation',
        'ToolUsage': 'Tool Usage',
        'MultiAgent': 'Multi-Agent',
        'Reasoning': 'Reasoning'
    }
    
    for result in results:
        category = result.category if hasattr(result, 'category') else result.get('category', '')
        score = result.overall_score if hasattr(result, 'overall_score') else result.get('overall_score', 0.0)
        
        if category in category_mapping:
            category_scores[category].append(score)
    
    # í‰ê·  ê³„ì‚°
    agentbench_scores = {}
    for category, scores in category_scores.items():
        if scores:
            avg = sum(scores) / len(scores)
            agentbench_scores[category_mapping[category]] = avg * 100
    
    # Overall ê³„ì‚°
    if agentbench_scores:
        overall = sum(agentbench_scores.values()) / len(agentbench_scores)
        agentbench_scores['Overall'] = overall
    
    return agentbench_scores


def load_benchmark_results(results_dir: str = "results") -> Dict[str, float]:
    """ì €ì¥ëœ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¡œë“œ"""
    results_path = project_root / results_dir
    
    # JSON ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
    json_files = list(results_path.glob("benchmark_results_*.json"))
    
    if json_files:
        latest = max(json_files, key=lambda p: p.stat().st_mtime)
        print(f"ğŸ“Š Loading from: {latest}")
        
        with open(latest, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ê²°ê³¼ì—ì„œ ì ìˆ˜ ê³„ì‚°
        results = data.get('results', [])
        return calculate_category_scores_from_results(results)
    
    return {}


def main():
    """AgentBench ì ìˆ˜ í™•ì¸"""
    print("=" * 80)
    print("ğŸ“Š AgentBench Score Analysis")
    print("=" * 80)
    print()
    
    # READMEì˜ í˜„ì¬ ê°’
    readme_scores = {
        "Web Navigation": 58.0,
        "Tool Usage": 59.0,
        "Multi-Agent": 59.5,
        "Reasoning": 56.8,
        "Overall": 58.3
    }
    
    print("ğŸ“‹ README Current Values:")
    for cat, score in readme_scores.items():
        print(f"  {cat}: {score}%")
    print()
    
    # ì‹¤ì œ ì¸¡ì • ê²°ê³¼ í™•ì¸
    actual_scores = load_benchmark_results()
    
    if actual_scores:
        print("ğŸ“Š Actual Measurement Results:")
        for cat, score in actual_scores.items():
            print(f"  {cat}: {score:.1f}%")
        print()
        
        print("ğŸ“ˆ Comparison:")
        for cat in readme_scores.keys():
            readme_val = readme_scores.get(cat, 0)
            actual_val = actual_scores.get(cat, 0)
            
            if actual_val > 0:
                diff = actual_val - readme_val
                status = "âœ…" if diff >= 0 else "âš ï¸"
                print(f"  {status} {cat}: {readme_val}% â†’ {actual_val:.1f}% ({diff:+.1f}%)")
    else:
        print("âš ï¸  No benchmark results found")
        print()
        print("ğŸ’¡ READMEì˜ ê°’ë“¤(58.0%, 59.0%, 59.5%, 56.8%, 58.3%)ì€:")
        print("   - ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ê²°ê³¼ê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        print("   - ì‹¤ì œ ì¸¡ì •ì„ í†µí•´ ì—…ë°ì´íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        print()
        print("ì‹¤ì œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰:")
        print("  python tests/benchmark/run_benchmarks.py")
    
    print()
    print("=" * 80)


if __name__ == "__main__":
    main()

