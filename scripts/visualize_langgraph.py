#!/usr/bin/env python3
"""
LangGraph ì›Œí¬í”Œë¡œìš° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸

AutonomousOrchestratorì˜ LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
"""

import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Set environment variables for minimal config
# Note: OPENROUTER_API_KEY must be set via environment variable
if not os.getenv("OPENROUTER_API_KEY"):
    raise ValueError("OPENROUTER_API_KEY environment variable is required")
os.environ.setdefault("LLM_MODEL", "google/gemini-2.5-flash-lite")
os.environ.setdefault("LLM_TEMPERATURE", "0.7")
os.environ.setdefault("LLM_MAX_TOKENS", "4000")
# Note: GOOGLE_API_KEY must be set via environment variable
if not os.getenv("GOOGLE_API_KEY"):
    raise ValueError("GOOGLE_API_KEY environment variable is required")
os.environ.setdefault("PLANNING_MODEL", "google/gemini-2.5-flash-lite")
os.environ.setdefault("REASONING_MODEL", "google/gemini-2.5-flash-lite")
os.environ.setdefault("VERIFICATION_MODEL", "google/gemini-2.5-flash-lite")
os.environ.setdefault("GENERATION_MODEL", "google/gemini-2.5-flash-lite")
os.environ.setdefault("COMPRESSION_MODEL", "google/gemini-2.5-flash-lite")
os.environ.setdefault("BUDGET_LIMIT", "10.0")
os.environ.setdefault("ENABLE_COST_OPTIMIZATION", "true")
os.environ.setdefault("MAX_RESEARCHERS", "3")
os.environ.setdefault("MIN_RESEARCHERS", "1")
os.environ.setdefault("ENABLE_ADAPTIVE_ALLOCATION", "true")
os.environ.setdefault("COMPLEXITY_THRESHOLD_HIGH", "7.0")
os.environ.setdefault("COMPLEXITY_THRESHOLD_MEDIUM", "4.0")
os.environ.setdefault("ENABLE_DYNAMIC_PRIORITY", "true")
os.environ.setdefault("MAX_PARALLEL_TASKS", "5")
os.environ.setdefault("MAX_SEARCH_DEPTH", "3")
os.environ.setdefault("MAX_SEARCH_RESULTS", "10")
os.environ.setdefault("ENABLE_DEEP_RESEARCH", "true")
os.environ.setdefault("RESEARCH_TIMEOUT", "300")
os.environ.setdefault("MCP_SERVERS", "")
os.environ.setdefault("MCP_ACADEMIC_TOOLS", "")
os.environ.setdefault("MCP_SEARCH_TOOLS", "")
os.environ.setdefault("MCP_DATA_TOOLS", "")
os.environ.setdefault("MCP_CODE_TOOLS", "")
os.environ.setdefault("MCP_BUSINESS_TOOLS", "")
os.environ.setdefault("MCP_BUILDER_ENABLED", "true")
os.environ.setdefault("MCP_BUILDER_TEMP_DIR", "temp/mcp_servers")
os.environ.setdefault("MCP_BUILDER_AUTO_CLEANUP", "true")
os.environ.setdefault("MCP_BUILDER_CACHE_ENABLED", "true")
os.environ.setdefault("ENABLE_HIERARCHICAL_COMPRESSION", "true")
os.environ.setdefault("COMPRESSION_LEVELS", "3")
os.environ.setdefault("PRESERVE_IMPORTANT_INFO", "true")
os.environ.setdefault("ENABLE_COMPRESSION_VALIDATION", "true")
os.environ.setdefault("COMPRESSION_HISTORY_ENABLED", "true")
os.environ.setdefault("MIN_COMPRESSION_RATIO", "0.3")
os.environ.setdefault("TARGET_COMPRESSION_RATIO", "0.5")
os.environ.setdefault("ENABLE_CONTINUOUS_VERIFICATION", "true")
os.environ.setdefault("VERIFICATION_STAGES", "3")
os.environ.setdefault("CONFIDENCE_THRESHOLD", "0.7")
os.environ.setdefault("ENABLE_EARLY_WARNING", "true")
os.environ.setdefault("ENABLE_FACT_CHECK", "true")
os.environ.setdefault("ENABLE_UNCERTAINTY_MARKING", "true")
os.environ.setdefault("ENABLE_ADAPTIVE_CONTEXT", "true")
os.environ.setdefault("MIN_TOKENS", "1000")
os.environ.setdefault("MAX_TOKENS", "100000")
os.environ.setdefault("IMPORTANCE_BASED_PRESERVATION", "true")
os.environ.setdefault("ENABLE_AUTO_COMPRESSION", "true")
os.environ.setdefault("ENABLE_LONG_TERM_MEMORY", "false")
os.environ.setdefault("MEMORY_REFRESH_INTERVAL", "3600")
os.environ.setdefault("ENABLE_PRODUCTION_RELIABILITY", "true")
os.environ.setdefault("ENABLE_CIRCUIT_BREAKER", "true")
os.environ.setdefault("ENABLE_EXPONENTIAL_BACKOFF", "true")
os.environ.setdefault("ENABLE_STATE_PERSISTENCE", "false")
os.environ.setdefault("ENABLE_HEALTH_CHECK", "true")
os.environ.setdefault("ENABLE_GRACEFUL_DEGRADATION", "true")
os.environ.setdefault("ENABLE_DETAILED_LOGGING", "true")
os.environ.setdefault("FAILURE_THRESHOLD", "3")
os.environ.setdefault("RECOVERY_TIMEOUT", "60")
os.environ.setdefault("STATE_BACKEND", "memory")
os.environ.setdefault("STATE_TTL", "3600")
os.environ.setdefault("OUTPUT_DIR", "./output")
os.environ.setdefault("ENABLE_PDF", "true")
os.environ.setdefault("ENABLE_MARKDOWN", "true")
os.environ.setdefault("ENABLE_JSON", "true")
os.environ.setdefault("ENABLE_DOCX", "true")
os.environ.setdefault("ENABLE_HTML", "true")
os.environ.setdefault("ENABLE_LATEX", "false")


def visualize_langgraph():
    """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print("LangGraph ì›Œí¬í”Œë¡œìš° ì‹œê°í™”")
    print("=" * 80)
    
    try:
        from src.core.researcher_config import load_config_from_env
        from src.core.autonomous_orchestrator import AutonomousOrchestrator
        
        # Load configuration first
        print("\n[0] Configuration ë¡œë“œ ì¤‘...")
        config = load_config_from_env()
        print("âœ… Configuration ë¡œë“œ ì™„ë£Œ")
        
        # Create orchestrator (this builds the graph)
        print("\n[1] AutonomousOrchestrator ì´ˆê¸°í™” ì¤‘...")
        orchestrator = AutonomousOrchestrator()
        
        if orchestrator.graph is None:
            print("âŒ ê·¸ë˜í”„ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        print("âœ… ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
        
        # Get graph representation
        print("\n[2] ê·¸ë˜í”„ êµ¬ì¡° ë¶„ì„ ì¤‘...")
        graph = orchestrator.graph.get_graph()
        
        # Print nodes
        print("\n" + "=" * 80)
        print("ğŸ“Š ë…¸ë“œ ëª©ë¡ (Nodes)")
        print("=" * 80)
        nodes = graph.nodes
        for i, node in enumerate(nodes, 1):
            print(f"{i:2d}. {node}")
        
        # Print edges
        print("\n" + "=" * 80)
        print("ğŸ”— ì—£ì§€ ëª©ë¡ (Edges)")
        print("=" * 80)
        edges = graph.edges
        for i, edge in enumerate(edges, 1):
            print(f"{i:2d}. {edge.source} â†’ {edge.target}")
        
        # Generate Mermaid diagram
        print("\n" + "=" * 80)
        print("ğŸ¨ Mermaid ë‹¤ì´ì–´ê·¸ë¨")
        print("=" * 80)
        try:
            mermaid = graph.draw_mermaid()
            print(mermaid)
            
            # Save Mermaid file
            mermaid_file = project_root / "langgraph_workflow.mmd"
            with open(mermaid_file, 'w', encoding='utf-8') as f:
                f.write(mermaid)
            print(f"\nâœ… Mermaid ë‹¤ì´ì–´ê·¸ë¨ ì €ì¥: {mermaid_file}")
            
        except Exception as e:
            print(f"âš ï¸ Mermaid ìƒì„± ì‹¤íŒ¨: {e}")
        
        # Generate PNG using draw_mermaid_png
        print("\n" + "=" * 80)
        print("ğŸ–¼ï¸ PNG ì´ë¯¸ì§€ ìƒì„±")
        print("=" * 80)
        try:
            png_output = project_root / "langgraph_workflow.png"
            
            # Try using draw_mermaid_png if available
            try:
                png_data = graph.draw_mermaid_png()
                with open(png_output, 'wb') as f:
                    f.write(png_data)
                print(f"âœ… PNG ì´ë¯¸ì§€ ì €ì¥ (draw_mermaid_png): {png_output}")
            except AttributeError:
                print("âš ï¸ draw_mermaid_png ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ëŒ€ì²´ ë°©ë²• ì‹œë„ ì¤‘...")
                
                # Alternative: use mermaid-cli if available
                import subprocess
                mermaid_file = project_root / "langgraph_workflow.mmd"
                
                # Check if mmdc (mermaid-cli) is installed
                try:
                    result = subprocess.run(
                        ['which', 'mmdc'],
                        capture_output=True,
                        text=True
                    )
                    if result.returncode == 0:
                        print("âœ… mermaid-cli (mmdc) ë°œê²¬")
                        subprocess.run(
                            ['mmdc', '-i', str(mermaid_file), '-o', str(png_output), '-b', 'transparent'],
                            check=True
                        )
                        print(f"âœ… PNG ì´ë¯¸ì§€ ì €ì¥ (mmdc): {png_output}")
                    else:
                        print("âš ï¸ mermaid-cliê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        print("\nì„¤ì¹˜ ë°©ë²•:")
                        print("  npm install -g @mermaid-js/mermaid-cli")
                        print("\në˜ëŠ” Python íŒ¨í‚¤ì§€ ì‚¬ìš©:")
                        print("  pip install pyppeteer")
                        print("\nê·¸ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
                        
                        # Try using Python mermaid package
                        try:
                            print("\nPython mermaid íŒ¨í‚¤ì§€ë¡œ ì‹œë„ ì¤‘...")
                            from io import BytesIO
                            import base64
                            
                            # Try pyppeteer-based rendering
                            print("pyppeteer ê¸°ë°˜ ë Œë”ë§ ì‹œë„...")
                            subprocess.run(
                                ['python3', '-m', 'pip', 'install', 'pyppeteer', '--quiet'],
                                check=False
                            )
                            
                            # Create a simple HTML file with mermaid
                            html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({{startOnLoad:true}});</script>
</head>
<body>
    <div class="mermaid">
    {mermaid}
    </div>
</body>
</html>
"""
                            html_file = project_root / "langgraph_workflow.html"
                            with open(html_file, 'w', encoding='utf-8') as f:
                                f.write(html_content)
                            print(f"âœ… HTML íŒŒì¼ ì €ì¥: {html_file}")
                            print("\nğŸ“ ë¸Œë¼ìš°ì €ì—ì„œ HTML íŒŒì¼ì„ ì—´ê³  ìŠ¤í¬ë¦°ìƒ·ì„ ì°ê±°ë‚˜,")
                            print("   ì˜¨ë¼ì¸ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:")
                            print("   - https://mermaid.live/ (ì˜¨ë¼ì¸ ì—ë””í„°)")
                            print("   - https://mermaid.ink/ (PNG ìƒì„± API)")
                            
                        except Exception as e3:
                            print(f"âš ï¸ Python mermaid ë Œë”ë§ ì‹¤íŒ¨: {e3}")
                            
                except Exception as e2:
                    print(f"âš ï¸ ëŒ€ì²´ ë°©ë²• ì‹¤íŒ¨: {e2}")
                    
        except Exception as e:
            print(f"âŒ PNG ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        # Print workflow summary
        print("\n" + "=" * 80)
        print("ğŸ“‹ ì›Œí¬í”Œë¡œìš° ìš”ì•½")
        print("=" * 80)
        print(f"ì´ ë…¸ë“œ ìˆ˜: {len(nodes)}")
        print(f"ì´ ì—£ì§€ ìˆ˜: {len(edges)}")
        
        # Identify entry and end points
        entry_nodes = [n for n in nodes if not any(e.target == n for e in edges)]
        end_nodes = [n for n in nodes if not any(e.source == n for e in edges)]
        
        print(f"\nì§„ì…ì  (Entry Points): {entry_nodes}")
        print(f"ì¢…ë£Œì  (End Points): {end_nodes}")
        
        # Analyze conditional edges
        print("\nì¡°ê±´ë¶€ ë¼ìš°íŒ…:")
        for edge in edges:
            if hasattr(edge, 'data') and edge.data:
                print(f"  {edge.source} --[{edge.data}]--> {edge.target}")
        
        print("\n" + "=" * 80)
        print("âœ… ì‹œê°í™” ì™„ë£Œ!")
        print("=" * 80)
        
    except ImportError as e:
        print(f"âŒ Import ì—ëŸ¬: {e}")
        print("\ní•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("  pip install langgraph langchain-core")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    visualize_langgraph()

