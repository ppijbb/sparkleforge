"""
Universal MCP Hub - 2025ë…„ 10ì›” ìµœì‹  ë²„ì „

Model Context Protocol í†µí•©ì„ ìœ„í•œ ë²”ìš© í—ˆë¸Œ.
OpenRouterì™€ Gemini 2.5 Flash Lite ê¸°ë°˜ì˜ ìµœì‹  MCP ì—°ê²°.
Production ìˆ˜ì¤€ì˜ ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„± ë³´ì¥.
"""

import asyncio
import sys
import json
import logging
import time
import aiohttp
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass
from enum import Enum
import subprocess
import os
from datetime import datetime, timedelta
from contextlib import AsyncExitStack
import random
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# MCP imports
try:
    from mcp import ClientSession, StdioServerParameters
    from mcp.client.stdio import stdio_client
    from mcp.client.sse import sse_client
    from mcp.client.streamable_http import streamablehttp_client
    from mcp.types import ListToolsResult, TextContent
    from mcp.shared.exceptions import McpError
    from urllib.parse import urlencode
    import httpx
    MCP_AVAILABLE = True
    HTTP_CLIENT_AVAILABLE = True
except ImportError:
    MCP_AVAILABLE = False
    HTTP_CLIENT_AVAILABLE = False
    ClientSession = None
    StdioServerParameters = None
    stdio_client = None
    sse_client = None
    streamablehttp_client = None
    urlencode = None
    ListToolsResult = None
    TextContent = None
    McpError = Exception  # Fallback
    httpx = None

# FastMCP imports
try:
    from fastmcp import Client as FastMCPClient
    import logging as fastmcp_logging
    # FastMCP ë¡œê±° ë ˆë²¨ì„ warningìœ¼ë¡œ ì„¤ì •
    fastmcp_logger = fastmcp_logging.getLogger("fastmcp")
    fastmcp_logger.setLevel(fastmcp_logging.WARNING)
    # fastmcp ê´€ë ¨ ëª¨ë“  ë¡œê±°ì— ëŒ€í•´ warning ë ˆë²¨ ì ìš©
    for logger_name in ["fastmcp", "fastmcp.client", "fastmcp.runner"]:
        logger_instance = fastmcp_logging.getLogger(logger_name)
        logger_instance.setLevel(fastmcp_logging.WARNING)
    
    # MCP í´ë¼ì´ì–¸íŠ¸ ë¡œê±°ë„ í•„í„°ë§ (heartbeat ì˜¤ë¥˜ ë°©ì§€)
    for logger_name in ["mcp", "mcp.client", "mcp.client.streamable_http", "Runner"]:
        logger_instance = logging.getLogger(logger_name)
        logger_instance.setLevel(logging.WARNING)
        # heartbeat ê´€ë ¨ ë©”ì‹œì§€ í•„í„°ë§
        class HeartbeatFilter(logging.Filter):
            def filter(self, record):
                msg = record.getMessage()
                # heartbeat ê´€ë ¨ ì˜¤ë¥˜ ë©”ì‹œì§€ í•„í„°ë§
                if "heartbeat" in msg.lower() or "invalid_token" in msg.lower():
                    return False
                return True
        logger_instance.addFilter(HeartbeatFilter())
    
    FASTMCP_AVAILABLE = True
except ImportError:
    FastMCPClient = None
    FASTMCP_AVAILABLE = False

# LangChain imports
try:
    from langchain_core.tools import BaseTool, StructuredTool
    # Pydantic v2 í˜¸í™˜ì„± - ìµœì‹  LangChainì€ pydantic v2 ì‚¬ìš©
    try:
        from pydantic import BaseModel, Field
    except ImportError:
        try:
            from pydantic.v1 import BaseModel, Field
        except ImportError:
            from langchain_core.pydantic_v1 import BaseModel, Field
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    BaseTool = None
    StructuredTool = None
    BaseModel = None
    Field = None

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.researcher_config import get_mcp_config, get_llm_config
from src.core.mcp_auto_discovery import FastMCPMulti
from src.core.mcp_tool_loader import MCPToolLoader, ToolInfo as MCPToolInfo
from src.core.config import HTTPServerSpec

logger = logging.getLogger(__name__)

# 9ëŒ€ í˜ì‹ : ToolTrace ì¶”ì  ì‹œìŠ¤í…œ
_tool_trace_manager = None

def get_tool_trace_manager():
    """ì „ì—­ ToolTraceManager ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)."""
    global _tool_trace_manager
    if _tool_trace_manager is None:
        from src.core.tool_trace import ToolTraceManager
        _tool_trace_manager = ToolTraceManager()
    return _tool_trace_manager

def set_tool_trace_manager(manager):
    """ì „ì—­ ToolTraceManager ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •."""
    global _tool_trace_manager
    _tool_trace_manager = manager

def _create_tool_trace(
    tool_id: str,
    citation_id: str,
    tool_type: str,
    query: str,
    result: Dict[str, Any],
    mcp_server: Optional[str] = None,
    mcp_tool_name: Optional[str] = None,
) -> Optional[Any]:
    """
    ToolTrace ìƒì„± í—¬í¼ í•¨ìˆ˜ (9ëŒ€ í˜ì‹ : ToolTrace ì¶”ì  ì‹œìŠ¤í…œ).
    
    Args:
        tool_id: Tool ID
        citation_id: Citation ID
        tool_type: Tool type
        query: Query string
        result: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼
        mcp_server: MCP ì„œë²„ ì´ë¦„ (optional)
        mcp_tool_name: MCP ë„êµ¬ ì´ë¦„ (optional)
    
    Returns:
        ToolTrace ê°ì²´ (ìƒì„± ì„±ê³µ ì‹œ), None (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        from src.core.tool_trace import ToolTrace
        
        # raw_answer ìƒì„± (resultë¥¼ JSON ë¬¸ìì—´ë¡œ)
        raw_answer = json.dumps(result, ensure_ascii=False, indent=2) if result else "{}"
        
        # summary ìƒì„± (ê°„ë‹¨í•œ ìš”ì•½)
        if result.get("success"):
            if isinstance(result.get("data"), dict):
                if "results" in result["data"]:
                    summary = f"Found {len(result['data']['results'])} results"
                elif "content" in result["data"]:
                    content = str(result["data"]["content"])
                    summary = f"Content: {content[:100]}..." if len(content) > 100 else f"Content: {content}"
                else:
                    summary = "Tool executed successfully"
            else:
                summary = "Tool executed successfully"
        else:
            summary = f"Tool execution failed: {result.get('error', 'Unknown error')[:100]}"
        
        trace = ToolTrace.create_with_size_limit(
            tool_id=tool_id,
            citation_id=citation_id,
            tool_type=tool_type,
            query=query,
            raw_answer=raw_answer,
            summary=summary,
            mcp_server=mcp_server,
            mcp_tool_name=mcp_tool_name,
        )
        
        # ToolTraceManagerì— ì¶”ê°€
        try:
            manager = get_tool_trace_manager()
            manager.add_trace(trace)
        except Exception as e:
            logger.debug(f"Failed to add ToolTrace to manager: {e}")
        
        return trace
    except Exception as e:
        logger.debug(f"Failed to create ToolTrace: {e}")
        return None

def _infer_tool_type(tool_name: str) -> str:
    """
    ë„êµ¬ ì´ë¦„ì—ì„œ ë„êµ¬ íƒ€ì… ì¶”ë¡ .
    
    Args:
        tool_name: ë„êµ¬ ì´ë¦„
    
    Returns:
        ë„êµ¬ íƒ€ì…
    """
    tool_lower = tool_name.lower()
    
    if "::" in tool_name:
        # MCP ë„êµ¬
        return "mcp_tool"
    elif "search" in tool_lower or "google" in tool_lower or "tavily" in tool_lower:
        return "web_search"
    elif "arxiv" in tool_lower or "scholar" in tool_lower or "paper" in tool_lower:
        return "paper_search"
    elif "rag" in tool_lower or "query" in tool_lower:
        return "rag_hybrid" if "hybrid" in tool_lower else "rag_naive"
    elif "code" in tool_lower or "python" in tool_lower or "execute" in tool_lower:
        return "run_code"
    elif "browser" in tool_lower:
        return "browser"
    elif "generate" in tool_lower or "document" in tool_lower:
        return "document_generation"
    elif "file" in tool_lower:
        return "file_operation"
    else:
        return "unknown"

def _format_query_string(tool_name: str, parameters: Dict[str, Any]) -> str:
    """
    ë„êµ¬ íŒŒë¼ë¯¸í„°ë¥¼ ì¿¼ë¦¬ ë¬¸ìì—´ë¡œ í¬ë§·.
    
    Args:
        tool_name: ë„êµ¬ ì´ë¦„
        parameters: ë„êµ¬ íŒŒë¼ë¯¸í„°
    
    Returns:
        í¬ë§·ëœ ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # ì£¼ìš” íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    query_keys = ["query", "question", "text", "input", "url", "path", "code"]
    for key in query_keys:
        if key in parameters:
            value = parameters[key]
            if isinstance(value, str):
                return value[:200]  # ìµœëŒ€ 200ì
            elif isinstance(value, dict):
                return json.dumps(value, ensure_ascii=False)[:200]
    
    # íŒŒë¼ë¯¸í„° ì „ì²´ë¥¼ JSONìœ¼ë¡œ
    return json.dumps(parameters, ensure_ascii=False)[:200]


class ToolCategory(Enum):
    """MCP ë„êµ¬ ì¹´í…Œê³ ë¦¬."""
    SEARCH = "search"
    DATA = "data"
    CODE = "code"
    ACADEMIC = "academic"
    BUSINESS = "business"
    UTILITY = "utility"
    BROWSER = "browser"  # ë¸Œë¼ìš°ì € ìë™í™”
    DOCUMENT = "document"  # ë¬¸ì„œ ìƒì„±
    FILE = "file"  # íŒŒì¼ ì‘ì—…
    GIT = "git"  # Git ì›Œí¬í”Œë¡œìš°


@dataclass
class ToolInfo:
    """ë„êµ¬ ì •ë³´."""
    name: str
    category: ToolCategory
    description: str
    parameters: Dict[str, Any]
    mcp_server: str


@dataclass
class ToolResult:
    """ë„êµ¬ ì‹¤í–‰ ê²°ê³¼."""
    success: bool
    data: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0
    confidence: float = 0.0
    tool_name: Optional[str] = None
    source: Optional[str] = None


class ToolRegistry:
    """Tool ì¤‘ì•™ ê´€ë¦¬ ì‹œìŠ¤í…œ - MCP ë° ë¡œì»¬ Tool í†µí•© ê´€ë¦¬."""
    
    def __init__(self):
        """ToolRegistry ì´ˆê¸°í™”."""
        self.tools: Dict[str, ToolInfo] = {}  # tool_name -> ToolInfo
        self.langchain_tools: Dict[str, BaseTool] = {}  # tool_name -> LangChain Tool
        self.tool_sources: Dict[str, str] = {}  # tool_name -> source (mcp/local)
        self.mcp_tool_mapping: Dict[str, Tuple[str, str]] = {}  # tool_name -> (server_name, original_tool_name)
        
    def register_mcp_tool(self, server_name: str, tool: Any, tool_def: Any = None):
        """
        MCP Toolì„ server_name::tool_name í˜•ì‹ìœ¼ë¡œ ë“±ë¡.
        
        Args:
            server_name: MCP ì„œë²„ ì´ë¦„
            tool: MCP Tool ê°ì²´ ë˜ëŠ” tool name
            tool_def: MCP Tool ì •ì˜ (description, inputSchema ë“± í¬í•¨)
        """
        if isinstance(tool, str):
            tool_name = tool
        else:
            tool_name = tool.name if hasattr(tool, 'name') else str(tool)
        
        # server_name::tool_name í˜•ì‹ìœ¼ë¡œ ë“±ë¡
        registered_name = f"{server_name}::{tool_name}"
        
        # ToolInfo ìƒì„±
        if tool_def and hasattr(tool_def, 'description'):
            description = tool_def.description
            input_schema = tool_def.inputSchema if hasattr(tool_def, 'inputSchema') else {}
        else:
            description = f"Tool from MCP server {server_name}"
            input_schema = {}
        
        # ì¹´í…Œê³ ë¦¬ ì¶”ë¡  (ê¸°ë³¸ê°’: UTILITY)
        category = ToolCategory.UTILITY
        tool_lower = tool_name.lower()
        if 'search' in tool_lower:
            category = ToolCategory.SEARCH
        elif 'scholar' in tool_lower or 'arxiv' in tool_lower or 'paper' in tool_lower:
            category = ToolCategory.ACADEMIC
        elif 'browser' in tool_lower:
            category = ToolCategory.BROWSER
        elif tool_lower.startswith('generate_') or 'document' in tool_lower or 'pdf' in tool_lower or 'docx' in tool_lower or 'pptx' in tool_lower:
            category = ToolCategory.DOCUMENT
        elif 'file' in tool_lower and 'fetch' not in tool_lower:
            category = ToolCategory.FILE
        elif 'fetch' in tool_lower:
            category = ToolCategory.DATA
        elif 'code' in tool_lower or 'python' in tool_lower:
            category = ToolCategory.CODE
        
        tool_info = ToolInfo(
            name=registered_name,
            category=category,
            description=description,
            parameters=input_schema,
            mcp_server=server_name
        )
        
        self.tools[registered_name] = tool_info
        self.tool_sources[registered_name] = "mcp"
        self.mcp_tool_mapping[registered_name] = (server_name, tool_name)
        
        logger.debug(f"Registered MCP tool: {registered_name} from server {server_name}")
        
    def register_local_tool(self, tool_info: ToolInfo, langchain_tool: BaseTool):
        """
        ë¡œì»¬ Toolì„ LangChain Toolê³¼ í•¨ê»˜ ë“±ë¡.
        
        Args:
            tool_info: ToolInfo ê°ì²´
            langchain_tool: LangChain BaseTool ì¸ìŠ¤í„´ìŠ¤
        """
        tool_name = tool_info.name
        
        self.tools[tool_name] = tool_info
        self.langchain_tools[tool_name] = langchain_tool
        self.tool_sources[tool_name] = "local"
        
        logger.debug(f"Registered local tool: {tool_name}")
        
    def get_tool_info(self, tool_name: str) -> Optional[ToolInfo]:
        """Tool ì •ë³´ ì¡°íšŒ."""
        return self.tools.get(tool_name)
        
    def get_langchain_tool(self, tool_name: str) -> Optional[BaseTool]:
        """LangChain Tool ì¡°íšŒ."""
        return self.langchain_tools.get(tool_name)
        
    def get_all_langchain_tools(self) -> List[BaseTool]:
        """ëª¨ë“  Toolì„ LangChain Tool ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜."""
        return list(self.langchain_tools.values())
        
    def get_tools_by_category(self, category: ToolCategory) -> List[str]:
        """ì¹´í…Œê³ ë¦¬ë³„ Tool ëª©ë¡ ë°˜í™˜."""
        return [
            name for name, info in self.tools.items()
            if info.category == category
        ]
        
    def is_mcp_tool(self, tool_name: str) -> bool:
        """Toolì´ MCP Toolì¸ì§€ í™•ì¸."""
        return self.tool_sources.get(tool_name) == "mcp"
        
    def get_mcp_server_info(self, tool_name: str) -> Optional[Tuple[str, str]]:
        """MCP Toolì˜ ì„œë²„ ì •ë³´ ë°˜í™˜: (server_name, original_tool_name)."""
        return self.mcp_tool_mapping.get(tool_name)
        
    def get_all_tool_names(self) -> List[str]:
        """ë“±ë¡ëœ ëª¨ë“  Tool ì´ë¦„ ë°˜í™˜."""
        return list(self.tools.keys())
        
    def remove_tool(self, tool_name: str):
        """Tool ì œê±°."""
        if tool_name in self.tools:
            del self.tools[tool_name]
        if tool_name in self.langchain_tools:
            del self.langchain_tools[tool_name]
        if tool_name in self.tool_sources:
            del self.tool_sources[tool_name]
        if tool_name in self.mcp_tool_mapping:
            del self.mcp_tool_mapping[tool_name]


class OpenRouterClient:
    """(ë¹„í™œì„±í™”) OpenRouter ê²½ìœ ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."""
    def __init__(self, api_key: str):
        self.api_key = api_key
    async def __aenter__(self):
        raise RuntimeError("OpenRouter is disabled. Use Gemini direct path via llm_manager.")
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        return False
    async def generate_response(self, *args, **kwargs):
        raise RuntimeError("OpenRouter is disabled. Use Gemini direct path via llm_manager.")



class UniversalMCPHub:
    """Universal MCP Hub - 2025ë…„ 10ì›” ìµœì‹  ë²„ì „."""

    def __init__(self):
        self.config = get_mcp_config()
        self.llm_config = get_llm_config()

        # ToolRegistry í†µí•© ê´€ë¦¬
        self.registry = ToolRegistry()
        
        # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ë³„ MCP ì„¸ì…˜ ê´€ë¦¬ (ROMA ìŠ¤íƒ€ì¼)
        # ê° ì‹¤í–‰ë§ˆë‹¤ ë…ë¦½ì ì¸ MCP ì„¸ì…˜ í’€ì„ ìœ ì§€
        self._execution_sessions: Dict[str, Dict[str, Any]] = {}
        self.tools: Dict[str, ToolInfo] = {}  # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (registry.tools ì°¸ì¡°)
        self.openrouter_client: Optional[OpenRouterClient] = None

        # MCP í´ë¼ì´ì–¸íŠ¸ (ê¸°ì¡´ ì‹œìŠ¤í…œ)
        self.mcp_sessions: Dict[str, ClientSession] = {}
        self.exit_stacks: Dict[str, AsyncExitStack] = {}  # ì°¸ì¡°ë§Œ ìœ ì§€, cleanupì—ì„œ aclose() í˜¸ì¶œ ì•ˆ í•¨
        self.mcp_tools_map: Dict[str, Dict[str, Any]] = {}  # server_name -> {tool_name -> tool_info}
        self.mcp_server_configs: Dict[str, Dict[str, Any]] = {}
        # ê° ì„œë²„ë³„ ì—°ê²° ì§„ë‹¨ ì •ë³´
        self.connection_diagnostics: Dict[str, Dict[str, Any]] = {}
        # ì¢…ë£Œ/ì°¨ë‹¨ í”Œë˜ê·¸ (ì¢…ë£Œ ì¤‘ ì‹ ê·œ ì—°ê²° ë°©ì§€)
        self.stopping: bool = False
        
        # FastMCP Client ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ (ì—°ê²° í’€ë§)
        self.fastmcp_clients: Dict[str, Any] = {}  # server_name -> FastMCPClient
        
        # Anti-bot ìš°íšŒë¥¼ ìœ„í•œ User-Agent í’€ (Skyvern ìŠ¤íƒ€ì¼)
        self.user_agents = [
            # Chrome (Windows)
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            # Chrome (macOS)
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            # Chrome (Linux)
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            # Firefox (Windows)
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0",
            # Firefox (macOS)
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0",
            # Safari (macOS)
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.1 Safari/605.1.15",
            # Edge (Windows)
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
        ]
        
        # ìš”ì²­ ê°„ê²© ë³€ë™ì„±ì„ ìœ„í•œ íˆìŠ¤í† ë¦¬ (Skyvern ìŠ¤íƒ€ì¼: ì¸ê°„ í–‰ë™ íŒ¨í„´ ëª¨ë°©)
        self.request_timing_history: Dict[str, List[float]] = {}  # server_name -> [timestamps]

        # FastMCP ìë™ ë°œê²¬ ì‹œìŠ¤í…œ (ì‹ ê·œ)
        self.fastmcp_servers: Dict[str, HTTPServerSpec] = {}  # ìë™ ë°œê²¬ìš© ì„œë²„ ì„¤ì •
        self.fastmcp_multi: Optional[FastMCPMulti] = None
        self.fastmcp_tool_loader: Optional[MCPToolLoader] = None
        # FastMCP ì„¤ì • ì €ì¥ì†Œ (ì„œë²„ë³„) - ClientëŠ” context managerì´ë¯€ë¡œ ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±
        self.fastmcp_configs: Dict[str, Dict[str, Any]] = {}  # server_name -> mcp_config
        self.auto_discovered_tools: Dict[str, BaseTool] = {}  # ìë™ ë°œê²¬ëœ ë„êµ¬ë“¤
        self.auto_discovered_tool_infos: Dict[str, MCPToolInfo] = {}  # ë„êµ¬ ë©”íƒ€ë°ì´í„°

        # ERA ì„œë²„ ê´€ë¦¬ì (ì•ˆì „í•œ ì½”ë“œ ì‹¤í–‰)
        self.era_server_manager: Optional[Any] = None
        try:
            from src.core.researcher_config import get_era_config
            from src.core.era_server_manager import ERAServerManager
            
            era_config = get_era_config()
            if era_config.enabled:
                # ì„œë²„ ì£¼ì†Œ íŒŒì‹±
                server_addr = ":8080"  # ê¸°ë³¸ê°’
                if ':' in era_config.server_url:
                    try:
                        port = era_config.server_url.split(':')[-1]
                        server_addr = f":{port}"
                    except:
                        pass
                
                self.era_server_manager = ERAServerManager(
                    agent_binary_path=era_config.agent_binary_path,
                    server_url=era_config.server_url,
                    server_addr=server_addr,
                    auto_start=era_config.auto_start
                )
                logger.info("ERA server manager initialized")
        except ImportError:
            logger.debug("ERA modules not available")
        except Exception as e:
            logger.warning(f"Failed to initialize ERA server manager: {e}")

        self._load_tools_config()
        self._initialize_tools()
        self._initialize_clients()
        self._load_mcp_servers_from_config()
        
    def _load_tools_config(self):
        """tools_config.jsonì—ì„œ Tool ë©”íƒ€ë°ì´í„° ë¡œë“œ."""
        # configs í´ë”ì—ì„œ ë¡œë“œ ì‹œë„ (ìš°ì„ )
        tools_config_file = project_root / "configs" / "tools_config.json"
        if not tools_config_file.exists():
            # í•˜ìœ„ í˜¸í™˜ì„±: ë£¨íŠ¸ì—ì„œë„ ì‹œë„
            tools_config_file = project_root / "tools_config.json"
        
        if tools_config_file.exists():
            try:
                with open(tools_config_file, 'r', encoding='utf-8') as f:
                    self.tools_config = json.load(f)
                logger.info(f"âœ… Loaded tools config from {tools_config_file}")
            except Exception as e:
                logger.warning(f"Failed to load tools config: {e}")
                self.tools_config = {}
        else:
            logger.warning(f"tools_config.json not found at {tools_config_file}")
            self.tools_config = {}
    
    def _create_langchain_tool_wrapper(self, tool_name: str, tool_config: Dict[str, Any]) -> Optional[BaseTool]:
        """
        tools_config.jsonì˜ ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ LangChain Tool ë˜í¼ ìƒì„±.
        
        Args:
            tool_name: Tool ì´ë¦„
            tool_config: tools_config.jsonì—ì„œ ë¡œë“œëœ Tool ì„¤ì •
            
        Returns:
            LangChain BaseTool ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
        """
        if not LANGCHAIN_AVAILABLE:
            logger.warning("LangChain not available, cannot create tool wrapper")
            return None
        
        try:
            # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
            category_map = {
                "search": ToolCategory.SEARCH,
                "data": ToolCategory.DATA,
                "code": ToolCategory.CODE,
                "academic": ToolCategory.ACADEMIC,
                "business": ToolCategory.BUSINESS,
                "utility": ToolCategory.UTILITY,
                "browser": ToolCategory.BROWSER,
                "document": ToolCategory.DOCUMENT,
                "file": ToolCategory.FILE
            }
            
            category_str = tool_config.get("category", "utility")
            category = category_map.get(category_str, ToolCategory.UTILITY)
            description = tool_config.get("description", f"{tool_name} tool")
            params_config = tool_config.get("parameters", {})
            
            # Pydantic ìŠ¤í‚¤ë§ˆ ìƒì„± - ìµœì‹  ë°©ì‹ìœ¼ë¡œ ë‹¨ìˆœí™” (args_schema ì—†ì´ë„ ë™ì‘)
            ToolSchema = None
            # LangChain StructuredToolì€ args_schema ì—†ì´ë„ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì—ì„œ ìë™ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ë¡ í•¨
            # ë³µì¡í•œ ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„±ì„ í”¼í•˜ê³  í•¨ìˆ˜ íŒŒë¼ë¯¸í„°ë¡œ ì²˜ë¦¬
            
            # Tool ì‹¤í–‰ í•¨ìˆ˜ ì„ íƒ (ë™ê¸° ë˜í¼ ìƒì„±) - í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ëª…ì‹œ
            def create_sync_func(tool_name_str, func_type):
                """ë™ê¸° í•¨ìˆ˜ ë˜í¼ ìƒì„± - ëª…ì‹œì  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ë¡œ LangChainì´ íŒŒë¼ë¯¸í„° ì¶”ë¡ ."""
                if func_type == "search":
                    def search_wrapper(query: str, max_results: int = 10, num_results: int = 10) -> str:
                        params = {"query": query}
                        if max_results:
                            params["max_results"] = max_results
                        elif num_results:
                            params["max_results"] = num_results
                        return _execute_search_tool_sync(tool_name_str, params)
                    return search_wrapper
                elif func_type == "academic":
                    def academic_wrapper(query: str, max_results: int = 10, num_results: int = 10) -> str:
                        params = {"query": query}
                        if max_results:
                            params["max_results"] = max_results
                        elif num_results:
                            params["max_results"] = num_results
                        return _execute_academic_tool_sync(tool_name_str, params)
                    return academic_wrapper
                elif func_type == "data":
                    if tool_name_str == "fetch":
                        def fetch_wrapper(url: str) -> str:
                            return _execute_data_tool_sync("fetch", {"url": url})
                        return fetch_wrapper
                    elif tool_name_str == "filesystem":
                        def filesystem_wrapper(path: str, operation: str = "read") -> str:
                            return _execute_data_tool_sync("filesystem", {"path": path, "operation": operation})
                        return filesystem_wrapper
                    else:
                        def data_wrapper(**kwargs) -> str:
                            return _execute_data_tool_sync(tool_name_str, kwargs)
                        return data_wrapper
                elif func_type == "code":
                    if "interpreter" in tool_name_str.lower():
                        def code_wrapper(code: str, language: str = "python") -> str:
                            return _execute_code_tool_sync(tool_name_str, {"code": code, "language": language})
                        return code_wrapper
                    else:
                        def code_wrapper(code: str) -> str:
                            return _execute_code_tool_sync(tool_name_str, {"code": code})
                        return code_wrapper
                else:
                    return None
            
            # Toolë³„ ì‹¤í–‰ í•¨ìˆ˜ ë§¤í•‘
            func = None
            category_str = tool_config.get("category", "utility")
            
            if tool_name == "g-search":
                func = create_sync_func("g-search", "search")
            elif tool_name == "fetch":
                func = create_sync_func("fetch", "data")
            elif tool_name == "filesystem":
                func = create_sync_func("filesystem", "data")
            elif tool_name == "python_coder":
                func = create_sync_func("python_coder", "code")
            elif tool_name == "code_interpreter":
                func = create_sync_func("code_interpreter", "code")
            elif tool_name == "arxiv":
                func = create_sync_func("arxiv", "academic")
            elif tool_name == "scholar":
                func = create_sync_func("scholar", "academic")
            else:
                # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì„ íƒ ì‹œë„
                if category_str == "search":
                    func = create_sync_func(tool_name, "search")
                elif category_str == "data":
                    func = create_sync_func(tool_name, "data")
                elif category_str == "code":
                    func = create_sync_func(tool_name, "code")
                elif category_str == "academic":
                    func = create_sync_func(tool_name, "academic")
            
            if func is None:
                logger.warning(f"No execution function for tool: {tool_name}, category: {category_str}")
                # ì‹¤í–‰ í•¨ìˆ˜ê°€ ì—†ì–´ë„ ê¸°ë³¸ ë˜í¼ í•¨ìˆ˜ ìƒì„±
                def generic_executor(**kwargs):
                    """Generic executor when specific function not available."""
                    raise RuntimeError(f"Tool {tool_name} execution not implemented yet. Please configure execution function.")
                func = generic_executor
            
            # StructuredTool ìƒì„± - args_schema ì—†ì´ë„ ìƒì„± ê°€ëŠ¥í•˜ë„ë¡
            try:
                if StructuredTool and ToolSchema:
                    langchain_tool = StructuredTool.from_function(
                        func=func,
                        name=tool_name,
                        description=description,
                        args_schema=ToolSchema
                    )
                elif StructuredTool:
                    # args_schema ì—†ì´ ìƒì„± (íŒŒë¼ë¯¸í„°ëŠ” í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì—ì„œ ìë™ ì¶”ë¡ )
                    langchain_tool = StructuredTool.from_function(
                        func=func,
                        name=tool_name,
                        description=description
                    )
                else:
                    return None
                
                logger.info(f"âœ… Created LangChain tool wrapper for {tool_name}")
                return langchain_tool
            except Exception as schema_error:
                # Schema ìƒì„± ì‹¤íŒ¨ ì‹œ args_schema ì—†ì´ ì¬ì‹œë„
                logger.warning(f"Failed to create tool with schema for {tool_name}: {schema_error}, trying without schema")
                try:
                    if StructuredTool:
                        langchain_tool = StructuredTool.from_function(
                            func=func,
                            name=tool_name,
                            description=description
                        )
                        logger.info(f"âœ… Created LangChain tool wrapper for {tool_name} (without schema)")
                        return langchain_tool
                except Exception as e2:
                    logger.error(f"Failed to create tool without schema for {tool_name}: {e2}")
                    return None
            
        except Exception as e:
            logger.error(f"Failed to create LangChain tool wrapper for {tool_name}: {e}")
            return None
    
    def _initialize_tools(self):
        """ë„êµ¬ ì´ˆê¸°í™” - tools_config.json ê¸°ë°˜ + FastMCP ìë™ ë°œê²¬."""
        # 1. ìˆ˜ë™ ë“±ë¡ ë„êµ¬ ì´ˆê¸°í™”
        self._initialize_manual_tools()

        # 2. FastMCP ìë™ ë°œê²¬ ë„êµ¬ ì´ˆê¸°í™” (ë¹„ë™ê¸°)
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        try:
            # ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ í™•ì¸
            try:
                loop = asyncio.get_running_loop()
                # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰ (asyncio.run() ì‚¬ìš© ê¸ˆì§€)
                # íƒœìŠ¤í¬ë¥¼ ìƒì„±í•˜ì§€ë§Œ awaití•˜ì§€ ì•ŠìŒ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
                task = loop.create_task(self._initialize_auto_discovered_tools())
                # íƒœìŠ¤í¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì§€ ì•ŠìŒ (ë¹„ë™ê¸° ì´ˆê¸°í™”)
                logger.debug("Auto-discovered MCP tools initialization started as background task")
            except RuntimeError:
                # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ì—ì„œ ì‹¤í–‰
                asyncio.run(self._initialize_auto_discovered_tools())
        except Exception as e:
            logger.warning(f"Failed to initialize auto-discovered MCP tools: {e}")
            import traceback
            logger.debug(f"Traceback: {traceback.format_exc()}")
            # ìë™ ë°œê²¬ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰

        # 3. ë„êµ¬ í†µí•© ë° ì¶©ëŒ í•´ê²°
        self._merge_tools()

    def _initialize_manual_tools(self):
        """ìˆ˜ë™ ë“±ë¡ ë„êµ¬ ì´ˆê¸°í™” - tools_config.json ê¸°ë°˜."""
        local_tools = self.tools_config.get("local_tools", {})

        for tool_name, tool_config in local_tools.items():
            # MCP ì „ìš© Toolì€ ê±´ë„ˆë›°ê¸° (MCP ì„œë²„ì—ì„œ ë™ì  ë“±ë¡ë¨)
            if tool_config.get("implementation") == "mcp_only":
                continue

            # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
            category_map = {
                "search": ToolCategory.SEARCH,
                "data": ToolCategory.DATA,
                "code": ToolCategory.CODE,
                "academic": ToolCategory.ACADEMIC,
                "business": ToolCategory.BUSINESS,
                "utility": ToolCategory.UTILITY,
                "browser": ToolCategory.BROWSER,
                "document": ToolCategory.DOCUMENT,
                "file": ToolCategory.FILE
            }

            category_str = tool_config.get("category", "utility")
            category = category_map.get(category_str, ToolCategory.UTILITY)
            description = tool_config.get("description", f"{tool_name} tool")

            # ToolInfo ìƒì„±
            tool_info = ToolInfo(
                name=tool_name,
                category=category,
                description=description,
                parameters=tool_config.get("parameters", {}),
                mcp_server=tool_config.get("mcp_server_name", "")
            )

            # LangChain Tool ë˜í¼ ìƒì„±
            langchain_tool = self._create_langchain_tool_wrapper(tool_name, tool_config)

            if langchain_tool:
                # Registryì— ë“±ë¡
                self.registry.register_local_tool(tool_info, langchain_tool)
                # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ self.toolsì—ë„ ì¶”ê°€
                self.tools[tool_name] = tool_info
                logger.info(f"âœ… Registered local tool: {tool_name}")
            else:
                # LangChain wrapper ìƒì„± ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ ToolInfoëŠ” ë“±ë¡ (ë‚˜ì¤‘ì— ì‹¤í–‰ ì‹œë„ ê°€ëŠ¥)
                logger.warning(f"âš ï¸ Failed to create LangChain wrapper for {tool_name}, registering without wrapper")
                self.registry.tools[tool_name] = tool_info
                self.tools[tool_name] = tool_info

        # ========================================================================
        # NATIVE TOOLS REGISTRATION (Overrides/Fallbacks)
        # ========================================================================
        try:
            from src.core.tools.native_search import search_duckduckgo_json
            from langchain_core.tools import Tool
            
            native_tool_name = "ddg_search"
            logger.info(f"ğŸ› ï¸ Registering Native Tool: {native_tool_name}")
            
            native_tool_info = ToolInfo(
                name=native_tool_name,
                category=ToolCategory.SEARCH,
                description="Robust native DuckDuckGo search (No MCP required)",
                parameters={"query": {"type": "string", "description": "Search query"}, "max_results": {"type": "integer", "description": "Max results"}},
                mcp_server="" 
            )
            
            def native_search_wrapper(query: str, max_results: int = 5):
                # Handler for both string input (query only) and structured input
                if isinstance(query, dict):
                    q = query.get("query", "")
                    m = query.get("max_results", 5)
                    return search_duckduckgo_json(q, m)
                return search_duckduckgo_json(query, max_results)

            native_langchain_tool = Tool(
                name=native_tool_name,
                func=native_search_wrapper,
                description="Search DuckDuckGo natively"
            )
            
            self.registry.register_local_tool(native_tool_info, native_langchain_tool)
            self.tools[native_tool_name] = native_tool_info
            
            # Also alias 'search' and 'g-search' to this if not present
            for alias in ["search", "g-search"]:
                if alias not in self.tools and alias not in self.registry.tools:
                    self.tools[alias] = native_tool_info
                    self.registry.register_local_tool(native_tool_info, native_langchain_tool) # Re-registering with same object might verify alias support? No, straightforward.
                    logger.info(f"âœ… Aliased '{alias}' to native {native_tool_name}")
                    
        except Exception as e:
            logger.error(f"âŒ Failed to register native tools: {e}")

        # ========================================================================
        # GIT TOOLS REGISTRATION
        # ========================================================================
        try:
            from langchain_core.tools import Tool
            
            git_tools = [
                {
                    "name": "git_status",
                    "description": "Check Git repository status (branch, staged/unstaged files)",
                    "parameters": {
                        "repo_path": {"type": "string", "description": "Repository path (optional, defaults to current directory)"}
                    }
                },
                {
                    "name": "git_commit",
                    "description": "Create a Git commit with automatic message generation",
                    "parameters": {
                        "message": {"type": "string", "description": "Commit message (optional, auto-generated if not provided)"},
                        "auto_stage": {"type": "boolean", "description": "Automatically stage files (default: true)"},
                        "repo_path": {"type": "string", "description": "Repository path (optional)"}
                    }
                },
                {
                    "name": "git_push",
                    "description": "Push Git branch to remote repository",
                    "parameters": {
                        "branch": {"type": "string", "description": "Branch to push (optional, defaults to current branch)"},
                        "force": {"type": "boolean", "description": "Force push (default: false)"},
                        "repo_path": {"type": "string", "description": "Repository path (optional)"}
                    }
                },
                {
                    "name": "git_create_pr",
                    "description": "Create a Pull Request using GitHub CLI",
                    "parameters": {
                        "title": {"type": "string", "description": "PR title (required)"},
                        "body": {"type": "string", "description": "PR body (optional)"},
                        "base": {"type": "string", "description": "Base branch (default: main)"},
                        "repo_path": {"type": "string", "description": "Repository path (optional)"}
                    }
                },
                {
                    "name": "git_commit_push_pr",
                    "description": "Complete workflow: commit, push, and create PR in one step",
                    "parameters": {
                        "commit_message": {"type": "string", "description": "Commit message (optional, auto-generated if not provided)"},
                        "pr_title": {"type": "string", "description": "PR title (optional, uses commit message if not provided)"},
                        "pr_body": {"type": "string", "description": "PR body (optional, auto-generated if not provided)"},
                        "base": {"type": "string", "description": "Base branch (default: main)"},
                        "repo_path": {"type": "string", "description": "Repository path (optional)"}
                    }
                }
            ]
            
            for git_tool_config in git_tools:
                tool_name = git_tool_config["name"]
                logger.info(f"ğŸ› ï¸ Registering Git Tool: {tool_name}")
                
                tool_info = ToolInfo(
                    name=tool_name,
                    category=ToolCategory.GIT,
                    description=git_tool_config["description"],
                    parameters=git_tool_config["parameters"],
                    mcp_server=""
                )
                
                # LangChain Tool ë˜í¼ ìƒì„±
                def create_git_tool_wrapper(tool_name: str):
                    async def git_tool_wrapper(**kwargs):
                        from src.core.mcp_integration import _execute_git_tool, ToolResult
                        result = await _execute_git_tool(tool_name, kwargs)
                        if result.success:
                            return result.data if isinstance(result.data, dict) else {"result": result.data}
                        else:
                            return {"error": result.error}
                    
                    return git_tool_wrapper
                
                # ë™ê¸° ë˜í¼ (LangChain Toolì€ ë™ê¸° í•¨ìˆ˜ë¥¼ ê¸°ëŒ€)
                def sync_git_wrapper(tool_name: str):
                    def wrapper(**kwargs):
                        import asyncio
                        try:
                            loop = asyncio.get_event_loop()
                            if loop.is_running():
                                # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ íƒœìŠ¤í¬ ìƒì„±
                                import concurrent.futures
                                with concurrent.futures.ThreadPoolExecutor() as executor:
                                    future = executor.submit(asyncio.run, create_git_tool_wrapper(tool_name)(**kwargs))
                                    return future.result()
                            else:
                                return loop.run_until_complete(create_git_tool_wrapper(tool_name)(**kwargs))
                        except RuntimeError:
                            return asyncio.run(create_git_tool_wrapper(tool_name)(**kwargs))
                    return wrapper
                
                langchain_tool = Tool(
                    name=tool_name,
                    func=sync_git_wrapper(tool_name),
                    description=git_tool_config["description"]
                )
                
                self.registry.register_local_tool(tool_info, langchain_tool)
                self.tools[tool_name] = tool_info
                logger.info(f"âœ… Registered Git tool: {tool_name}")
                
        except Exception as e:
            logger.error(f"âŒ Failed to register Git tools: {e}", exc_info=True)
        
        # Registryì˜ toolsë¥¼ self.toolsì™€ ë™ê¸°í™”
        self.tools.update(self.registry.tools)
        
        logger.info(f"âœ… Initialized {len(self.registry.tools)} tools in registry ({len(self.registry.langchain_tools)} with LangChain wrappers)")

    async def _initialize_auto_discovered_tools(self):
        """FastMCPë¥¼ í†µí•œ ìë™ ë°œê²¬ ë„êµ¬ ì´ˆê¸°í™”."""
        # FastMCP ì„œë²„ ì„¤ì • ì´ˆê¸°í™”
        self._initialize_fastmcp_servers()

        if not self.fastmcp_servers:
            logger.info("No FastMCP servers configured for auto-discovery")
            return

        # FastMCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.fastmcp_multi = FastMCPMulti(self.fastmcp_servers)
        self.fastmcp_tool_loader = MCPToolLoader(self.fastmcp_multi)

        try:
            # ë„êµ¬ ìë™ ë°œê²¬
            discovered_tools = await self.fastmcp_tool_loader.get_all_tools()
            tool_infos = await self.fastmcp_tool_loader.list_tool_info()

            # ë°œê²¬ëœ ë„êµ¬ ì €ì¥
            for tool, info in zip(discovered_tools, tool_infos):
                tool_name = info.name
                self.auto_discovered_tools[tool_name] = tool
                self.auto_discovered_tool_infos[tool_name] = info

            logger.info(f"Auto-discovered {len(discovered_tools)} tools from {len(self.fastmcp_servers)} FastMCP servers")

        except Exception as e:
            logger.error(f"Failed to auto-discover MCP tools: {e}")
            raise

    def _initialize_fastmcp_servers(self):
        """í™˜ê²½ ë³€ìˆ˜ ë° êµ¬ì„±ì—ì„œ FastMCP ì„œë²„ ì„¤ì • ì´ˆê¸°í™”."""
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„œë²„ ì„¤ì • ë¡œë“œ (ì˜ˆ: FASTMCP_SERVERS)
        # ì‹¤ì œë¡œëŠ” configë‚˜ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œí•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ ë¹ˆ ì„¤ì • ìœ ì§€
        pass

    def _merge_tools(self):
        """ìë™ ë°œê²¬ ë„êµ¬ì™€ ìˆ˜ë™ ë“±ë¡ ë„êµ¬ í†µí•© ë° ì¶©ëŒ í•´ê²°."""
        # ìë™ ë°œê²¬ëœ ë„êµ¬ë“¤ì„ ToolRegistryì— í†µí•©
        for tool_name, tool in self.auto_discovered_tools.items():
            tool_info = self.auto_discovered_tool_infos[tool_name]

            # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (MCP ToolInfo -> ê¸°ì¡´ ToolCategory)
            category_map = {
                "search": ToolCategory.SEARCH,
                "data": ToolCategory.DATA,
                "code": ToolCategory.CODE,
                "academic": ToolCategory.ACADEMIC,
                "business": ToolCategory.BUSINESS,
                "utility": ToolCategory.UTILITY,
                "browser": ToolCategory.BROWSER,
                "document": ToolCategory.DOCUMENT,
                "file": ToolCategory.FILE
            }

            # ë„êµ¬ ì„¤ëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡  (ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜)
            description_lower = tool_info.description.lower()
            category = ToolCategory.UTILITY  # ê¸°ë³¸ê°’
            for keyword, cat in category_map.items():
                if keyword in description_lower:
                    category = cat
                    break

            # ê¸°ì¡´ ToolInfo í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            legacy_tool_info = ToolInfo(
                name=tool_name,
                category=category,
                description=tool_info.description,
                parameters={},  # MCP ìŠ¤í‚¤ë§ˆëŠ” ë³„ë„ ì²˜ë¦¬
                mcp_server=tool_info.server_guess
            )

            # ì´ë¦„ ì¶©ëŒ í™•ì¸
            if tool_name in self.registry.tools:
                # ì¶©ëŒ ì‹œ ìë™ ë°œê²¬ ë„êµ¬ ìš°ì„  (mcp_auto_ ì ‘ë‘ì‚¬ë¡œ êµ¬ë¶„)
                auto_tool_name = f"mcp_auto_{tool_name}"
                logger.warning(f"Tool name conflict: '{tool_name}' already exists. Using '{auto_tool_name}' for auto-discovered tool.")
                legacy_tool_info.name = auto_tool_name

            # Registryì— ë“±ë¡
            self.registry.register_local_tool(legacy_tool_info, tool)

        # Registryì™€ self.tools ë™ê¸°í™”
        self.tools.update(self.registry.tools)
        logger.info(f"âœ… Merged tools: {len(self.registry.tools)} total tools in registry")

    def _initialize_clients(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” - Gemini ì§ê²° ì‚¬ìš©, OpenRouter ë¹„í™œì„±í™”."""
        self.openrouter_client = None
        logger.info("âœ… LLM routed via llm_manager (Gemini direct). OpenRouter disabled.")
    
    def _resolve_env_vars_in_value(self, value: Any) -> Any:
        """
        ì¬ê·€ì ìœ¼ë¡œ ê°ì²´ ë‚´ì˜ í™˜ê²½ë³€ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜.
        ${VAR_NAME} ë˜ëŠ” $VAR_NAME í˜•ì‹ ì§€ì›.
        """
        if isinstance(value, str):
            import re
            # ${VAR_NAME} ë˜ëŠ” $VAR_NAME íŒ¨í„´ ì°¾ê¸°
            pattern = r'\$\{([^}]+)\}|\$(\w+)'
            
            def replace_env_var(match):
                var_name = match.group(1) or match.group(2)
                env_value = os.getenv(var_name)
                if env_value is not None:
                    return env_value
                # í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ìœ ì§€ (ë˜ëŠ” ê²½ê³ )
                logger.warning(f"Environment variable '{var_name}' not found, keeping placeholder")
                return match.group(0)
            
            result = re.sub(pattern, replace_env_var, value)
            return result
        elif isinstance(value, dict):
            return {k: self._resolve_env_vars_in_value(v) for k, v in value.items()}
        elif isinstance(value, list):
            return [self._resolve_env_vars_in_value(item) for item in value]
        else:
            return value
    
    def _check_server_requirements(self, server_name: str, server_config: Dict[str, Any]) -> bool:
        """
        ì„œë²„ì— í•„ìš”í•œ API í‚¤ë‚˜ í™˜ê²½ë³€ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸.
        
        Returns:
            True: ì„œë²„ë¥¼ ë¡œë“œí•´ë„ ë¨
            False: API í‚¤ê°€ ì—†ì–´ì„œ ìŠ¤í‚µí•´ì•¼ í•¨
        """
        # exa ì„œë²„ëŠ” EXA_API_KEY í•„ìš”
        if server_name == "exa" or "exa" in server_name.lower():
            exa_key = os.getenv("EXA_API_KEY")
            if not exa_key:
                return False
            # headersì— Authorizationì´ í•„ìš”í•œ ê²½ìš° í™•ì¸
            headers = server_config.get("headers", {})
            if "Authorization" in headers:
                auth_value = headers.get("Authorization", "")
                # í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜ì´ ì•ˆëœ ê²½ìš° (${EXA_API_KEY} í˜•íƒœ)
                if "${" in auth_value or not auth_value.replace("Bearer ", "").strip():
                    return False
        
        # stdio ë°©ì‹ ì„œë²„ëŠ” API í‚¤ ë¶ˆí•„ìš” (npxë¡œ ì‹¤í–‰)
        # ë‹¨, github ì„œë²„ëŠ” GITHUB_TOKENì´ í•„ìš”í•¨
        if "command" in server_config and "httpUrl" not in server_config and "url" not in server_config:
            # github ì„œë²„ëŠ” GITHUB_TOKEN ì²´í¬
            if server_name == "github" or "github" in server_name.lower():
                github_token = os.getenv("GITHUB_TOKEN")
                if not github_token:
                    logger.debug(f"[MCP][check.req] server={server_name} requires GITHUB_TOKEN but not set")
                    return False
                # env ì„¤ì •ì—ì„œë„ í™•ì¸
                env_config = server_config.get("env", {})
                if "GITHUB_PERSONAL_ACCESS_TOKEN" in env_config:
                    env_value = env_config["GITHUB_PERSONAL_ACCESS_TOKEN"]
                    # í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜ì´ ì•ˆëœ ê²½ìš° (${GITHUB_TOKEN} í˜•íƒœ)
                    if isinstance(env_value, str) and "${" in env_value and not github_token:
                        return False
            logger.debug(f"[MCP][check.req] server={server_name} stdio mode, requirements checked")
            return True
        
        # HTTP ì„œë²„ëŠ” ì„¤ì •ì— ë”°ë¼ API í‚¤ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ (ì„œë²„ë³„ë¡œ ë‹¤ë¦„)
        # ê° ì„œë²„ì˜ headers ì„¤ì •ì—ì„œ í™˜ê²½ë³€ìˆ˜ë¡œ API í‚¤ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŒ
        
        # ë‹¤ë¥¸ ì„œë²„ë“¤ì€ API í‚¤ê°€ ì—†ì–´ë„ ì‚¬ìš© ê°€ëŠ¥ (ì˜ˆ: ddg_search)
        return True
    
    def _load_mcp_servers_from_config(self):
        """MCP ì„œë²„ ì„¤ì •ì„ configì—ì„œ ë¡œë“œí•˜ê³  í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜."""
        # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        if hasattr(self, '_mcp_servers_loaded') and self._mcp_servers_loaded:
            logger.debug("[MCP][load.skip] MCP server configs already loaded, skipping")
            return

        try:
            # configs í´ë”ì—ì„œ ë¡œë“œ ì‹œë„ (ìš°ì„ )
            config_file = project_root / "configs" / "mcp_config.json"
            if not config_file.exists():
                # í•˜ìœ„ í˜¸í™˜ì„±: ë£¨íŠ¸ì—ì„œë„ ì‹œë„
                config_file = project_root / "mcp_config.json"
            
            if config_file.exists():
                with open(config_file, 'r') as f:
                    config_data = json.load(f)
                    raw_configs = config_data.get("mcpServers", {})
                    
                    # í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜
                    resolved_configs = self._resolve_env_vars_in_value(raw_configs)
                    
                    # API í‚¤ í™•ì¸ ë° í•„í„°ë§
                    filtered_configs = {}
                    for server_name, server_config in resolved_configs.items():
                        # disabled í”Œë˜ê·¸ í™•ì¸
                        if server_config.get("disabled"):
                            logger.info(f"[MCP][skip.disabled] server={server_name}")
                            continue
                        
                        # API í‚¤ê°€ í•„ìš”í•œ ì„œë²„ í™•ì¸
                        if not self._check_server_requirements(server_name, server_config):
                            logger.info(f"[MCP][skip.no-api-key] server={server_name} (API key not configured)")
                            continue
                        
                        filtered_configs[server_name] = server_config
                    
                    self.mcp_server_configs = filtered_configs
                    logger.info(f"âœ… Loaded MCP server configs: {list(self.mcp_server_configs.keys())}")
                    # ë¡œë“œ ì™„ë£Œ í”Œë˜ê·¸ ì„¤ì •
                    self._mcp_servers_loaded = True
            else:
                # ê¸°ë³¸ DuckDuckGo MCP ì„œë²„ ì„¤ì •
                self.mcp_server_configs = {
                    "ddg_search": {
                        "command": "npx",
                        "args": [
                            "-y",
                            "@modelcontextprotocol/server-duckduckgo-search@latest"
                        ]
                    }
                }
                logger.info("âœ… Using default MCP server config for ddg_search")
                # ë¡œë“œ ì™„ë£Œ í”Œë˜ê·¸ ì„¤ì •
                self._mcp_servers_loaded = True
            
            # FORCE DISABLE FLAKY SERVERS (DDG only) to use native fallbacks
            if "ddg_search" in self.mcp_server_configs:
                logger.info("ğŸš« Disabling flaky 'ddg_search' MCP server to use Native Tool fallback")
                del self.mcp_server_configs["ddg_search"]

            # tavily-mcpëŠ” ì´ì œ í™œì„±í™” (ì‚¬ìš©ìê°€ ìš”ì²­)
                
            # Ensure we don't default to them either (tavily-mcp ì œì™¸)
            keys_to_remove = [k for k in self.mcp_server_configs if k in ["ddg_search"]]
            for k in keys_to_remove:
                del self.mcp_server_configs[k]
                
        except Exception as e:
            logger.warning(f"Failed to load MCP server configs: {e}")
            self.mcp_server_configs = {}
    
    def _get_server_specific_settings(self, server_name: str, server_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê° MCP ì„œë²„ë³„ íŠ¹ì„±ì— ë§ëŠ” ì„¤ì • ë°˜í™˜.
        
        ì„œë²„ë³„ íŠ¹ì„±:
        - stdio ì„œë²„ (npx ê¸°ë°˜): í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ì‹œê°„ í•„ìš”, ë” ê¸´ íƒ€ì„ì•„ì›ƒ
        - HTTP ì„œë²„: ë¹ ë¥¸ ì—°ê²°, ì§§ì€ íƒ€ì„ì•„ì›ƒ
        - íŠ¹ì • ì„œë²„: íŠ¹ìˆ˜ ì„¤ì • ì ìš©
        """
        is_stdio = "httpUrl" not in server_config and "url" not in server_config and server_config.get("type") != "http"
        is_npx = is_stdio and "npx" in server_config.get("command", "")
        
        # ì„œë²„ë³„ ê¸°ë³¸ ì„¤ì •
        settings = {
            "timeout": 30.0,
            "max_retries": 1,
        }
        
        # npx ê¸°ë°˜ stdio ì„œë²„ëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ í•„ìš”
        if is_npx:
            settings["timeout"] = 60.0  # npx ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰ ì‹œê°„ ê³ ë ¤
        
        # íŠ¹ì • ì„œë²„ë³„ ì»¤ìŠ¤í…€ ì„¤ì • - íƒ€ì„ì•„ì›ƒë§Œ ì„¤ì • (ì´ˆê¸°í™” ì§€ì—°ì€ ì¼ê´„ ì²˜ë¦¬)
        if server_name == "exa":
            settings["timeout"] = 15.0  # HTTP ì„œë²„ëŠ” ë¹ ë¥´ì§€ë§Œ ì—¬ìœ  ì‹œê°„ í™•ë³´
        elif server_name == "semantic_scholar":
            settings["timeout"] = 20.0  # HTTP ì„œë²„ì§€ë§Œ ì¸ì¦ ì²˜ë¦¬ ì‹œê°„ í•„ìš”
        elif server_name == "context7-mcp":
            settings["timeout"] = 60.0  # Upstash ì„œë²„ëŠ” ì´ˆê¸°í™” ì‹œê°„ í•„ìš” (npx ê¸°ë°˜)
        elif server_name == "parallel-search":
            settings["timeout"] = 60.0  # npx ê¸°ë°˜ ì„œë²„
        elif server_name == "unified-search-mcp-server":
            settings["timeout"] = 60.0
        elif server_name in ["tavily-mcp", "WebSearch-MCP"]:
            settings["timeout"] = 60.0  # npx ê¸°ë°˜ ì„œë²„, API í‚¤ ê²€ì¦ ì‹œê°„ í•„ìš”
        elif server_name == "ddg_search":
            settings["timeout"] = 45.0  # npx ê¸°ë°˜ ì„œë²„ëŠ” ì´ˆê¸°í™” ì‹œê°„ í•„ìš”
        elif server_name in ["fetch", "docfork"]:
            settings["timeout"] = 60.0  # npx ê¸°ë°˜ ì„œë²„
        elif server_name == "arxiv":
            settings["timeout"] = 60.0  # npx ê¸°ë°˜ arXiv MCP ì„œë²„
        
        # HTTP ì„œë²„ëŠ” ë¹ ë¥´ì§€ë§Œ ì—¬ìœ  ì‹œê°„ í™•ë³´
        if not is_stdio:
            settings["timeout"] = max(settings["timeout"], 20.0)  # ìµœì†Œ 20ì´ˆ
        
        return settings
    
    async def _check_connection_health(self, server_name: str) -> bool:
        """
        Check if existing MCP server connection is healthy.
        
        Args:
            server_name: Server name to check
            
        Returns:
            True if connection is healthy, False otherwise
        """
        # FastMCP Client í™•ì¸
        if server_name in self.fastmcp_clients:
            try:
                fastmcp_client = self.fastmcp_clients[server_name]
                # FastMCP ClientëŠ” context managerì´ë¯€ë¡œ ê°„ë‹¨í•œ health check
                # ì‹¤ì œë¡œëŠ” ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ list_toolsë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆì§€ë§Œ, 
                # ì—¬ê¸°ì„œëŠ” í´ë¼ì´ì–¸íŠ¸ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸ (ì„±ëŠ¥ ê³ ë ¤)
                return fastmcp_client is not None
            except Exception as e:
                logger.debug(f"FastMCP connection health check failed for {server_name}: {e}")
                return False
        
        # ê¸°ì¡´ ClientSession ë°©ì‹ í™•ì¸
        if server_name not in self.mcp_sessions:
            return False
        
        try:
            session = self.mcp_sessions[server_name]
            # Try to list tools as a health check (lightweight operation)
            # This will fail if connection is broken
            if hasattr(session, 'list_tools'):
                # Quick health check - just verify session is still valid
                # We don't actually call list_tools to avoid overhead
                return True
            return True  # Assume healthy if session exists
        except Exception as e:
            logger.debug(f"Connection health check failed for {server_name}: {e}")
            return False
    
    async def _connect_to_mcp_server(self, server_name: str, server_config: Dict[str, Any], timeout: float = None):
        """MCP ì„œë²„ì— ì—°ê²° - Connection pooling with health check and auto-reconnection."""
        if self.stopping:
            logger.warning(f"[MCP][skip.stopping] server={server_name}")
            return False
        
        # Connection pooling: Check if connection already exists and is healthy
        if server_name in self.mcp_sessions:
            is_healthy = await self._check_connection_health(server_name)
            if is_healthy:
                logger.debug(f"[MCP][connect.pool] Reusing existing connection for {server_name}")
                return True
            else:
                logger.warning(f"[MCP][connect.reconnect] Connection unhealthy for {server_name}, reconnecting...")
                # Disconnect unhealthy connection
                try:
                    await self._disconnect_from_mcp_server(server_name)
                except Exception as e:
                    logger.debug(f"Error disconnecting unhealthy connection: {e}")
        
        # ì„œë²„ë³„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        server_settings = self._get_server_specific_settings(server_name, server_config)
        if timeout is None:
            timeout = server_settings["timeout"]
        
        logger.info(f"[MCP][connect.start] server={server_name} type={server_config.get('type','stdio')} url={(server_config.get('httpUrl') or server_config.get('url'))} timeout={timeout}")
        self.connection_diagnostics[server_name] = {
            "server": server_name,
            "type": ("http" if (server_config.get("httpUrl") or server_config.get("url") or server_config.get("type") == "http") else "stdio"),
            "url": server_config.get("httpUrl") or server_config.get("url"),
            "stage": "start",
            "ok": False,
            "error": None,
            "traceback": None,
            "init_ms": None,
            "list_ms": None,
        }
        if not MCP_AVAILABLE:
            logger.error("MCP package not available")
            return False
        
        try:
            
            exit_stack = AsyncExitStack()
            self.exit_stacks[server_name] = exit_stack
            
            # ì„œë²„ íƒ€ì… í™•ì¸ (stdio vs HTTP)
            server_type = server_config.get("type", "stdio")
            is_stdio = server_type == "stdio" or ("command" in server_config and "httpUrl" not in server_config and "url" not in server_config)
            
            if is_stdio:
                # stdio ì„œë²„ ì—°ê²° (í‘œì¤€ MCP ë°©ì‹ - OpenManus ìŠ¤íƒ€ì¼)
                if not MCP_AVAILABLE or ClientSession is None or StdioServerParameters is None or stdio_client is None:
                    logger.error(f"MCP package not available for stdio server {server_name}")
                    return False
                
                command = server_config.get("command")
                args = server_config.get("args", [])
                if not command:
                    logger.error(f"No command provided for stdio server {server_name}")
                    return False
                
                # í™˜ê²½ë³€ìˆ˜ ì²˜ë¦¬ (github ë“± envê°€ í•„ìš”í•œ ì„œë²„)
                env_vars = server_config.get("env", {})
                resolved_env = {}
                if env_vars:
                    for env_key, env_value in env_vars.items():
                        # í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜ (${VAR} í˜•ì‹)
                        if isinstance(env_value, str) and "${" in env_value:
                            import re
                            env_var_pattern = r'\$\{([^}]+)\}'
                            matches = re.findall(env_var_pattern, env_value)
                            resolved_value = env_value
                            for env_var in matches:
                                actual_value = os.getenv(env_var)
                                if actual_value:
                                    resolved_value = resolved_value.replace(f"${{{env_var}}}", actual_value)
                                else:
                                    logger.warning(f"[MCP][stdio.connect] server={server_name} env var {env_var} not found, keeping placeholder")
                            resolved_env[env_key] = resolved_value
                        else:
                            resolved_env[env_key] = env_value
                    
                    # í™˜ê²½ë³€ìˆ˜ê°€ ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ ì„œë²„ ìŠ¤í‚µ
                    if all(not v or (isinstance(v, str) and "${" in v) for v in resolved_env.values()):
                        logger.warning(f"[MCP][stdio.connect] server={server_name} required env vars not set, skipping")
                        self.connection_diagnostics[server_name].update({
                            "ok": False,
                            "error": "Required environment variables not set",
                            "stage": "failed"
                        })
                        return False
                
                logger.info(f"[MCP][stdio.connect] server={server_name} command={command} args={args} env={list(resolved_env.keys()) if resolved_env else 'none'}")
                
                # npm ìºì‹œ ì†ìƒ ë¬¸ì œ í•´ê²°: npx ìºì‹œ ì •ë¦¬
                if command == "npx":
                    try:
                        import shutil
                        import subprocess
                        # npx ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ ì‹œë„
                        npx_cache_dir = os.path.expanduser("~/.npm/_npx")
                        
                        # ERR_MODULE_NOT_FOUND ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°, ì†ìƒëœ ìºì‹œ ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ
                        if os.path.exists(npx_cache_dir):
                            # zod ëª¨ë“ˆ ì˜¤ë¥˜ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ì°¾ê¸°
                            for item in os.listdir(npx_cache_dir):
                                item_path = os.path.join(npx_cache_dir, item)
                                if os.path.isdir(item_path):
                                    # zod ëª¨ë“ˆì´ ì†ìƒëœ ê²½ìš° í•´ë‹¹ ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ
                                    zod_path = os.path.join(item_path, "node_modules", "zod")
                                    if os.path.exists(zod_path):
                                        # zod íŒŒì¼ë“¤ì´ ì—†ëŠ” ê²½ìš° (TAR_ENTRY_ERROR)
                                        zod_external = os.path.join(zod_path, "v3", "external.js")
                                        if not os.path.exists(zod_external):
                                            # ì†ìƒëœ íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ
                                            try:
                                                shutil.rmtree(item_path, ignore_errors=True)
                                                logger.info(f"[MCP][stdio.connect] Cleaned corrupted npx cache directory: {item}")
                                            except Exception as e:
                                                logger.debug(f"[MCP][stdio.connect] Failed to remove cache dir {item}: {e}")
                    except Exception as e:
                        logger.debug(f"[MCP][stdio.connect] Failed to clean npm cache: {e}")
                
                try:
                    # í‘œì¤€ MCP ë°©ì‹ìœ¼ë¡œ ì—°ê²° (OpenManus ìŠ¤íƒ€ì¼)
                    # StdioServerParametersì— env ì „ë‹¬
                    server_params = StdioServerParameters(
                        command=command,
                        args=args,
                        env=resolved_env if resolved_env else None
                    )
                    
                    # AsyncExitStackìœ¼ë¡œ ì—°ê²° ìœ ì§€ (OpenManus ë°©ì‹)
                    stdio_transport = await exit_stack.enter_async_context(
                        stdio_client(server_params)
                    )
                    read, write = stdio_transport
                    session = await exit_stack.enter_async_context(ClientSession(read, write))
                    
                    # ì„¸ì…˜ ì´ˆê¸°í™” ë° ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    if self.stopping:
                        raise asyncio.CancelledError("Stopping flag is set, skipping initialize")
                    
                    await session.initialize()
                    response = await asyncio.wait_for(session.list_tools(), timeout=timeout)
                    
                    # ë„êµ¬ ë“±ë¡
                    for tool in response.tools:
                        # register_mcp_tool ì‚¬ìš©
                        self.registry.register_mcp_tool(server_name, tool, tool)
                        
                        if server_name not in self.mcp_tools_map:
                            self.mcp_tools_map[server_name] = {}
                        # MCPToolInfo ìƒì„± (ìë™ ë°œê²¬ìš©)
                        tool_info = MCPToolInfo(
                            server_guess=server_name,
                            name=f"{server_name}::{tool.name}",
                            description=tool.description or "",
                            input_schema=tool.inputSchema if hasattr(tool, 'inputSchema') else {}
                        )
                        self.mcp_tools_map[server_name][tool.name] = tool_info
                    
                    # ì„¸ì…˜ ì €ì¥ (ì—°ê²° ìœ ì§€)
                    self.mcp_sessions[server_name] = session
                    
                    logger.info(f"[MCP][stdio.connect] âœ… Connected to {server_name}, tools: {len(response.tools)}")
                    
                    self.connection_diagnostics[server_name].update({
                        "ok": True,
                        "stage": "connected",
                        "tools_count": len(response.tools)
                    })
                    
                    return True
                except asyncio.CancelledError:
                    logger.debug(f"[MCP][stdio.connect] Connection cancelled for {server_name}")
                    raise
                except Exception as e:
                        error_str = str(e).lower()
                        error_msg = str(e)
                        
                        # npm 404 ì—ëŸ¬ëŠ” íŒ¨í‚¤ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¬ì‹œë„ ë¶ˆí•„ìš”
                        is_npm_404 = "404" in error_str and ("npm" in error_str or "not found" in error_str or "not in this registry" in error_str)
                        
                        # npm ì˜¤ë¥˜ ê°ì§€
                        is_npm_enotempty = "enotempty" in error_str or ("npm error" in error_str and "directory not empty" in error_str)
                        is_npm_tar_error = "tar_entry_error" in error_str or ("enoent" in error_str and "zod" in error_str)
                        is_module_not_found = "err_module_not_found" in error_str or ("cannot find module" in error_str and "zod" in error_str)
                        
                        # Connection closed ì˜¤ë¥˜ëŠ” ì„œë²„ ì—°ê²° ì‹¤íŒ¨
                        is_connection_closed = "connection closed" in error_str or "client failed to connect" in error_str
                        
                        # npm ìºì‹œ ì†ìƒ ì˜¤ë¥˜ í•´ê²°: ìºì‹œ ì •ë¦¬ í›„ ì¬ì‹œë„
                        if (is_npm_enotempty or is_npm_tar_error or is_module_not_found) and command == "npx":
                            try:
                                import shutil
                                import subprocess
                                # npm cache clean --force ì‹¤í–‰
                                try:
                                    subprocess.run(
                                        ["npm", "cache", "clean", "--force"],
                                        capture_output=True,
                                        timeout=10,
                                        check=False
                                    )
                                except Exception:
                                    pass
                                
                                # npx ìºì‹œ ë””ë ‰í† ë¦¬ ì „ì²´ ì •ë¦¬ ì‹œë„
                                npx_cache_dir = os.path.expanduser("~/.npm/_npx")
                                if os.path.exists(npx_cache_dir):
                                    # ì†ìƒëœ íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ì°¾ê¸° ë° ì‚­ì œ
                                    for item in os.listdir(npx_cache_dir):
                                        item_path = os.path.join(npx_cache_dir, item)
                                        if os.path.isdir(item_path):
                                            try:
                                                # zod ëª¨ë“ˆì´ ì†ìƒëœ ê²½ìš° í•´ë‹¹ ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ
                                                zod_path = os.path.join(item_path, "node_modules", "zod")
                                                if os.path.exists(zod_path):
                                                    # zod íŒŒì¼ë“¤ì´ ì—†ëŠ” ê²½ìš° (TAR_ENTRY_ERROR ë˜ëŠ” MODULE_NOT_FOUND)
                                                    zod_external = os.path.join(zod_path, "v3", "external.js")
                                                    if not os.path.exists(zod_external):
                                                        # ì†ìƒëœ íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ì „ì²´ ì‚­ì œ
                                                        shutil.rmtree(item_path, ignore_errors=True)
                                                        logger.info(f"[MCP][stdio.connect] Cleaned corrupted npx cache directory: {item}")
                                            except Exception:
                                                pass
                                    
                                    # ì¬ì‹œë„ (í•œ ë²ˆë§Œ) - í‘œì¤€ MCP ë°©ì‹ìœ¼ë¡œ
                                    logger.info(f"[MCP][stdio.connect] Retrying connection to {server_name} after npm cache cleanup...")
                                    try:
                                        # í‘œì¤€ MCP ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
                                        retry_server_params = StdioServerParameters(
                                            command=command,
                                            args=args,
                                            env=resolved_env if resolved_env else None
                                        )
                                        
                                        retry_stdio_transport = await exit_stack.enter_async_context(
                                            stdio_client(retry_server_params)
                                        )
                                        retry_read, retry_write = retry_stdio_transport
                                        retry_session = await exit_stack.enter_async_context(ClientSession(retry_read, retry_write))
                                        
                                        await retry_session.initialize()
                                        retry_response = await asyncio.wait_for(retry_session.list_tools(), timeout=timeout)
                                        
                                        # ë„êµ¬ ë“±ë¡
                                        for tool in retry_response.tools:
                                            self.registry.register_mcp_tool(server_name, tool, tool)
                                            if server_name not in self.mcp_tools_map:
                                                self.mcp_tools_map[server_name] = {}
                                            tool_info = MCPToolInfo(
                                                server_guess=server_name,
                                                name=f"{server_name}::{tool.name}",
                                                description=tool.description or "",
                                                input_schema=tool.inputSchema if hasattr(tool, 'inputSchema') else {}
                                            )
                                            self.mcp_tools_map[server_name][tool.name] = tool_info
                                        
                                        # ì„¸ì…˜ ì €ì¥
                                        self.mcp_sessions[server_name] = retry_session
                                        
                                        logger.info(f"[MCP][stdio.connect] âœ… Connected to {server_name} after cache cleanup, tools: {len(retry_response.tools)}")
                                        self.connection_diagnostics[server_name].update({
                                            "ok": True,
                                            "stage": "connected",
                                            "tools_count": len(retry_response.tools)
                                        })
                                        return True
                                    except Exception as retry_e:
                                        logger.warning(f"[MCP][stdio.connect] Retry failed for {server_name}: {retry_e}")
                            except Exception as cleanup_e:
                                logger.debug(f"[MCP][stdio.connect] Cache cleanup failed: {cleanup_e}")
                        
                        # ì¡°ìš©íˆ ì²˜ë¦¬í•  ì˜¤ë¥˜ë“¤ (WARNING ë ˆë²¨ë¡œë§Œ ë¡œê¹…)
                        if is_npm_404:
                            logger.warning(f"[MCP][stdio.connect] Package not found for {server_name} (npm 404), skipping")
                        elif is_connection_closed:
                            logger.warning(f"[MCP][stdio.connect] Connection closed for {server_name}, skipping")
                        else:
                            # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” WARNING ë ˆë²¨ë¡œ ë¡œê¹…
                            logger.warning(f"[MCP][stdio.connect] Failed to connect to {server_name}: {error_msg[:200]}")
                        
                        self.connection_diagnostics[server_name].update({
                            "ok": False,
                            "error": error_msg[:200],  # ê¸´ ì—ëŸ¬ ë©”ì‹œì§€ ìë¥´ê¸°
                            "stage": "failed",
                            "is_npm_404": is_npm_404,
                            "is_npm_enotempty": is_npm_enotempty,
                            "is_connection_closed": is_connection_closed
                        })
                        
                        # npm 404, Connection closedëŠ” ì¬ì‹œë„ ë¶ˆí•„ìš”
                        if is_npm_404 or is_connection_closed:
                            return False
                        
                        return False
                        
                except Exception as e:
                    logger.error(f"[MCP][stdio.connect] Error setting up stdio connection for {server_name}: {e}", exc_info=True)
                    self.connection_diagnostics[server_name].update({
                        "ok": False,
                        "error": str(e),
                        "stage": "failed"
                    })
                    return False
            else:
                # HTTP ì„œë²„ ì—°ê²° (ê¸°ì¡´ ë¡œì§)
                # FastMCP ê¸°ë°˜ ì—°ê²° (ëª¨ë“  ì„œë²„ë¥¼ HTTPë¡œ ì²˜ë¦¬)
                if not FASTMCP_AVAILABLE or FastMCPClient is None:
                    logger.error(f"FastMCP client not available for server {server_name}")
                    return False
                
                # ì„œë²„ ì„¤ì •ì„ FastMCP í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                base_url = server_config.get("httpUrl") or server_config.get("url")
                if not base_url:
                    logger.error(f"No URL provided for MCP server {server_name}")
                    return False
            
            # Headers êµ¬ì„± (í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜ í¬í•¨)
            headers = server_config.get("headers", {}).copy()
            
            # í™˜ê²½ ë³€ìˆ˜ ì¹˜í™˜ (${VAR} í˜•ì‹) - Bearer ${API_KEY} ê°™ì€ í˜•ì‹ ì§€ì›
            resolved_headers = {}
            for k, v in headers.items():
                if isinstance(v, str):
                    # ${VAR} í˜•ì‹ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì „ì²´ ê°’ì´ ${VAR}ì´ê±°ë‚˜ Bearer ${VAR} ê°™ì€ í˜•ì‹)
                    import re
                    env_var_pattern = r'\$\{([^}]+)\}'
                    matches = re.findall(env_var_pattern, v)
                    if matches:
                        resolved_value = v
                        for env_var in matches:
                            env_value = os.getenv(env_var, "")
                            if env_value:
                                # ${VAR}ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜
                                resolved_value = resolved_value.replace(f"${{{env_var}}}", env_value)
                                logger.debug(f"[MCP][auth.env] server={server_name} Resolved {k} from {env_var}")
                            else:
                                logger.warning(f"[MCP][auth.env] server={server_name} {env_var} not found in environment")
                        resolved_headers[k] = resolved_value
                    else:
                        resolved_headers[k] = v
                else:
                    resolved_headers[k] = v
            
            # Authorization í—¤ë”ëŠ” ì„œë²„ ì„¤ì •ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•¨
            # í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜ì„ í†µí•´ ê° ì„œë²„ë³„ API í‚¤ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŒ
            
            # FastMCP ì„¤ì • êµ¬ì„±
            # FastMCPëŠ” httpUrlì´ ì•„ë‹ˆë¼ urlì„ ê¸°ëŒ€í•¨
            # FastMCPëŠ” headersë¥¼ ì§€ì›í•˜ë¯€ë¡œ Authorization í—¤ë”ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
            server_config_dict = {
                "url": base_url
            }
            
            # headersê°€ ìˆìœ¼ë©´ ì¶”ê°€ (FastMCPëŠ” headersë¥¼ ì§€ì›í•¨)
            if resolved_headers:
                server_config_dict["headers"] = resolved_headers
            
            mcp_config = {
                "mcpServers": {
                    server_name: server_config_dict
                }
            }
            
            
            logger.info(f"[MCP][fastmcp.connect] server={server_name} url={base_url} headers={list(resolved_headers.keys()) if resolved_headers else 'None'}")
            
            try:
                # FastMCP Client ì§ì ‘ ì‚¬ìš© (ê°€ì´ë“œì— ë”°ë¥¸ ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•)
                # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                if server_name in self.fastmcp_clients:
                    fastmcp_client = self.fastmcp_clients[server_name]
                    logger.debug(f"[MCP][fastmcp.reuse] server={server_name} Reusing existing FastMCP client")
                else:
                    # FastMCP Client ìƒì„±
                    fastmcp_client = FastMCPClient(mcp_config)
                    self.fastmcp_clients[server_name] = fastmcp_client
                    logger.debug(f"[MCP][fastmcp.create] server={server_name} Created new FastMCP client")
                
                # FastMCP Clientë¥¼ Context Managerë¡œ ì‚¬ìš© (ê°€ì´ë“œì— ë”°ë¥¸ ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•)
                try:
                    # stopping í”Œë˜ê·¸ ì¬í™•ì¸
                    if self.stopping:
                        logger.warning(f"[MCP][skip.stopping] server={server_name} stopping flag is set")
                        raise asyncio.CancelledError("Stopping flag is set")
                    
                    # Context Managerë¡œ ì‚¬ìš©í•˜ì—¬ ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                    async with fastmcp_client:
                        # stopping í”Œë˜ê·¸ ì²´í¬
                        if self.stopping:
                            logger.info(f"[MCP][skip.stopping] server={server_name} stopping flag is set, skipping connection")
                            raise asyncio.CancelledError("Stopping flag is set")
                        
                        # ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì„¤ì •, shield ì œê±°í•˜ì—¬ ì·¨ì†Œ ê°€ëŠ¥)
                        try:
                            tools = await asyncio.wait_for(
                                fastmcp_client.list_tools(),
                                timeout=timeout
                            )
                        except asyncio.TimeoutError:
                            logger.warning(f"[MCP][list_tools.timeout] server={server_name} list_tools timeout after {timeout}s")
                            raise
                        except asyncio.CancelledError as e:
                            if self.stopping:
                                logger.info(f"[MCP][list_tools.cancelled] server={server_name} cancelled due to stopping flag")
                                raise
                            else:
                                logger.warning(f"[MCP][list_tools.cancelled] server={server_name} list_tools was cancelled unexpectedly")
                                raise
                    
                    # ë„êµ¬ ì •ë³´ ì €ì¥
                    tools_dict = {}
                    if tools:
                        for tool in tools:
                            tools_dict[tool.name] = {
                                "name": tool.name,
                                "description": getattr(tool, "description", "") or "",
                                "inputSchema": getattr(tool, "inputSchema", {}) or {}
                            }
                    
                    self.mcp_tools_map[server_name] = tools_dict
                    logger.info(f"[MCP][fastmcp.success] server={server_name} Connected, {len(tools_dict)} tools available")
                    
                    # ì—°ê²° ì§„ë‹¨ ì •ë³´ ì—…ë°ì´íŠ¸
                    di = self.connection_diagnostics.get(server_name, {})
                    di.update({
                        "ok": True,
                        "tools_count": len(tools_dict),
                        "client_type": "FastMCP"
                    })
                    self.connection_diagnostics[server_name] = di
                    
                    # FastMCP Client ì¸ìŠ¤í„´ìŠ¤ ì €ì¥ (ë‚˜ì¤‘ì— ë„êµ¬ í˜¸ì¶œ ì‹œ ì‚¬ìš©)
                    # ì£¼ì˜: FastMCP ClientëŠ” context managerì´ë¯€ë¡œ, ë„êµ¬ í˜¸ì¶œ ì‹œë§ˆë‹¤ async withë¡œ ì‚¬ìš©í•´ì•¼ í•¨
                    # ì„¸ì…˜ì€ ì €ì¥í•˜ì§€ ì•Šê³  í´ë¼ì´ì–¸íŠ¸ë§Œ ì €ì¥
                    self.mcp_sessions[server_name] = fastmcp_client  # FastMCP Client ì €ì¥
                    
                    return True
                    
                except Exception as fastmcp_error:
                    error_msg = str(fastmcp_error)
                    error_type = type(fastmcp_error).__name__
                    logger.error(f"[MCP][fastmcp.error] server={server_name} err={error_type}: {error_msg}")
                    logger.exception(f"[MCP][fastmcp.error] server={server_name} full traceback:")
                    
                    # ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë¼ì´ì–¸íŠ¸ ì œê±°
                    if server_name in self.fastmcp_clients:
                        del self.fastmcp_clients[server_name]
                    
                    di = self.connection_diagnostics.get(server_name, {})
                    di.update({
                        "stage": "fastmcp_connect",
                        "error": error_msg,
                        "error_type": error_type,
                        "ok": False
                    })
                    self.connection_diagnostics[server_name] = di
                    return False
                    
            except Exception as e:
                error_msg = str(e)
                error_type = type(e).__name__
                logger.error(f"[MCP][fastmcp.error] server={server_name} err={error_type}: {error_msg}")
                logger.exception(f"[MCP][fastmcp.error] server={server_name} full traceback:")
                di = self.connection_diagnostics.get(server_name, {})
                di.update({"stage": "fastmcp_connect", "error": error_msg, "error_type": error_type})
                self.connection_diagnostics[server_name] = di
                if server_name in self.fastmcp_configs:
                    del self.fastmcp_configs[server_name]
                return False
            
            # ë„êµ¬ ë§µ ìƒì„± ë° Registryì— ë™ì  ë“±ë¡
            self.mcp_tools_map[server_name] = {}
            for tool in response.tools:
                self.mcp_tools_map[server_name][tool.name] = tool
                # ToolRegistryì— server_name::tool_name í˜•ì‹ìœ¼ë¡œ ë“±ë¡
                self.registry.register_mcp_tool(server_name, tool.name, tool)
                logger.debug(f"[MCP][register] {server_name}::{tool.name}")
            
            # Registry toolsë¥¼ self.toolsì— ë™ê¸°í™”
            self.tools.update(self.registry.tools)
            
            tool_names = [t for t in self.mcp_tools_map.get(server_name, {}).keys()]
            if 't1' in locals() and 't2' in locals():
                logger.info(f"[MCP][connect.ok] server={server_name} init_ms={(t1-t0)*1000:.0f} list_ms={(t2-t1)*1000:.0f} tools={tool_names}")
            else:
                logger.info(f"[MCP][connect.ok] server={server_name} tools={tool_names}")
            logger.info(f"âœ… Connected to MCP server {server_name} with {len(response.tools)} tools")
            return True
            
        except asyncio.CancelledError:
            # ì‘ì—…ì´ ì·¨ì†Œëœ ê²½ìš° (ì¢…ë£Œ ì‹ í˜¸ ë“±) - ì •ìƒì ì¸ ë™ì‘
            logger.info(f"[MCP][connect.cancelled] server={server_name} stage=generic (shutdown in progress)")
            try:
                await self._disconnect_from_mcp_server(server_name)
            except Exception:
                pass  # cleanup ì¤‘ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
            return False  # raiseí•˜ì§€ ì•Šê³  False ë°˜í™˜í•˜ì—¬ ë‹¤ë¥¸ ì„œë²„ ì—°ê²° ê³„ì† ì§„í–‰
        except asyncio.TimeoutError:
            logger.error(f"[MCP][connect.timeout] server={server_name} stage=generic")
            di = self.connection_diagnostics.get(server_name, {})
            di.update({"stage": "timeout_generic", "error": f"timeout_{timeout}s"})
            self.connection_diagnostics[server_name] = di
            # íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ exit_stack ì°¸ì¡°ë§Œ ì œê±° (aclose() í˜¸ì¶œí•˜ì§€ ì•ŠìŒ - anyio ì˜¤ë¥˜ ë°©ì§€)
            if server_name in self.exit_stacks:
                del self.exit_stacks[server_name]
            await self._disconnect_from_mcp_server(server_name)
            return False
        except Exception as e:
            logger.exception(f"[MCP][connect.error] server={server_name} err={e}")
            import traceback
            logger.debug(f"Traceback: {traceback.format_exc()}")
            di = self.connection_diagnostics.get(server_name, {})
            di.update({"stage": "exception", "error": str(e), "traceback": traceback.format_exc()})
            self.connection_diagnostics[server_name] = di
            # ì‹¤íŒ¨ ì‹œ exit_stack ì°¸ì¡°ë§Œ ì œê±° (aclose() í˜¸ì¶œí•˜ì§€ ì•ŠìŒ - anyio ì˜¤ë¥˜ ë°©ì§€)
            if server_name in self.exit_stacks:
                del self.exit_stacks[server_name]
            try:
                await self._disconnect_from_mcp_server(server_name)
            except:
                pass
            return False
    
    async def _register_dynamic_server(
        self,
        server_name: str,
        server_path: Path
    ) -> bool:
        """
        ë™ì ìœ¼ë¡œ ìƒì„±ëœ MCP ì„œë²„ë¥¼ ë“±ë¡í•˜ê³  ì‹œì‘.
        
        Args:
            server_name: ì„œë²„ ì´ë¦„
            server_path: ì„œë²„ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë“±ë¡ ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info(f"[MCP][builder.register] Registering dynamic server: {server_name}")
            
            # ì„œë²„ ì„¤ì • ìƒì„± (stdio ë°©ì‹)
            server_config = {
                "type": "stdio",
                "command": "python",
                "args": [str(server_path)]
            }
            
            # mcp_server_configsì— ì¶”ê°€
            self.mcp_server_configs[server_name] = server_config
            
            # mcp_config.jsonì—ë„ ì¶”ê°€ (ì„ íƒì , ì˜êµ¬ ì €ì¥)
            try:
                config_file = project_root / "configs" / "mcp_config.json"
                if config_file.exists():
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_data = json.load(f)
                    
                    if "mcpServers" not in config_data:
                        config_data["mcpServers"] = {}
                    
                    # ë™ì  ì„œë²„ ì¶”ê°€ (ê¸°ì¡´ ì„œë²„ì™€ ì¶©ëŒ ë°©ì§€)
                    if server_name not in config_data["mcpServers"]:
                        config_data["mcpServers"][server_name] = server_config
                        
                        # ë°±ì—… í›„ ì €ì¥
                        backup_file = config_file.with_suffix('.json.bak')
                        if not backup_file.exists():
                            import shutil
                            shutil.copy2(config_file, backup_file)
                        
                        with open(config_file, 'w', encoding='utf-8') as f:
                            json.dump(config_data, f, indent=2, ensure_ascii=False)
                        logger.debug(f"[MCP][builder.register] Added {server_name} to mcp_config.json")
            except Exception as config_error:
                logger.warning(f"[MCP][builder.register] Failed to update mcp_config.json: {config_error}")
                # ê³„ì† ì§„í–‰ (ë©”ëª¨ë¦¬ì—ëŠ” ë“±ë¡ë¨)
            
            # ì„œë²„ ì—°ê²° ì‹œë„
            connected = await self._connect_to_mcp_server(server_name, server_config, timeout=30.0)
            
            if connected:
                logger.info(f"[MCP][builder.register] âœ… Dynamic server registered and connected: {server_name}")
                
                # ProcessManagerì— ë“±ë¡ (ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì¶”ì )
                try:
                    from src.core.process_manager import get_process_manager
                    pm = get_process_manager()
                    # ì„œë²„ í”„ë¡œì„¸ìŠ¤ëŠ” _connect_to_mcp_serverì—ì„œ ì‹œì‘ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¡œê¹…ë§Œ
                    logger.debug(f"[MCP][builder.register] Server {server_name} process will be tracked by ProcessManager")
                except Exception as pm_error:
                    logger.debug(f"[MCP][builder.register] ProcessManager registration skipped: {pm_error}")
                
                return True
            else:
                logger.error(f"[MCP][builder.register] âŒ Failed to connect to dynamic server: {server_name}")
                # ë“±ë¡ì€ í–ˆì§€ë§Œ ì—°ê²° ì‹¤íŒ¨ - ì„¤ì •ì€ ìœ ì§€ (ì¬ì‹œë„ ê°€ëŠ¥)
                return False
                
        except Exception as e:
            logger.error(f"[MCP][builder.register] Failed to register dynamic server {server_name}: {e}", exc_info=True)
            return False
    
    async def _disconnect_from_mcp_server(self, server_name: str):
        """MCP ì„œë²„ ì—°ê²° í•´ì œ - ì•ˆì „í•œ ë¹„ë™ê¸° ì •ë¦¬."""
        try:
            # FastMCP Client ì •ë¦¬
            if server_name in self.fastmcp_clients:
                try:
                    fastmcp_client = self.fastmcp_clients[server_name]
                    # FastMCP Client ëª…ì‹œì  ì¢…ë£Œ ì‹œë„
                    if hasattr(fastmcp_client, 'close'):
                        try:
                            await asyncio.wait_for(fastmcp_client.close(), timeout=0.5)
                        except (asyncio.TimeoutError, Exception) as e:
                            logger.debug(f"FastMCP client close timeout/error for {server_name}: {e}")
                    elif hasattr(fastmcp_client, '__aexit__'):
                        # Context managerì˜ __aexit__ í˜¸ì¶œ ì‹œë„
                        try:
                            await asyncio.wait_for(fastmcp_client.__aexit__(None, None, None), timeout=0.5)
                        except (asyncio.TimeoutError, Exception) as e:
                            logger.debug(f"FastMCP client __aexit__ timeout/error for {server_name}: {e}")
                    # ì°¸ì¡° ì œê±°
                    del self.fastmcp_clients[server_name]
                    logger.debug(f"Removed FastMCP client for {server_name}")
                except Exception as e:
                    logger.debug(f"Error removing FastMCP client for {server_name}: {e}")
                    # ì˜¤ë¥˜ê°€ ìˆì–´ë„ ì°¸ì¡°ëŠ” ì œê±°
                    if server_name in self.fastmcp_clients:
                        del self.fastmcp_clients[server_name]
            
            # ì„¸ì…˜ ë¨¼ì € ì œê±° ë° ì¢…ë£Œ (heartbeat ë¬´í•œ ë£¨í”„ ë°©ì§€)
            if server_name in self.mcp_sessions:
                session = self.mcp_sessions[server_name]
                # FastMCP Clientì¸ ê²½ìš° context managerì´ë¯€ë¡œ ëª…ì‹œì  shutdown ë¶ˆí•„ìš”
                is_fastmcp_client = session and FASTMCP_AVAILABLE and isinstance(session, FastMCPClient)
                if not is_fastmcp_client:
                    # ê¸°ì¡´ ClientSession ë°©ì‹
                    try:
                        # ì„¸ì…˜ ì¢…ë£Œ ì‹œë„ (ì•ˆì „í•˜ê²Œ) - heartbeat ì¤‘ì§€
                        if hasattr(session, 'shutdown'):
                            await asyncio.wait_for(session.shutdown(), timeout=1.0)
                        elif hasattr(session, 'close'):
                            await asyncio.wait_for(session.close(), timeout=1.0)
                    except (asyncio.TimeoutError, AttributeError, Exception) as e:
                        logger.debug(f"Session shutdown timeout/error for {server_name}: {e}")
                        # íƒ€ì„ì•„ì›ƒì´ì–´ë„ ì„¸ì…˜ì€ ì œê±° (heartbeat ì¤‘ì§€)
                # ì„¸ì…˜ ì œê±° (heartbeat ë¬´í•œ ë£¨í”„ ë°©ì§€)
                del self.mcp_sessions[server_name]
            
            # Exit stack ì •ë¦¬: aclose() í˜¸ì¶œí•˜ì§€ ì•ŠìŒ (anyio cancel scope ì˜¤ë¥˜ ë°©ì§€)
            # ì°¸ì¡°ë§Œ ì œê±° - ì»¨í…ìŠ¤íŠ¸ëŠ” ì›ë˜ íƒœìŠ¤í¬ì—ì„œ ì •ë¦¬ë¨
            if server_name in self.exit_stacks:
                del self.exit_stacks[server_name]
            
            if server_name in self.mcp_tools_map:
                del self.mcp_tools_map[server_name]
            
            logger.debug(f"Disconnected from MCP server: {server_name}")
            
        except Exception as e:
            logger.debug(f"Error disconnecting from MCP server {server_name}: {e}")
            # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì„¸ì…˜/í´ë¼ì´ì–¸íŠ¸ëŠ” ì œê±° ì‹œë„ (heartbeat ë¬´í•œ ë£¨í”„ ë°©ì§€)
            if server_name in self.mcp_sessions:
                try:
                    del self.mcp_sessions[server_name]
                except:
                    pass
            if server_name in self.fastmcp_clients:
                try:
                    del self.fastmcp_clients[server_name]
                except:
                    pass
    
    async def initialize_mcp(self):
        """MCP ì´ˆê¸°í™” - OpenRouterì™€ MCP ì„œë²„ ì—°ê²°."""
        if not self.config.enabled:
            logger.warning("MCP is disabled. Continuing with limited functionality.")
            return
        if self.stopping:
            logger.warning("MCP initialization requested during stopping state; skipping")
            return
        
        # ERA ì„œë²„ ì‹œì‘ (ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•´)
        if self.era_server_manager:
            try:
                if await self.era_server_manager.ensure_server_running():
                    logger.info("âœ… ERA server is running (safe code execution enabled)")
                else:
                    logger.warning("âš ï¸ ERA server is not available (code execution will use fallback)")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to start ERA server: {e} (code execution will use fallback)")
        
        try:
            logger.info("Initializing MCP Hub with MCP servers (no OpenRouter)...")
            
            # ì¼ê´„ ì´ˆê¸°í™” ëŒ€ê¸° ì‹œê°„ (agent ì‹œì‘ ì´ˆê¸°ì— ëª¨ë“  ì„œë²„ ì¤€ë¹„ ì‹œê°„ í™•ë³´)
            batch_init_delay = float(os.getenv("MCP_BATCH_INIT_DELAY", "3.0"))  # ê¸°ë³¸ 3ì´ˆ
            if batch_init_delay > 0:
                logger.info(f"[MCP][init.batch] Waiting {batch_init_delay}s for batch initialization before connecting servers...")
                await asyncio.sleep(batch_init_delay)
            
            # MCP ì„œë²„ ì—°ê²° (ëª¨ë“  ì„œë²„) - ë³‘ë ¬ + íƒ€ì„ì•„ì›ƒ ì ìš©
            timeout_per_server = float(os.getenv("MCP_CONNECT_TIMEOUT", "60"))  # ì„œë²„ë‹¹ ìµœëŒ€ 60ì´ˆ(í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì •, npx ì„œë²„ ê³ ë ¤)
            max_concurrency = int(os.getenv("MCP_MAX_CONCURRENCY", "3"))  # ë™ì‹œ ì—°ê²° ìˆ˜ ì œí•œ (ê¸°ë³¸ 3ê°œ)
            semaphore = asyncio.Semaphore(max_concurrency)
            logger.info(f"[MCP][init] max_concurrency={max_concurrency}, timeout_per_server={timeout_per_server}s")


            # disabled=true ì„¤ì •ëœ ì„œë²„ëŠ” ê±´ë„ˆë›°ê¸° + í—ˆìš© ì„œë²„ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš©
            allowlist_str = os.getenv("MCP_ALLOWED_SERVERS", "").strip()
            allowlist = [s.strip() for s in allowlist_str.split(",") if s.strip()]
            base_items = [(n, c) for n, c in self.mcp_server_configs.items() if not c.get("disabled")]
            if allowlist:
                # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë§Œ ì—°ê²°
                enabled_server_items = [(n, c) for n, c in base_items if n in allowlist]
                logger.info(f"[MCP][allowlist] enabled={ [n for n,_ in enabled_server_items] }")
            else:
                # í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ disabledê°€ ì•„ë‹Œ ëª¨ë“  ì„œë²„ ì—°ê²° ì‹œë„
                enabled_server_items = base_items
                logger.info(f"[MCP][allowlist] not set; connecting to all enabled servers: { [n for n,_ in enabled_server_items] }")

            # ì„œë²„ë³„ íƒ€ì„ì•„ì›ƒ ì„¤ì • ì ìš© (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            async def connect_one_with_settings(name: str, cfg: Dict[str, Any]) -> tuple[str, bool]:
                try:
                    # stopping í”Œë˜ê·¸ ì²´í¬
                    if self.stopping:
                        logger.info(f"[MCP][skip.stopping] server={name} stopping flag is set")
                        return name, False
                    
                    async with semaphore:
                        # semaphore íšë“ í›„ ë‹¤ì‹œ ì²´í¬
                        if self.stopping:
                            logger.info(f"[MCP][skip.stopping] server={name} stopping flag is set after semaphore")
                            return name, False
                        
                        if cfg.get("disabled"):
                            logger.warning(f"[MCP][skip.disabled] server={name}")
                            return name, False
                        
                        # ì„œë²„ë³„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
                        server_settings = self._get_server_specific_settings(name, cfg)
                        server_timeout = server_settings["timeout"]
                        
                        # ì¬ì‹œë„ ë¡œì§: íƒ€ì„ì•„ì›ƒì´ë‚˜ ì¼ì‹œì  ì—ëŸ¬ëŠ” ì¬ì‹œë„
                        max_connection_retries = 3
                        connection_success = False
                        
                        for retry_attempt in range(max_connection_retries):
                            # ì¬ì‹œë„ ì „ stopping í”Œë˜ê·¸ ì²´í¬
                            if self.stopping:
                                logger.info(f"[MCP][skip.stopping] server={name} stopping flag is set before retry {retry_attempt + 1}")
                                return name, False
                            
                            try:
                                logger.info(f"Connecting to MCP server {name} (timeout: {server_timeout}s, attempt {retry_attempt + 1}/{max_connection_retries})...")
                                # stopping í”Œë˜ê·¸ ì²´í¬
                                if self.stopping:
                                    logger.info(f"[MCP][skip.stopping] server={name} stopping flag is set, skipping connection")
                                    return name, False
                                # shield ì œê±°í•˜ì—¬ ì·¨ì†Œ ê°€ëŠ¥í•˜ë„ë¡ (stopping í”Œë˜ê·¸ë¡œ ì œì–´)
                                ok = await self._connect_to_mcp_server(name, cfg, timeout=server_timeout)
                                if ok:
                                    connection_success = True
                                    if retry_attempt > 0:
                                        logger.info(f"[MCP][init.success] server={name} connected after {retry_attempt + 1} attempts")
                                    break
                                else:
                                    # ì—°ê²° ì‹¤íŒ¨
                                    if retry_attempt < max_connection_retries - 1:
                                        wait_time = 2 ** retry_attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ
                                        logger.warning(f"[MCP][init.retry] server={name} connection failed (attempt {retry_attempt + 1}/{max_connection_retries}), retrying in {wait_time}s...")
                                        await asyncio.sleep(wait_time)
                                        continue
                                    else:
                                        logger.warning(f"[MCP][init.failed] server={name} failed after {max_connection_retries} attempts")
                                        break
                                        
                            except asyncio.TimeoutError:
                                # íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ê°€ëŠ¥
                                if retry_attempt < max_connection_retries - 1:
                                    wait_time = 2 ** retry_attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ
                                    logger.warning(f"[MCP][init.timeout] server={name} timeout (attempt {retry_attempt + 1}/{max_connection_retries}), retrying in {wait_time}s...")
                                    await asyncio.sleep(wait_time)
                                    continue
                                else:
                                    logger.warning(f"[MCP][init.timeout] server={name} timeout after {max_connection_retries} attempts")
                                    break
                                    
                            except Exception as e:
                                error_str = str(e).lower()
                                error_msg = str(e)
                                
                                # npm 404 ì—ëŸ¬ëŠ” íŒ¨í‚¤ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¬ì‹œë„ ë¶ˆí•„ìš”
                                is_npm_404 = "404" in error_str and ("npm" in error_str or "not found" in error_str or "not in this registry" in error_str or "package not found" in error_str)
                                
                                # npm ENOTEMPTY ì˜¤ë¥˜ëŠ” ë””ë ‰í† ë¦¬ ê´€ë ¨ ë¬¸ì œë¡œ, ì¬ì‹œë„ ë¶ˆí•„ìš”
                                is_npm_enotempty = "enotempty" in error_str or ("npm error" in error_str and "directory not empty" in error_str)
                                
                                # Connection closed ì˜¤ë¥˜ëŠ” ì„œë²„ ì—°ê²° ì‹¤íŒ¨ë¡œ, ì¬ì‹œë„ ë¶ˆí•„ìš”
                                is_connection_closed = "connection closed" in error_str or "client failed to connect" in error_str
                                
                                # ì¡°ìš©íˆ ì²˜ë¦¬í•  ì˜¤ë¥˜ë“¤ (ì¬ì‹œë„ ë¶ˆí•„ìš”)
                                if is_npm_404:
                                    logger.warning(f"[MCP][init.skip] server={name} package not found (npm 404), skipping")
                                    break
                                elif is_npm_enotempty:
                                    logger.warning(f"[MCP][init.skip] server={name} npm directory issue (ENOTEMPTY), skipping")
                                    break
                                elif is_connection_closed:
                                    logger.warning(f"[MCP][init.skip] server={name} connection closed, skipping")
                                    break
                                
                                # 504, 502, 503 ë“± ì„œë²„ ì—ëŸ¬ëŠ” ì¬ì‹œë„
                                is_retryable = any(code in error_str for code in ["504", "502", "503", "500", "gateway", "timeout", "unavailable"])
                                
                                if is_retryable and retry_attempt < max_connection_retries - 1:
                                    wait_time = 2 ** retry_attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ
                                    logger.warning(f"[MCP][init.retry] server={name} error (attempt {retry_attempt + 1}/{max_connection_retries}): {error_msg[:100]}, retrying in {wait_time}s...")
                                    await asyncio.sleep(wait_time)
                                    continue
                                else:
                                    # ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬ ë˜ëŠ” ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
                                    logger.warning(f"[MCP][connect.error] server={name} error: {error_msg[:200]}")
                                    break
                        
                        return name, connection_success
                        
                except asyncio.CancelledError:
                    # shutdown ì¤‘ ì·¨ì†ŒëŠ” ì •ìƒì ì¸ ë™ì‘ - ë‹¤ë¥¸ ì„œë²„ ì—°ê²°ì€ ê³„ì† ì§„í–‰
                    logger.info(f"[MCP][init.cancelled] server={name} (shutdown in progress)")
                    return name, False
                except Exception as e:
                    logger.exception(f"[MCP][connect.error] server={name} unexpected err={e}")
                    return name, False

            tasks = [asyncio.create_task(connect_one_with_settings(n, c)) for n, c in enabled_server_items]
            # return_exceptions=Trueë¡œ ë³€ê²½í•˜ì—¬ ì¼ë¶€ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            # ì „ì²´ ì´ˆê¸°í™” íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì„œë²„ ìˆ˜ * íƒ€ì„ì•„ì›ƒ, ìµœëŒ€ 300ì´ˆ)
            total_timeout = min(len(enabled_server_items) * timeout_per_server, 300.0)
            try:
                results = await asyncio.wait_for(
                    asyncio.gather(*tasks, return_exceptions=True),
                    timeout=total_timeout
                )
            except asyncio.TimeoutError:
                logger.warning(f"[MCP][init.timeout] MCP initialization timeout after {total_timeout}s, cancelling remaining tasks...")
                # ë‚¨ì€ ì‘ì—… ì·¨ì†Œ
                for task in tasks:
                    if not task.done():
                        task.cancel()
                # ì™„ë£Œëœ ì‘ì—…ë§Œ ê²°ê³¼ ìˆ˜ì§‘
                results = []
                for task in tasks:
                    try:
                        result = await task
                        results.append(result)
                    except (asyncio.CancelledError, Exception):
                        results.append(None)
            
            # ê²°ê³¼ íŒŒì‹± (ì˜ˆì™¸ê°€ í¬í•¨ë  ìˆ˜ ìˆìŒ)
            connected_servers = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    server_name = enabled_server_items[i][0]
                    if isinstance(result, asyncio.CancelledError):
                        logger.info(f"[MCP][init.cancelled] server={server_name} (task was cancelled)")
                    else:
                        logger.warning(f"[MCP][init.exception] server={server_name} error={result}")
                elif isinstance(result, tuple) and len(result) == 2:
                    name, ok = result
                    if ok:
                        connected_servers.append(name)
            
            if connected_servers:
                logger.info(f"âœ… Successfully connected to {len(connected_servers)} MCP servers: {', '.join(connected_servers)}")
            else:
                logger.warning("âš ï¸ No MCP servers connected successfully")
            
            # OpenRouter ì—°ê²° í…ŒìŠ¤íŠ¸ ì œê±° (GeminiëŠ” llm_manager ê²½ìœ )
            logger.info("âœ… MCP Hub initialized (OpenRouter disabled)")
            logger.info(f"Available tools: {len(self.tools)}")
            logger.info(f"MCP servers: {list(self.mcp_sessions.keys())}")
            logger.info(f"Primary model: {self.llm_config.primary_model}")
            # ì„œë²„ë³„ ì—°ê²° ì§„ë‹¨ ìš”ì•½ ì¶œë ¥
            if self.connection_diagnostics:
                logger.info("[MCP][diagnostics] server connection summary")
                for name, di in self.connection_diagnostics.items():
                    init_ms = di.get('init_ms')
                    list_ms = di.get('list_ms')
                    logger.info(
                        "[MCP][diag] server=%s type=%s url=%s stage=%s ok=%s init_ms=%s list_ms=%s err=%s",
                        name,
                        di.get("type"),
                        di.get("url"),
                        di.get("stage"),
                        di.get("ok"),
                        f"{init_ms:.0f}" if isinstance(init_ms, (int, float)) else "-",
                        f"{list_ms:.0f}" if isinstance(list_ms, (int, float)) else "-",
                        di.get("error")
                    )
            
            # í•„ìˆ˜ ë„êµ¬ ê²€ì¦ - ì‹¤íŒ¨ ì‹œ warningë§Œ
            await self._validate_essential_tools()
            
        except Exception as e:
            logger.warning(f"âš ï¸ MCP Hub initialization failed: {e} - continuing with graceful degradation")
            logger.info("â„¹ï¸ System will continue with limited functionality (no API calls)")
            # Don't raise, allow graceful degradation
    
    async def _execute_via_mcp_server(self, server_name: str, tool_name: str, params: Dict[str, Any]) -> Optional[Any]:
        """MCP ì„œë²„ë¥¼ í†µí•´ ë„êµ¬ ì‹¤í–‰ (with connection pooling and health check)."""
        
        # Connection pooling: Check if connection exists and is healthy
        if server_name not in self.mcp_sessions:
            # Try to connect if not in sessions
            logger.debug(f"Server {server_name} not in sessions, attempting connection...")
            if server_name in self.mcp_server_configs:
                server_config = self.mcp_server_configs[server_name]
                connected = await self._connect_to_mcp_server(server_name, server_config)
                if not connected:
                    logger.error(f"Failed to connect to server {server_name}")
                    return None
            else:
                logger.error(f"Server {server_name} not in mcp_sessions and no config found. Available: {list(self.mcp_sessions.keys())}")
                return None
        else:
            # Health check existing connection
            is_healthy = await self._check_connection_health(server_name)
            if not is_healthy:
                logger.warning(f"Connection to {server_name} is unhealthy, reconnecting...")
                # Auto-reconnection
                if server_name in self.mcp_server_configs:
                    try:
                        await self._disconnect_from_mcp_server(server_name)
                    except Exception:
                        pass
                    server_config = self.mcp_server_configs[server_name]
                    connected = await self._connect_to_mcp_server(server_name, server_config)
                    if not connected:
                        logger.error(f"Failed to reconnect to server {server_name}")
                        return None
                else:
                    logger.error(f"Cannot reconnect to {server_name}: no config found")
                    return None
        
        if server_name not in self.mcp_sessions:
            logger.error(f"Server {server_name} still not in mcp_sessions after connection attempt")
            return None
        
        if server_name not in self.mcp_tools_map:
            logger.error(f"Server {server_name} not in mcp_tools_map. Available: {list(self.mcp_tools_map.keys())}")
            return None
        
        if tool_name not in self.mcp_tools_map[server_name]:
            available_tools = list(self.mcp_tools_map[server_name].keys())
            logger.error(f"Tool {tool_name} not found in server {server_name}. Available tools: {available_tools}")
            return None
        
        # ì¬ì‹œë„ + ì¬ì—°ê²°(ClosedResource/429) + ê°„ë‹¨í•œ ë°±ì˜¤í”„
        max_attempts = 3
        backoff_seconds = [0.5, 1.5, 3.0]
        
        for attempt in range(max_attempts):
            try:
                # í‘œì¤€ MCP ClientSession ë°©ì‹ (ìš°ì„ )
                if server_name in self.mcp_sessions:
                    session = self.mcp_sessions[server_name]
                    logger.debug(f"Calling tool {tool_name} on server {server_name} using ClientSession (attempt {attempt+1}/{max_attempts})")
                    
                    if session is None:
                        logger.error(f"[MCP][exec.error] Session is None for {server_name}")
                        return None
                    
                    if not hasattr(session, "call_tool"):
                        logger.error(f"[MCP][exec.error] Session does not have call_tool method: {type(session)}")
                        return None
                    
                    # ê¸°ì¡´ ClientSession ë°©ì‹
                    result = await session.call_tool(tool_name, params)
                    
                    # ê²°ê³¼ë¥¼ TextContentì—ì„œ ì¶”ì¶œ (ClientSession ë°©ì‹)
                    if result and hasattr(result, "content") and result.content:
                        content_parts = []
                        for item in result.content:
                            if isinstance(item, TextContent):
                                content_parts.append(item.text)
                            else:
                                # ë‹¤ë¥¸ íƒ€ì…ì˜ contentë„ ì²˜ë¦¬
                                content_parts.append(str(item))
                        
                        content_str = " ".join(content_parts)
                        logger.debug(f"Tool {tool_name} returned content length: {len(content_str)}")
                        return content_str
                    else:
                        logger.warning(f"Tool {tool_name} returned empty result")
                        return None
                else:
                    logger.error(f"[MCP][exec.error] Server {server_name} not found in fastmcp_clients or mcp_sessions")
                    return None
            
            except McpError as e:
                error_msg = str(e) if e else "Unknown MCP error"
                error_code = getattr(e.error, 'code', None) if hasattr(e, 'error') else None
                error_data = getattr(e.error, 'data', None) if hasattr(e, 'error') else None
                
                # ë ˆì´íŠ¸ë¦¬ë°‹ / í† í° ì˜¤ë¥˜ ê°ì§€
                is_rate_limit = "Too Many Requests" in error_msg or (error_code == 429)
                is_auth_error = "invalid_token" in error_msg.lower() or (error_code == 401)
                
                error_details = f"[MCP][exec.error] server={server_name} tool={tool_name} operation=call_tool"
                if error_code:
                    error_details += f" code={error_code}"
                if error_data:
                    error_details += f" data={error_data}"
                error_details += f" error={error_msg}"
                logger.error(error_details)
                
                if is_rate_limit and attempt < max_attempts - 1:
                    wait = backoff_seconds[attempt]
                    logger.warning(f"[MCP][exec.retry] Rate limit hit, retrying in {wait}s (attempt {attempt+2}/{max_attempts})")
                    await asyncio.sleep(wait)
                    continue
                
                if is_auth_error:
                    logger.error("[MCP][auth] invalid or expired token; refresh credentials and re-init MCP")
                return None
            
            except (RuntimeError, ConnectionError, OSError) as e:
                # ClosedResourceError, connection reset ë“±
                error_type = type(e).__name__
                error_msg = str(e)
                closed_like = "closed" in error_msg.lower() or "connection reset" in error_msg.lower()
                
                if closed_like and server_name in self.mcp_server_configs and attempt < max_attempts - 1:
                    logger.warning(f"[MCP][exec.retry] server={server_name} tool={tool_name} connection closed, reconnecting (attempt {attempt+2}/{max_attempts})")
                    try:
                        await self._disconnect_from_mcp_server(server_name)
                    except Exception:
                        pass
                    server_config = self.mcp_server_configs[server_name]
                    reconnected = await self._connect_to_mcp_server(server_name, server_config)
                    if reconnected:
                        wait = backoff_seconds[attempt]
                        await asyncio.sleep(wait)
                        continue
                    logger.error(f"[MCP][exec.error] Reconnect failed for {server_name}")
                    # Reconnect failed, session/client is bad or gone
                    if server_name in self.mcp_sessions:
                        del self.mcp_sessions[server_name]
                    if server_name in self.fastmcp_clients:
                        del self.fastmcp_clients[server_name]
                    return None
                
                logger.error(f"[MCP][exec.error] server={server_name} tool={tool_name} operation=call_tool type={error_type} error={error_msg}")
                # Invalidate session/client on fatal error if it looks like a connection issue
                if closed_like or "broken pipe" in error_msg.lower():
                    if server_name in self.mcp_sessions:
                        logger.warning(f"[MCP][session.invalidate] Removing dead session for {server_name}")
                        del self.mcp_sessions[server_name]
                    if server_name in self.fastmcp_clients:
                        logger.warning(f"[MCP][client.invalidate] Removing dead FastMCP client for {server_name}")
                        del self.fastmcp_clients[server_name]
                
                import traceback
                logger.debug(f"[MCP][exec.exception] server={server_name} tool={tool_name} - Full traceback:\n{traceback.format_exc()}")
                return None
            
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                logger.error(f"[MCP][exec.error] server={server_name} tool={tool_name} operation=call_tool type={error_type} error={error_msg}")
                import traceback
                logger.debug(f"[MCP][exec.exception] server={server_name} tool={tool_name} - Full traceback:\n{traceback.format_exc()}")
                return None
    
    async def _validate_essential_tools(self):
        """í•„ìˆ˜ MCP ë„êµ¬ ê²€ì¦ - Toolì´ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ë§Œ (ì‹¤ì œ ì‹¤í–‰ì€ ì„ íƒì )."""
        essential_tools = ["g-search", "fetch", "filesystem"]
        missing_tools = []
        
        logger.info("Validating essential tools availability...")
        
        # ë“±ë¡ëœ ëª¨ë“  tool ëª©ë¡ í™•ì¸
        all_tools = self.registry.get_all_tool_names()
        logger.info(f"Registered tools: {all_tools}")
        
        for tool in essential_tools:
            # tool_nameìœ¼ë¡œ ì§ì ‘ ì°¾ê¸°
            tool_found = False
            
            # 1. ì§ì ‘ ë“±ë¡ëœ tool í™•ì¸
            if tool in all_tools:
                tool_found = True
                logger.info(f"âœ… Found essential tool: {tool}")
            
            # 2. server_name::tool_name í˜•ì‹ìœ¼ë¡œë„ ì°¾ê¸°
            if not tool_found:
                for registered_name in all_tools:
                    if "::" in registered_name:
                        _, original_tool_name = registered_name.split("::", 1)
                        if original_tool_name == tool:
                            tool_found = True
                            logger.info(f"âœ… Found essential tool: {tool} as {registered_name}")
                            break
            
            if not tool_found:
                missing_tools.append(tool)
                logger.warning(f"âš ï¸ Essential tool {tool} not found in registry")
        
        # ëˆ„ë½ëœ toolì´ ìˆìœ¼ë©´ ê²½ê³ ë§Œ (ì‹¤ì œ ì‹¤í–‰ ì „ê¹Œì§€ëŠ” ì •í™•í•œ ê²€ì¦ ë¶ˆê°€)
        if missing_tools:
            logger.warning(f"âš ï¸ Some essential tools not found: {missing_tools}")
            logger.warning("âš ï¸ Tools may be registered later when MCP servers connect or may need manual configuration")
            logger.warning("âš ï¸ System will continue, but these tools may not be available")
        else:
            logger.info("âœ… All essential tools found in registry")
        
        # ì‹¤ì œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ëŠ” ì„ íƒì  (timeoutìœ¼ë¡œ ì¸í•œ false negative ë°©ì§€)
        # Production í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ ì‚¬ìš© ì‹œì ì— ê²€ì¦í•˜ëŠ” ê²ƒì´ ë” ì•ˆì „
    
    async def cleanup(self):
        """MCP ì—°ê²° ì •ë¦¬ - Production-grade cleanup."""
        logger.info("Cleaning up MCP Hub...")
        # ì‹ ê·œ ì—°ê²° ì°¨ë‹¨
        self.stopping = True
        
        # ERA ì„œë²„ ì •ë¦¬
        if self.era_server_manager:
            try:
                self.era_server_manager.cleanup()
                logger.info("âœ… ERA server cleaned up")
            except Exception as e:
                logger.warning(f"Error cleaning up ERA server: {e}")
        
        # OpenRouter í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© ì•ˆ í•¨
        self.openrouter_client = None
        
        # FastMCP Client ì •ë¦¬ (ë³‘ë ¬ë¡œ ë¹ ë¥´ê²Œ ì¢…ë£Œ)
        async def close_fastmcp_client(server_name: str, client: Any):
            """FastMCP Client ì¢…ë£Œ í—¬í¼"""
            try:
                # ëª…ì‹œì  ì¢…ë£Œ ì‹œë„
                if hasattr(client, 'close'):
                    try:
                        await asyncio.wait_for(client.close(), timeout=0.5)
                    except (asyncio.TimeoutError, Exception):
                        pass
                elif hasattr(client, '__aexit__'):
                    try:
                        await asyncio.wait_for(client.__aexit__(None, None, None), timeout=0.5)
                    except (asyncio.TimeoutError, Exception):
                        pass
                logger.debug(f"Closed FastMCP client for {server_name}")
            except Exception as e:
                logger.debug(f"Error closing FastMCP client for {server_name}: {e}")
        
        # ëª¨ë“  FastMCP Clientë¥¼ ë³‘ë ¬ë¡œ ì¢…ë£Œ (ìµœëŒ€ 1ì´ˆ íƒ€ì„ì•„ì›ƒ)
        if self.fastmcp_clients:
            close_tasks = [
                close_fastmcp_client(name, client)
                for name, client in list(self.fastmcp_clients.items())
            ]
            try:
                await asyncio.wait_for(
                    asyncio.gather(*close_tasks, return_exceptions=True),
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                logger.warning("FastMCP clients cleanup timed out (continuing)")
            except Exception as e:
                logger.debug(f"Error during parallel FastMCP cleanup: {e}")
            finally:
                # ì°¸ì¡°ëŠ” ë¬´ì¡°ê±´ ì œê±°
                self.fastmcp_clients.clear()
        
        # ëª¨ë“  MCP ì„œë²„ ì—°ê²° í•´ì œ (ì—­ìˆœìœ¼ë¡œ ì •ë¦¬)
        server_names = list(self.mcp_sessions.keys())
        for server_name in reversed(server_names):
            try:
                # ì„¸ì…˜ ì œê±°
                if server_name in self.mcp_sessions:
                    session = self.mcp_sessions.get(server_name)
                    # FastMCP Clientì¸ ê²½ìš° ëª…ì‹œì  ì¢…ë£Œ ì‹œë„
                    if session and isinstance(session, FastMCPClient) if FASTMCP_AVAILABLE else False:
                        try:
                            # FastMCP Client ëª…ì‹œì  ì¢…ë£Œ
                            if hasattr(session, 'close'):
                                await asyncio.wait_for(session.close(), timeout=0.5)
                            elif hasattr(session, '__aexit__'):
                                await asyncio.wait_for(session.__aexit__(None, None, None), timeout=0.5)
                        except (asyncio.TimeoutError, Exception) as e:
                            logger.debug(f"FastMCP session close timeout/error for {server_name}: {e}")
                    elif session and hasattr(session, 'shutdown'):
                        # ê¸°ì¡´ ClientSession ë°©ì‹
                        try:
                            await asyncio.wait_for(session.shutdown(), timeout=0.5)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
                        except:
                            pass
                    del self.mcp_sessions[server_name]
                
                # Exit stack ì •ë¦¬: anyio cancel scope ì˜¤ë¥˜ ë¬´ì‹œí•˜ê³  ì‹œë„
                if server_name in self.exit_stacks:
                    exit_stack = self.exit_stacks[server_name]
                    try:
                        # anyio RuntimeErrorëŠ” ì™„ì „íˆ ë¬´ì‹œ (ë‹¤ë¥¸ íƒœìŠ¤í¬ì—ì„œ ë‹«íˆë ¤ í•  ë•Œ ë°œìƒ)
                        await asyncio.wait_for(exit_stack.aclose(), timeout=2.0)
                    except RuntimeError as e:
                        if "cancel scope" in str(e).lower() or "different task" in str(e).lower():
                            # anyio cancel scope ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                            pass
                        else:
                            logger.debug(f"RuntimeError during exit_stack cleanup for {server_name}: {e}")
                    except (asyncio.TimeoutError, Exception) as e:
                        # ê¸°íƒ€ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                        logger.debug(f"Error closing exit_stack for {server_name}: {e}")
                    finally:
                        del self.exit_stacks[server_name]
                
                if server_name in self.mcp_tools_map:
                    del self.mcp_tools_map[server_name]
                    
            except Exception as e:
                logger.debug(f"Error disconnecting from {server_name}: {e}")
        
        # ì •ë¦¬ ì™„ë£Œ ëŒ€ê¸°
        try:
            await asyncio.sleep(0.1)
        except:
            pass
        
        # ë™ì ìœ¼ë¡œ ìƒì„±ëœ ì„œë²„ ì •ë¦¬ (auto_cleanupì´ í™œì„±í™”ëœ ê²½ìš°)
        if self.config.builder_auto_cleanup:
            try:
                from src.core.mcp_server_builder import get_mcp_server_builder
                builder = get_mcp_server_builder()
                # ë¹Œë“œëœ ì„œë²„ ë””ë ‰í† ë¦¬ ì •ë¦¬ (ì„ íƒì )
                # ì‹¤ì œ ì„œë²„ í”„ë¡œì„¸ìŠ¤ëŠ” ProcessManagerê°€ ê´€ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¡œê¹…ë§Œ
                logger.debug("[MCP][cleanup] Dynamic servers will be cleaned up by ProcessManager")
            except Exception as e:
                logger.debug(f"[MCP][cleanup] Builder cleanup skipped: {e}")
        
        logger.info("MCP Hub cleanup completed")

    def start_shutdown(self):
        """ì™¸ë¶€ì—ì„œ ì¢…ë£Œ ì‹œì‘ ì‹œ í˜¸ì¶œ - ì‹ ê·œ ì—°ê²° ì°¨ë‹¨"""
        self.stopping = True
    
    async def call_llm_async(self, model: str, messages: List[Dict[str, str]], 
                           temperature: float = 0.1, max_tokens: int = 4000) -> Dict[str, Any]:
        """LLM í˜¸ì¶œì€ llm_managerë¥¼ í†µí•´ ìˆ˜í–‰í•˜ë„ë¡ ê°•ì œ (Gemini ì§ê²°)."""
        raise RuntimeError("call_llm_async via MCP Hub is disabled. Use llm_manager for Gemini.")
    
    async def execute_tool(self, tool_name: str, parameters: Dict[str, Any], citation_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Tool ì‹¤í–‰ - MCP í”„ë¡œí† ì½œë§Œ ì‚¬ìš© (9ëŒ€ í˜ì‹ : ToolTrace ì¶”ì  í†µí•©).

        ì‹¤í–‰ ìš°ì„ ìˆœìœ„:
        1. MCP ì„œë²„ì—ì„œ Tool ì‹¤í–‰ (server_name::tool_name í˜•ì‹ ë˜ëŠ” tool_nameìœ¼ë¡œ ì°¾ê¸°)
        2. ì‹¤íŒ¨ ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë°˜í™˜ (fallback ì—†ìŒ)
        
        Args:
            tool_name: ë„êµ¬ ì´ë¦„
            parameters: ë„êµ¬ íŒŒë¼ë¯¸í„°
            citation_id: Citation ID (optional, ToolTrace ì¶”ì ìš©)
        """
        import time
        import uuid
        start_time = time.time()
        
        # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ì—ì„œ execution_id ê°€ì ¸ì˜¤ê¸° (ROMA ìŠ¤íƒ€ì¼)
        execution_id = None
        try:
            from src.core.recursive_context_manager import ExecutionContext
            ctx = ExecutionContext.get()
            if ctx:
                execution_id = ctx.execution_id
                logger.debug(f"Tool execution in execution context: {execution_id}")
        except Exception as e:
            logger.debug(f"Failed to get ExecutionContext: {e}")
        
        # 9ëŒ€ í˜ì‹ : ToolTrace ì¶”ì  ì¤€ë¹„
        tool_id = f"tool_{uuid.uuid4().hex[:8]}"
        tool_type = _infer_tool_type(tool_name)
        query_str = _format_query_string(tool_name, parameters)
        
        # ë¡œì»¬ ë„êµ¬ ìš°ì„  ì²˜ë¦¬ (suna-style: ì‹¤ì œ ë™ì‘í•˜ëŠ” ë„êµ¬ ìš°ì„ )
        local_tools = {
            # ì‹¤ì œ ë™ì‘í•˜ëŠ” ë„êµ¬ë“¤
            "browser_navigate", "browser_extract", "browser_screenshot", "browser_interact",
            "run_shell_command", "run_interactive_command", "run_background_command",
            "create_file", "read_file", "write_file", "edit_file", "list_files", "delete_file",
            "filesystem", "browser", "shell"  # ì¼ë°˜ì ì¸ ì´ë¦„ë„ ì§€ì›
        }

        if tool_name in local_tools or any(tool_name.startswith(prefix) for prefix in ["browser_", "shell_", "file_"]):
            logger.debug(f"Executing local tool: {tool_name}")
            try:
                # ToolResultë¥¼ Dictë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
                if tool_name.startswith("browser") or tool_name == "browser":
                    result = await _execute_browser_tool(tool_name, parameters)
                elif tool_name.startswith("shell") or tool_name == "shell":
                    result = await _execute_shell_tool(tool_name, parameters)
                elif tool_name.startswith(("file", "create_", "read_", "write_", "edit_", "list_", "delete_")) or tool_name == "filesystem":
                    result = await _execute_file_tool(tool_name, parameters)
                else:
                    # ì¼ë°˜ì ì¸ ê²½ìš° data toolë¡œ ì²˜ë¦¬
                    result = await _execute_data_tool(tool_name, parameters)

                execution_time = time.time() - start_time
                return {
                    "success": result.success,
                    "data": result.data,
                    "error": result.error,
                    "execution_time": result.execution_time,
                    "confidence": result.confidence,
                    "source": "local_tool"
                }

            except Exception as e:
                logger.error(f"Local tool execution failed: {tool_name} - {e}")
                execution_time = time.time() - start_time
                return {
                    "success": False,
                    "error": f"Local tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0,
                    "source": "local_tool"
                }

        # MCP ì„œë²„ ì •ë³´ ì¶”ì¶œ
        mcp_server = None
        mcp_tool_name = None
        if "::" in tool_name:
            parts = tool_name.split("::", 1)
            mcp_server = parts[0]
            mcp_tool_name = parts[1] if len(parts) > 1 else tool_name
        
        # Citation IDê°€ ì—†ìœ¼ë©´ ìƒì„± (ì„ì‹œ)
        if not citation_id:
            try:
                from src.generation.citation_manager import CitationManager
                # ì „ì—­ citation managerê°€ ìˆë‹¤ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì„ì‹œ ìƒì„±
                # ì‹¤ì œë¡œëŠ” orchestratorì—ì„œ ê´€ë¦¬í•˜ëŠ” citation_idë¥¼ ì „ë‹¬ë°›ì•„ì•¼ í•¨
                citation_id = f"TEMP-{tool_id}"
            except Exception:
                citation_id = f"TEMP-{tool_id}"

        # ì¶œë ¥ ë§¤ë‹ˆì € í†µí•©
        from src.utils.output_manager import get_output_manager, OutputLevel, ToolExecutionResult
        output_manager = get_output_manager()

        # ë„êµ¬ ì‹¤í–‰ ì‹œì‘ ì•Œë¦¼
        await output_manager.output(
            f"ğŸ”§ ë„êµ¬ '{tool_name}' ì‹¤í–‰ ì‹œì‘...",
            level=OutputLevel.SERVICE,
            agent_name="mcp_integration"
        )

        logger.info(f"[MCP][exec.start] tool={tool_name} params_keys={list(parameters.keys())}")
        logger.info(f"[MCP][exec.start] parameters_preview={str(parameters)[:200]}...")
        
        # í•™ìˆ  ë„êµ¬ ë¼ìš°íŒ… (arxiv, scholar) - MCP ì„œë²„ ìš°ì„  ì‚¬ìš©
        if tool_name in ["arxiv", "scholar"]:
            logger.info(f"[MCP][exec.academic] Routing {tool_name} to _execute_academic_tool (MCP server first)")
            try:
                # ë¨¼ì € MCP ì„œë²„ì—ì„œ ì‹œë„
                mcp_hub = get_mcp_hub()
                
                # MCP ì„œë²„ ì—°ê²° í™•ì¸
                if not mcp_hub.mcp_sessions:
                    logger.warning("No MCP servers connected, attempting to initialize...")
                    try:
                        await mcp_hub.initialize_mcp()
                    except Exception as e:
                        logger.warning(f"Failed to initialize MCP servers: {e}")
                
                # arXiv MCP ì„œë²„ì—ì„œ ì‹œë„
                mcp_result = None
                if tool_name == "arxiv":
                    # arXiv MCP ì„œë²„ ë„êµ¬ ì°¾ê¸°
                    if "arxiv" in mcp_hub.mcp_sessions and "arxiv" in mcp_hub.mcp_tools_map:
                        tools = mcp_hub.mcp_tools_map["arxiv"]
                        arxiv_tool_name = None
                        
                        # arxiv_search, arxiv_get_paper ë“± ì°¾ê¸°
                        for tool_key in tools.keys():
                            tool_lower = tool_key.lower()
                            if "search" in tool_lower or "query" in tool_lower:
                                arxiv_tool_name = tool_key
                                break
                        
                        if arxiv_tool_name:
                            logger.info(f"Using arXiv MCP server with tool: {arxiv_tool_name}")
                            mcp_result = await mcp_hub._execute_via_mcp_server(
                                "arxiv",
                                arxiv_tool_name,
                                parameters
                            )
                
                # MCP ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë¡œì»¬ fallback
                if mcp_result:
                    from src.core.mcp_integration import ToolResult
                    tool_result = ToolResult(
                        success=True,
                        data=mcp_result if isinstance(mcp_result, dict) else {"result": mcp_result},
                        execution_time=time.time() - start_time,
                        confidence=0.9
                    )
                else:
                    # ë¡œì»¬ fallback
                    from src.core.mcp_integration import _execute_academic_tool, ToolResult
                    tool_result = await _execute_academic_tool(tool_name, parameters)
                
                execution_time = time.time() - start_time
                logger.info(f"[MCP][exec.academic.success] {tool_name} routing succeeded: success={tool_result.success}")

                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict) and 'results' in tool_result.data:
                        result_count = len(tool_result.data['results'])
                        result_summary = f"{result_count}ê°œ ë…¼ë¬¸ ê²€ìƒ‰ë¨"
                    else:
                        result_summary = f"ë°ì´í„° ë°˜í™˜ë¨ ({type(tool_result.data).__name__})"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."

                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)

                return {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "mcp_academic" if mcp_result else "local_academic"
                }
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.academic.error] {tool_name} routing failed: {e}", exc_info=True)

                # ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ê²°ê³¼ í‘œì‹œ
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"í•™ìˆ  ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)

                return {
                    "success": False,
                    "data": None,
                    "error": f"Academic tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0,
                    "source": "academic_routing_failed"
                }
        
        # ê²€ìƒ‰ ë„êµ¬ëŠ” ë¨¼ì € ë¼ìš°íŒ… í™•ì¸ (ë„êµ¬ ì°¾ê¸° ì „ì—)
        if tool_name in ["g-search", "ddg_search", "mcp_search", "tavily", "exa"]:
            logger.info(f"[MCP][exec.route] Routing {tool_name} to _execute_search_tool (tool_name type: {type(tool_name)})")
            try:
                from src.core.mcp_integration import _execute_search_tool, ToolResult
                tool_result = await _execute_search_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                logger.info(f"[MCP][exec.route.success] {tool_name} routing succeeded: success={tool_result.success}")

                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict) and 'results' in tool_result.data:
                        result_count = len(tool_result.data['results'])
                        result_summary = f"{result_count}ê°œ ê²°ê³¼ ê²€ìƒ‰ë¨"
                    else:
                        result_summary = f"ë°ì´í„° ë°˜í™˜ë¨ ({type(tool_result.data).__name__})"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."

                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)

                return {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "mcp_search"
                }
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.route.error] {tool_name} routing failed: {e}", exc_info=True)

                # ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨ ê²°ê³¼ í‘œì‹œ
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"ë¼ìš°íŒ… ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)

                # ë¼ìš°íŒ… ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ë„êµ¬ ì°¾ê¸°ë¡œ fallback
                # í•˜ì§€ë§Œ ë¼ìš°íŒ…ì´ ì‹¤íŒ¨í•˜ë©´ ê²€ìƒ‰ ë„êµ¬ ìì²´ê°€ ë¬¸ì œì´ë¯€ë¡œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                return {
                    "success": False,
                    "data": None,
                    "error": f"Search tool routing failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0,
                    "source": "mcp_search_routing_failed"
                }
        
        # ë¸Œë¼ìš°ì € ë„êµ¬ ë¼ìš°íŒ… (ìš°ì„  ì²˜ë¦¬)
        if tool_name.startswith("browser_"):
            logger.info(f"[MCP][exec.browser] Routing {tool_name} to _execute_browser_tool")
            try:
                from src.core.mcp_integration import _execute_browser_tool, ToolResult
                tool_result = await _execute_browser_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict):
                        if "extracted_data" in tool_result.data:
                            result_summary = f"ì½˜í…ì¸  ì¶”ì¶œ ì™„ë£Œ ({tool_result.data.get('content_length', 0)}ì)"
                        elif "screenshot_path" in tool_result.data:
                            result_summary = f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {tool_result.data['screenshot_path']}"
                        elif "actions" in tool_result.data:
                            result_summary = f"{len(tool_result.data['actions'])}ê°œ ì•¡ì…˜ ì‹¤í–‰"
                        else:
                            result_summary = "ë¸Œë¼ìš°ì € ì‘ì—… ì™„ë£Œ"
                    else:
                        result_summary = f"ë°ì´í„° ë°˜í™˜ë¨ ({type(tool_result.data).__name__})"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "browser"
                }
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.browser.error] {tool_name} failed: {e}", exc_info=True)
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"ë¸Œë¼ìš°ì € ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": False,
                    "data": None,
                    "error": f"Browser tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0
                }
        
        # ë¬¸ì„œ ìƒì„± ë„êµ¬ ë¼ìš°íŒ…
        if tool_name.startswith("generate_"):
            logger.info(f"[MCP][exec.document] Routing {tool_name} to _execute_document_tool")
            try:
                from src.core.mcp_integration import _execute_document_tool, ToolResult
                tool_result = await _execute_document_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict) and "file_path" in tool_result.data:
                        result_summary = f"ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {tool_result.data['file_path']}"
                    else:
                        result_summary = "ë¬¸ì„œ ìƒì„± ì™„ë£Œ"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "document"
                }
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.document.error] {tool_name} failed: {e}", exc_info=True)
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": False,
                    "data": None,
                    "error": f"Document tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0
                }
        
        # Shell ë„êµ¬ ë¼ìš°íŒ…
        if tool_name in ["run_shell_command", "run_interactive_command", "run_background_command"]:
            logger.info(f"[MCP][exec.shell] Routing {tool_name} to _execute_shell_tool")
            try:
                from src.core.mcp_integration import _execute_shell_tool, ToolResult
                tool_result = await _execute_shell_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict):
                        if "stdout" in tool_result.data:
                            stdout_preview = tool_result.data["stdout"][:100]
                            result_summary = f"ëª…ë ¹ ì‹¤í–‰ ì™„ë£Œ: {stdout_preview}..."
                        elif "pid" in tool_result.data:
                            result_summary = f"ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘: PID {tool_result.data['pid']}"
                        else:
                            result_summary = "Shell ëª…ë ¹ ì‹¤í–‰ ì™„ë£Œ"
                    else:
                        result_summary = "Shell ëª…ë ¹ ì‹¤í–‰ ì™„ë£Œ"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                result_dict = {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "shell"
                }
                
                # 9ëŒ€ í˜ì‹ : ToolTrace ìƒì„±
                _create_tool_trace(
                    tool_id=tool_id,
                    citation_id=citation_id or f"TEMP-{tool_id}",
                    tool_type=tool_type,
                    query=query_str,
                    result=result_dict,
                    mcp_server=mcp_server,
                    mcp_tool_name=mcp_tool_name,
                )
                
                return result_dict
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.shell.error] {tool_name} failed: {e}", exc_info=True)
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"Shell ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": False,
                    "data": None,
                    "error": f"Shell tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0,
                    "source": "shell"
                }
        
        # Git ë„êµ¬ ë¼ìš°íŒ…
        if tool_name in ["git_status", "git_commit", "git_push", "git_create_pr", "git_commit_push_pr", "git_create_branch"]:
            logger.info(f"[MCP][exec.git] Routing {tool_name} to _execute_git_tool")
            try:
                from src.core.mcp_integration import _execute_git_tool, ToolResult
                tool_result = await _execute_git_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict):
                        if "commit_hash" in tool_result.data:
                            result_summary = f"ì»¤ë°‹ ì™„ë£Œ: {tool_result.data['commit_hash'][:8]}"
                        elif "pr_url" in tool_result.data:
                            result_summary = f"PR ìƒì„± ì™„ë£Œ: {tool_result.data['pr_url']}"
                        elif "branch" in tool_result.data:
                            result_summary = f"ë¸Œëœì¹˜ ì‘ì—… ì™„ë£Œ: {tool_result.data['branch']}"
                        else:
                            result_summary = "Git ì‘ì—… ì™„ë£Œ"
                    else:
                        result_summary = "Git ì‘ì—… ì™„ë£Œ"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                result_dict = {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "git"
                }
                
                # 9ëŒ€ í˜ì‹ : ToolTrace ìƒì„±
                _create_tool_trace(
                    tool_id=tool_id,
                    citation_id=citation_id or f"TEMP-{tool_id}",
                    tool_type=tool_type,
                    query=query_str,
                    result=result_dict,
                    mcp_server=mcp_server,
                    mcp_tool_name=mcp_tool_name,
                )
                
                return result_dict
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.git.error] {tool_name} failed: {e}", exc_info=True)
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"Git ì‘ì—… ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": False,
                    "data": None,
                    "error": f"Git tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0,
                    "source": "git"
                }
        
        # íŒŒì¼ ë„êµ¬ ë¼ìš°íŒ…
        if tool_name in ["create_file", "read_file", "write_file", "edit_file", "list_files", "delete_file"]:
            logger.info(f"[MCP][exec.file] Routing {tool_name} to _execute_file_tool")
            try:
                from src.core.mcp_integration import _execute_file_tool, ToolResult
                tool_result = await _execute_file_tool(tool_name, parameters)
                execution_time = time.time() - start_time
                
                result_summary = ""
                if tool_result.success and tool_result.data:
                    if isinstance(tool_result.data, dict):
                        if "file_path" in tool_result.data:
                            result_summary = f"íŒŒì¼ ì‘ì—… ì™„ë£Œ: {tool_result.data['file_path']}"
                        elif "files" in tool_result.data:
                            result_summary = f"{len(tool_result.data['files'])}ê°œ íŒŒì¼/ë””ë ‰í† ë¦¬"
                        else:
                            result_summary = "íŒŒì¼ ì‘ì—… ì™„ë£Œ"
                    else:
                        result_summary = "íŒŒì¼ ì‘ì—… ì™„ë£Œ"
                elif tool_result.error:
                    result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=tool_result.success,
                    execution_time=execution_time,
                    result_summary=result_summary,
                    confidence=tool_result.confidence,
                    error_message=tool_result.error
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": tool_result.success,
                    "data": tool_result.data,
                    "error": tool_result.error,
                    "execution_time": execution_time,
                    "confidence": tool_result.confidence,
                    "source": "file"
                }
            except Exception as e:
                execution_time = time.time() - start_time
                logger.error(f"[MCP][exec.file.error] {tool_name} failed: {e}", exc_info=True)
                
                tool_exec_result = ToolExecutionResult(
                    tool_name=tool_name,
                    success=False,
                    execution_time=execution_time,
                    result_summary=f"íŒŒì¼ ì‘ì—… ì‹¤íŒ¨: {str(e)[:100]}...",
                    confidence=0.0,
                    error_message=str(e)
                )
                await output_manager.output_tool_execution(tool_exec_result)
                
                return {
                    "success": False,
                    "data": None,
                    "error": f"File tool execution failed: {str(e)}",
                    "execution_time": execution_time,
                    "confidence": 0.0
                }
        
        # Tool ì°¾ê¸° (server_name::tool_name ë˜ëŠ” tool_name)
        # ë¨¼ì € tool_nameì´ ì´ë¯¸ server_name::tool_name í˜•ì‹ì¸ì§€ í™•ì¸
        if "::" in tool_name:
            # ì´ë¯¸ ì „ì²´ ì´ë¦„ í˜•ì‹ì´ë©´ ì§ì ‘ ì°¾ê¸°
            tool_info = self.registry.get_tool_info(tool_name)
        else:
            # tool_nameë§Œ ì£¼ì–´ì§„ ê²½ìš° Registryì—ì„œ ì°¾ê¸°
            tool_info = self.registry.get_tool_info(tool_name)
        
        # tool_nameìœ¼ë¡œ ì§ì ‘ ì°¾ê¸° ì‹¤íŒ¨ ì‹œ, ëª¨ë“  MCP ì„œë²„ì—ì„œ server_name::tool_name í˜•ì‹ìœ¼ë¡œ ì°¾ê¸°
        if not tool_info:
            for registered_name in self.registry.get_all_tool_names():
                # ì´ë¯¸ ì „ì²´ ì´ë¦„ í˜•ì‹ì´ë©´ ì •í™•íˆ ë§¤ì¹­
                if "::" in tool_name and registered_name == tool_name:
                    tool_info = self.registry.get_tool_info(registered_name)
                    logger.info(f"Found tool by exact match: {tool_name}")
                    break
                # server_name::tool_name í˜•ì‹ì—ì„œ tool_name ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ë¹„êµ
                elif "::" in registered_name:
                    _, original_tool_name = registered_name.split("::", 1)
                    if original_tool_name == tool_name:
                        tool_info = self.registry.get_tool_info(registered_name)
                        logger.info(f"Found tool {tool_name} as {registered_name}")
                        break
                elif registered_name == tool_name:
                    tool_info = self.registry.get_tool_info(registered_name)
                    break
        
        if not tool_info:
            # Registryì—ì„œ ì§ì ‘ ì°¾ê¸°
            tool_info = self.registry.tools.get(tool_name)
        
        if not tool_info:
            # í•˜ìœ„ í˜¸í™˜ì„±: self.toolsì—ì„œ ì°¾ê¸°
            tool_info = self.tools.get(tool_name)
        
        if not tool_info:
            # MCP Builderë¥¼ í†µí•œ ìë™ ì„œë²„ ìƒì„± ì‹œë„
            if self.config.builder_enabled:
                logger.info(f"[MCP][builder] Tool '{tool_name}' not found, attempting auto-build...")
                try:
                    from src.core.mcp_server_builder import get_mcp_server_builder
                    builder = get_mcp_server_builder()
                    
                    # ì„œë²„ ë¹Œë“œ
                    build_result = await builder.build_mcp_server(
                        tool_name=tool_name,
                        parameters=parameters,
                        error_context=None
                    )
                    
                    if build_result.get("success"):
                        server_name = build_result["server_name"]
                        server_path = build_result["server_path"]
                        
                        logger.info(f"[MCP][builder] Server built successfully: {server_name}")
                        
                        # ë™ì  ì„œë²„ ë“±ë¡
                        registered = await self._register_dynamic_server(server_name, server_path)
                        
                        if registered:
                            logger.info(f"[MCP][builder] Server registered: {server_name}, retrying tool execution...")
                            # ë„êµ¬ ì‹¤í–‰ ì¬ì‹œë„
                            return await self.execute_tool(tool_name, parameters)
                        else:
                            logger.warning(f"[MCP][builder] Failed to register server: {server_name}")
                    else:
                        logger.warning(f"[MCP][builder] Server build failed: {build_result.get('error')}")
                except Exception as builder_error:
                    logger.error(f"[MCP][builder] Builder error: {builder_error}", exc_info=True)
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  tool ëª©ë¡ ë¡œê¹…
            available_tools = self.registry.get_all_tool_names()
            execution_time = time.time() - start_time
            logger.error(f"[MCP][exec.unknown] tool={tool_name} available={available_tools}")

            # ë„êµ¬ ì°¾ê¸° ì‹¤íŒ¨ ê²°ê³¼ í‘œì‹œ
            available_preview = ', '.join(available_tools[:5]) + ('...' if len(available_tools) > 5 else '')
            tool_exec_result = ToolExecutionResult(
                tool_name=tool_name,
                success=False,
                execution_time=execution_time,
                result_summary=f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {available_preview}",
                confidence=0.0,
                error_message=f"Unknown tool: {tool_name}"
            )
            await output_manager.output_tool_execution(tool_exec_result)

            return {
                "success": False,
                "data": None,
                "error": f"Unknown tool: {tool_name}. Available tools: {', '.join(available_tools[:10])}",
                "execution_time": execution_time,
                "confidence": 0.0
            }

        try:
            # 1. MCP Toolì¸ì§€ í™•ì¸ ë° ì‹¤í–‰ ì‹œë„ - tool_infoì—ì„œ ì§ì ‘ ì •ë³´ ì¶”ì¶œ
            found_tool_name = tool_name
            mcp_info = None
            
            # tool_infoê°€ ìˆìœ¼ë©´ MCP ë„êµ¬ì¸ì§€ í™•ì¸í•˜ê³  mcp_info ì¶”ì¶œ
            if tool_info:
                # tool_infoì—ì„œ mcp_server ì •ë³´ í™•ì¸
                mcp_server = tool_info.mcp_server
                if mcp_server:
                    # server_name::tool_name í˜•ì‹ì—ì„œ server_nameê³¼ tool_name ì¶”ì¶œ
                    if "::" in tool_name:
                        server_name, original_tool_name = tool_name.split("::", 1)
                        mcp_info = (server_name, original_tool_name)
                        found_tool_name = tool_name
                        logger.info(f"[MCP][exec.resolve] Using tool_info: {tool_name} -> server={server_name}, tool={original_tool_name}")
                    else:
                        # tool_nameë§Œ ìˆëŠ” ê²½ìš° tool_infoì˜ mcp_server ì‚¬ìš©
                        # tool_nameì´ ì‹¤ì œ ì„œë²„ì˜ ì›ë³¸ tool nameì¸ì§€ í™•ì¸ í•„ìš”
                        # registryì—ì„œ ì°¾ê¸°
                        for registered_name in self.registry.get_all_tool_names():
                            if registered_name == tool_name and self.registry.is_mcp_tool(registered_name):
                                mcp_info = self.registry.get_mcp_server_info(registered_name)
                                found_tool_name = registered_name
                                break
                            elif "::" in registered_name:
                                _, original_tool_name = registered_name.split("::", 1)
                                if original_tool_name == tool_name:
                                    mcp_info = self.registry.get_mcp_server_info(registered_name)
                                    found_tool_name = registered_name
                                    logger.info(f"[MCP][exec.resolve] Found {tool_name} as {registered_name}")
                                    break
            
            # tool_infoì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            if not mcp_info:
                # ì´ë¯¸ server_name::tool_name í˜•ì‹ì¸ ê²½ìš°
                if "::" in tool_name:
                    if self.registry.is_mcp_tool(tool_name):
                        mcp_info = self.registry.get_mcp_server_info(tool_name)
                        found_tool_name = tool_name
                        logger.info(f"[MCP][exec.resolve] Using full name: {tool_name}")
                elif self.registry.is_mcp_tool(tool_name):
                    mcp_info = self.registry.get_mcp_server_info(tool_name)
                    found_tool_name = tool_name
                else:
                    # server_name::tool_name í˜•ì‹ìœ¼ë¡œ ì°¾ê¸°
                    for registered_name in self.registry.get_all_tool_names():
                        if "::" in registered_name:
                            server_part, original_tool_name = registered_name.split("::", 1)
                            if original_tool_name == tool_name and self.registry.is_mcp_tool(registered_name):
                                mcp_info = self.registry.get_mcp_server_info(registered_name)
                                found_tool_name = registered_name
                                logger.info(f"[MCP][exec.resolve] {tool_name} -> {registered_name}")
                                break
                        elif registered_name == tool_name and self.registry.is_mcp_tool(registered_name):
                            mcp_info = self.registry.get_mcp_server_info(registered_name)
                            found_tool_name = registered_name
                            break
            
            if mcp_info:
                server_name, original_tool_name = mcp_info
                
                # MCP ì„œë²„ ì—°ê²° í™•ì¸
                if server_name in self.mcp_sessions:
                    try:
                        logger.info(f"[MCP][exec.try] server={server_name} tool={tool_name} as={found_tool_name}")
                        mcp_result = await self._execute_via_mcp_server(
                            server_name,
                            original_tool_name,
                            parameters
                        )
                        
                        if mcp_result:
                            # MCP ê²°ê³¼ë¥¼ ToolResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                            # ì—ëŸ¬ ì‘ë‹µ ì²´í¬
                            import json
                            import re
                            
                            result_lower = str(mcp_result).lower() if mcp_result else ""
                            error_patterns = [
                                r'\b(failed|error|invalid_token|authentication failed)\b',
                                r'\b(401|404|500|502|503|504)\b',
                                r'bad gateway',
                                r'not found',
                                r'unauthorized',
                                r'<!doctype html>',
                                r'<html',
                                r'<title>.*error.*</title>'
                            ]
                            
                            is_error = False
                            error_msg = None
                            for pattern in error_patterns:
                                if re.search(pattern, result_lower):
                                    is_error = True
                                    if '401' in result_lower:
                                        error_msg = "Authentication failed (401)"
                                    elif '404' in result_lower:
                                        error_msg = "Not found (404)"
                                    elif '502' in result_lower or 'bad gateway' in result_lower:
                                        error_msg = "Bad gateway (502)"
                                    elif '500' in result_lower:
                                        error_msg = "Internal server error (500)"
                                    else:
                                        error_msg = "Server error detected"
                                    break
                            
                            if is_error:
                                execution_time = time.time() - start_time
                                logger.error(f"MCP tool {tool_name} returned error: {error_msg}")

                                # MCP ë„êµ¬ ì—ëŸ¬ ê²°ê³¼ í‘œì‹œ
                                tool_exec_result = ToolExecutionResult(
                                    tool_name=tool_name,
                                    success=False,
                                    execution_time=execution_time,
                                    result_summary=f"MCP ë„êµ¬ ì—ëŸ¬: {error_msg[:100]}...",
                                    confidence=0.0,
                                    error_message=error_msg
                                )
                                await output_manager.output_tool_execution(tool_exec_result)

                                return {
                                    "success": False,
                                    "data": None,
                                    "error": f"MCP tool returned error: {error_msg}",
                                    "execution_time": execution_time,
                                    "confidence": 0.0,
                                    "source": "mcp"
                                }
                            
                            # ë¬¸ìì—´ì¸ ê²½ìš° ë§ˆí¬ë‹¤ìš´ íŒŒì‹± ì‹œë„
                            if isinstance(mcp_result, str):
                                # JSON ì‹œë„
                                try:
                                    result_data = json.loads(mcp_result)
                                except:
                                    # ë§ˆí¬ë‹¤ìš´ íŒŒì‹±
                                    results = []
                                    lines = mcp_result.strip().split('\n')
                                    current_result = None
                                    
                                    for line in lines:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        
                                        link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', line)
                                        if link_match:
                                            if current_result:
                                                results.append(current_result)
                                            title = link_match.group(1)
                                            url = link_match.group(2)
                                            current_result = {"title": title, "url": url, "snippet": ""}
                                        elif current_result and line:
                                            if current_result["snippet"]:
                                                current_result["snippet"] += " " + line
                                            else:
                                                current_result["snippet"] = line
                                    
                                    if current_result:
                                        results.append(current_result)
                                    
                                    if results:
                                        result_data = {"results": results}
                                    else:
                                        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸
                                        result_data = {"result": mcp_result}
                            else:
                                result_data = mcp_result if isinstance(mcp_result, dict) else {"result": mcp_result}

                            execution_time = time.time() - start_time

                            # MCP ë„êµ¬ ì„±ê³µ ê²°ê³¼ í‘œì‹œ
                            result_summary = ""
                            if isinstance(result_data, dict):
                                if 'results' in result_data and isinstance(result_data['results'], list):
                                    result_count = len(result_data['results'])
                                    result_summary = f"{result_count}ê°œ ê²°ê³¼ ë°˜í™˜ë¨"
                                elif 'result' in result_data:
                                    result_summary = f"ê²°ê³¼ ë°˜í™˜ë¨ ({type(result_data['result']).__name__})"
                                else:
                                    result_summary = f"ë°ì´í„° ë°˜í™˜ë¨ ({len(result_data)}ê°œ í•„ë“œ)"
                            else:
                                result_summary = f"ê²°ê³¼ ë°˜í™˜ë¨ ({type(result_data).__name__})"

                            tool_exec_result = ToolExecutionResult(
                                tool_name=tool_name,
                                success=True,
                                execution_time=execution_time,
                                result_summary=result_summary,
                                confidence=0.9
                            )
                            await output_manager.output_tool_execution(tool_exec_result)

                            result_dict = {
                                "success": True,
                                "data": result_data,
                                "error": None,
                                "execution_time": execution_time,
                                "confidence": 0.9,
                                "source": "mcp"
                            }
                            
                            # 9ëŒ€ í˜ì‹ : ToolTrace ìƒì„±
                            _create_tool_trace(
                                tool_id=tool_id,
                                citation_id=citation_id or f"TEMP-{tool_id}",
                                tool_type=tool_type,
                                query=query_str,
                                result=result_dict,
                                mcp_server=mcp_server,
                                mcp_tool_name=mcp_tool_name,
                            )
                            
                            return result_dict
                    except Exception as mcp_error:
                        execution_time = time.time() - start_time
                        logger.error(f"[MCP][exec.error] server={server_name} tool={tool_name} err={mcp_error}")

                        # MCP ì‹¤í–‰ ì‹¤íŒ¨ ê²°ê³¼ í‘œì‹œ
                        tool_exec_result = ToolExecutionResult(
                            tool_name=tool_name,
                            success=False,
                            execution_time=execution_time,
                            result_summary=f"MCP ì‹¤í–‰ ì‹¤íŒ¨: {str(mcp_error)[:100]}...",
                            confidence=0.0,
                            error_message=str(mcp_error)
                        )
                        await output_manager.output_tool_execution(tool_exec_result)

                        # MCP ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°˜í™˜ (fallback ì œê±°)
                        return {
                            "success": False,
                            "data": None,
                            "error": f"MCP tool execution failed: {str(mcp_error)}",
                            "execution_time": execution_time,
                            "confidence": 0.0,
                            "source": "mcp"
                        }
            
            # MCP ë„êµ¬ê°€ ì•„ë‹Œ ê²½ìš° ë¡œì»¬ ë„êµ¬ í™•ì¸
            tool_info = self.registry.get_tool_info(tool_name)
            if tool_info and self.registry.tool_sources.get(tool_name) == "local":
                # ë¡œì»¬ ë„êµ¬ ì‹¤í–‰
                logger.info(f"[MCP][exec.local] Executing local tool: {tool_name}")
                try:
                    # ë¡œì»¬ ë„êµ¬ëŠ” ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë‹¤ë¥¸ ì‹¤í–‰ í•¨ìˆ˜ ì‚¬ìš©
                    category = tool_info.category
                    
                    if category == ToolCategory.SEARCH:
                        from src.core.mcp_integration import _execute_search_tool, ToolResult
                        tool_result = await _execute_search_tool(tool_name, parameters)
                    elif category == ToolCategory.DATA:
                        from src.core.mcp_integration import _execute_data_tool
                        tool_result = await _execute_data_tool(tool_name, parameters)
                    elif category == ToolCategory.CODE:
                        from src.core.mcp_integration import _execute_code_tool
                        tool_result = await _execute_code_tool(tool_name, parameters)
                    elif category == ToolCategory.ACADEMIC:
                        from src.core.mcp_integration import _execute_academic_tool
                        tool_result = await _execute_academic_tool(tool_name, parameters)
                    elif category == ToolCategory.GIT:
                        from src.core.mcp_integration import _execute_git_tool
                        tool_result = await _execute_git_tool(tool_name, parameters)
                    else:
                        # ê¸°ë³¸ì ìœ¼ë¡œ ë°ì´í„° ë„êµ¬ë¡œ ì²˜ë¦¬
                        from src.core.mcp_integration import _execute_data_tool
                        tool_result = await _execute_data_tool(tool_name, parameters)
                    
                    execution_time = time.time() - start_time
                    
                    # ê²°ê³¼ ìš”ì•½ ìƒì„±
                    result_summary = ""
                    if tool_result.success and tool_result.data:
                        if isinstance(tool_result.data, dict):
                            if 'results' in tool_result.data:
                                result_count = len(tool_result.data['results'])
                                result_summary = f"{result_count}ê°œ ê²°ê³¼ ë°˜í™˜ë¨"
                            elif 'content' in tool_result.data:
                                content_len = len(str(tool_result.data['content']))
                                result_summary = f"ì½˜í…ì¸  ë°˜í™˜ë¨ ({content_len}ì)"
                            else:
                                result_summary = f"ë°ì´í„° ë°˜í™˜ë¨ ({type(tool_result.data).__name__})"
                        else:
                            result_summary = f"ê²°ê³¼ ë°˜í™˜ë¨ ({type(tool_result.data).__name__})"
                    elif tool_result.error:
                        result_summary = f"ì˜¤ë¥˜: {tool_result.error[:100]}..."
                    
                    tool_exec_result = ToolExecutionResult(
                        tool_name=tool_name,
                        success=tool_result.success,
                        execution_time=execution_time,
                        result_summary=result_summary,
                        confidence=tool_result.confidence,
                        error_message=tool_result.error
                    )
                    await output_manager.output_tool_execution(tool_exec_result)
                    
                    result_dict = {
                        "success": tool_result.success,
                        "data": tool_result.data,
                        "error": tool_result.error,
                        "execution_time": execution_time,
                        "confidence": tool_result.confidence,
                        "source": "local"
                    }
                    
                    # 9ëŒ€ í˜ì‹ : ToolTrace ìƒì„±
                    _create_tool_trace(
                        tool_id=tool_id,
                        citation_id=citation_id or f"TEMP-{tool_id}",
                        tool_type=tool_type,
                        query=query_str,
                        result=result_dict,
                        mcp_server=mcp_server,
                        mcp_tool_name=mcp_tool_name,
                    )
                    
                    return result_dict
                    
                except Exception as local_error:
                    execution_time = time.time() - start_time
                    logger.error(f"[MCP][exec.local.error] Local tool execution failed: {local_error}")
                    
                    tool_exec_result = ToolExecutionResult(
                        tool_name=tool_name,
                        success=False,
                        execution_time=execution_time,
                        result_summary=f"ë¡œì»¬ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {str(local_error)[:100]}...",
                        confidence=0.0,
                        error_message=str(local_error)
                    )
                    await output_manager.output_tool_execution(tool_exec_result)
                    
                    return {
                        "success": False,
                        "data": None,
                        "error": f"Local tool execution failed: {str(local_error)}",
                        "execution_time": execution_time,
                        "confidence": 0.0,
                        "source": "local"
                    }
            
            # MCP ë„êµ¬ë„ ë¡œì»¬ ë„êµ¬ë„ ì•„ë‹Œ ê²½ìš° MCP Builder ì‹œë„
            if self.config.builder_enabled:
                logger.info(f"[MCP][builder] Tool '{tool_name}' not available, attempting auto-build...")
                try:
                    from src.core.mcp_server_builder import get_mcp_server_builder
                    builder = get_mcp_server_builder()
                    
                    # ì„œë²„ ë¹Œë“œ
                    build_result = await builder.build_mcp_server(
                        tool_name=tool_name,
                        parameters=parameters,
                        error_context=f"Tool not found in MCP servers or local tools"
                    )
                    
                    if build_result.get("success"):
                        server_name = build_result["server_name"]
                        server_path = build_result["server_path"]
                        
                        logger.info(f"[MCP][builder] Server built successfully: {server_name}")
                        
                        # ë™ì  ì„œë²„ ë“±ë¡
                        registered = await self._register_dynamic_server(server_name, server_path)
                        
                        if registered:
                            logger.info(f"[MCP][builder] Server registered: {server_name}, retrying tool execution...")
                            # ë„êµ¬ ì‹¤í–‰ ì¬ì‹œë„
                            return await self.execute_tool(tool_name, parameters)
                        else:
                            logger.warning(f"[MCP][builder] Failed to register server: {server_name}")
                    else:
                        logger.warning(f"[MCP][builder] Server build failed: {build_result.get('error')}")
                except Exception as builder_error:
                    logger.error(f"[MCP][builder] Builder error: {builder_error}", exc_info=True)
            
            # MCP ë„êµ¬ë„ ë¡œì»¬ ë„êµ¬ë„ ì•„ë‹Œ ê²½ìš° ì—ëŸ¬ ë°˜í™˜
            error_msg = f"Tool '{tool_name}' is not available (neither MCP nor local)"
            execution_time = time.time() - start_time
            logger.error(f"[MCP][exec.error] {error_msg}")

            # ë„êµ¬ ì—†ìŒ ê²°ê³¼ í‘œì‹œ
            tool_exec_result = ToolExecutionResult(
                tool_name=tool_name,
                success=False,
                execution_time=execution_time,
                result_summary="ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ (MCP ì„œë²„ ë° ë¡œì»¬ ë„êµ¬ ëª¨ë‘ í™•ì¸ë¨)",
                confidence=0.0,
                error_message=error_msg
            )
            await output_manager.output_tool_execution(tool_exec_result)

            return {
                "success": False,
                "data": None,
                "error": error_msg,
                "execution_time": execution_time,
                "confidence": 0.0,
                "source": "unknown"
            }

        except Exception as e:
            execution_time = time.time() - start_time
            logger.exception(f"[MCP][exec.error] tool={tool_name} err={e}")

            # ì¼ë°˜ ì˜ˆì™¸ ê²°ê³¼ í‘œì‹œ
            tool_exec_result = ToolExecutionResult(
                tool_name=tool_name,
                success=False,
                execution_time=execution_time,
                result_summary=f"ì˜ˆì™¸ ë°œìƒ: {str(e)[:100]}...",
                confidence=0.0,
                error_message=str(e)
            )
            await output_manager.output_tool_execution(tool_exec_result)

            return {
                "success": False,
                "data": None,
                "error": str(e),
                "execution_time": execution_time,
                "confidence": 0.0
            }
    
    def get_tool_for_category(self, category: ToolCategory) -> Optional[str]:
        """ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë„êµ¬ ë°˜í™˜ - Registry ê¸°ë°˜."""
        tools_in_category = self.registry.get_tools_by_category(category)
        return tools_in_category[0] if tools_in_category else None
    
    def get_available_tools(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜ - Registry ê¸°ë°˜."""
        # Registryì˜ ëª¨ë“  Tool ì´ë¦„ ë°˜í™˜
        return self.registry.get_all_tool_names()
    
    async def get_tool_for_execution(self, tool_name: str, execution_id: Optional[str] = None) -> Optional[Any]:
        """
        ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ë³„ ë„êµ¬ ë°˜í™˜ (ROMA ìŠ¤íƒ€ì¼).
        
        ê° ì‹¤í–‰ë§ˆë‹¤ ë…ë¦½ì ì¸ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê´€ë¦¬í•˜ì—¬ ì‹¤í–‰ ê°„ ê²©ë¦¬ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
        
        Args:
            tool_name: ë„êµ¬ ì´ë¦„
            execution_id: ì‹¤í–‰ ID (Noneì´ë©´ ExecutionContextì—ì„œ ê°€ì ¸ì˜´)
        
        Returns:
            ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
        """
        # ExecutionContextì—ì„œ execution_id ê°€ì ¸ì˜¤ê¸°
        if execution_id is None:
            try:
                from src.core.recursive_context_manager import ExecutionContext
                ctx = ExecutionContext.get()
                if ctx:
                    execution_id = ctx.execution_id
            except Exception:
                pass
        
        # execution_idê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë„êµ¬ ë°˜í™˜ (í•˜ìœ„ í˜¸í™˜ì„±)
        if not execution_id:
            return self.registry.get_tool(tool_name)
        
        # ì‹¤í–‰ë³„ ì„¸ì…˜ ì´ˆê¸°í™”
        if execution_id not in self._execution_sessions:
            self._execution_sessions[execution_id] = {
                'tools': {},
                'created_at': datetime.now()
            }
        
        execution_session = self._execution_sessions[execution_id]
        
        # ë„êµ¬ê°€ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìœ¼ë©´ ë°˜í™˜
        if tool_name in execution_session['tools']:
            return execution_session['tools'][tool_name]
        
        # ë„êµ¬ ì´ˆê¸°í™” ë° ìºì‹±
        # LangChain Toolì´ ìˆìœ¼ë©´ ë°˜í™˜, ì—†ìœ¼ë©´ ToolInfo ë°˜í™˜
        tool = self.registry.get_langchain_tool(tool_name)
        if not tool:
            # LangChain Toolì´ ì—†ìœ¼ë©´ ToolInfo ë°˜í™˜
            tool = self.registry.get_tool_info(tool_name)
        
        if tool:
            execution_session['tools'][tool_name] = tool
            logger.debug(f"Tool {tool_name} cached for execution {execution_id}")
        
        return tool
    
    async def cleanup_execution(self, execution_id: str):
        """
        ì‹¤í–‰ ì¢…ë£Œ ì‹œ ì„¸ì…˜ ì •ë¦¬ (ROMA ìŠ¤íƒ€ì¼).
        
        ì‹¤í–‰ë³„ë¡œ ê´€ë¦¬ëœ ë„êµ¬ ì¸ìŠ¤í„´ìŠ¤ì™€ ì„¸ì…˜ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            execution_id: ì •ë¦¬í•  ì‹¤í–‰ ID
        """
        if execution_id in self._execution_sessions:
            session = self._execution_sessions[execution_id]
            tools_count = len(session.get('tools', {}))
            
            # ì„¸ì…˜ ì •ë¦¬
            del self._execution_sessions[execution_id]
            
            logger.info(f"Cleaned up execution session {execution_id} ({tools_count} tools)")
        else:
            logger.debug(f"Execution session {execution_id} not found (already cleaned up?)")
    
    def get_all_langchain_tools(self) -> List[BaseTool]:
        """ëª¨ë“  LangChain Tool ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
        if not LANGCHAIN_AVAILABLE:
            logger.warning("LangChain not available")
            return []
        return self.registry.get_all_langchain_tools()
    
    async def check_mcp_servers(self) -> Dict[str, Any]:
        """ëª¨ë“  MCP ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸ - mcp_config.jsonì— ì •ì˜ëœ ëª¨ë“  ì„œë²„."""
        server_status = {
            "timestamp": datetime.now().isoformat(),
            "total_servers": len(self.mcp_server_configs),
            "connected_servers": len(self.mcp_sessions),
            "servers": {}
        }
        
        logger.info(f"Checking {len(self.mcp_server_configs)} MCP servers...")
        
        for server_name, server_config in self.mcp_server_configs.items():
            server_info = {
                "name": server_name,
                "type": server_config.get("type", "stdio"),
                "connected": server_name in self.mcp_sessions,
                "tools_count": 0,
                "tools": [],
                "error": None
            }
            
            # ì—°ê²° íƒ€ì… ì •ë³´
            if server_config.get("type") == "http" or "httpUrl" in server_config or "url" in server_config:
                server_info["type"] = "http"
                server_info["url"] = server_config.get("httpUrl") or server_config.get("url", "unknown")
            else:
                server_info["type"] = "stdio"
                server_info["command"] = server_config.get("command", "unknown")
                server_info["args"] = server_config.get("args", [])
            
            # ì—°ê²° ìƒíƒœ í™•ì¸
            if server_name in self.mcp_sessions:
                session = self.mcp_sessions[server_name]
                # ì„¸ì…˜ì´ ìœ íš¨í•œì§€ í™•ì¸
                try:
                    if hasattr(session, '_transport') and session._transport:
                        server_info["connected"] = True
                    else:
                        server_info["connected"] = False
                        server_info["error"] = "Session transport not available"
                except:
                    server_info["connected"] = False
                    server_info["error"] = "Session check failed"
                
                # ì œê³µí•˜ëŠ” Tool ëª©ë¡ í™•ì¸
                if server_name in self.mcp_tools_map:
                    tools = self.mcp_tools_map[server_name]
                    server_info["tools_count"] = len(tools)
                    server_info["tools"] = list(tools.keys())
                    
                    # ë“±ë¡ëœ Tool ì´ë¦„ (server_name::tool_name í˜•ì‹)
                    registered_tools = [
                        name for name in self.registry.get_all_tool_names()
                        if name.startswith(f"{server_name}::")
                    ]
                    server_info["registered_tools"] = registered_tools
                else:
                    server_info["tools_count"] = 0
                    server_info["tools"] = []
                    server_info["error"] = "No tools discovered"
            else:
                server_info["connected"] = False
                server_info["error"] = "Not connected"
                # ì—°ê²° ì‹œë„ëŠ” í•˜ì§€ ì•ŠìŒ (ë³„ë„ì˜ initialize_mcp í˜¸ì¶œ í•„ìš”)
                # check_mcp_serversëŠ” ìƒíƒœ í™•ì¸ë§Œ ìˆ˜í–‰
            
            server_status["servers"][server_name] = server_info
        
        # í†µê³„ ìš”ì•½
        connected = sum(1 for s in server_status["servers"].values() if s["connected"])
        total_tools = sum(s["tools_count"] for s in server_status["servers"].values())
        
        server_status["summary"] = {
            "connected_servers": connected,
            "total_servers": len(self.mcp_server_configs),
            "total_tools_available": total_tools,
            "connection_rate": f"{connected}/{len(self.mcp_server_configs)}"
        }
        
        return server_status
    
    async def health_check(self) -> Dict[str, Any]:
        """ê°•í™”ëœ í—¬ìŠ¤ ì²´í¬ - OpenRouter, Gemini 2.5 Flash Lite, MCP ë„êµ¬ ê²€ì¦."""
        try:
            health_status = {
                "mcp_enabled": self.config.enabled,
                "tools_available": len(self.tools),
                "timestamp": datetime.now().isoformat()
            }
            
            # 1. OpenRouter ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                test_messages = [
                    {"role": "system", "content": "Health check test."},
                    {"role": "user", "content": "Respond with 'OK' if you can process this request."}
                ]
                
                test_response = await self.openrouter_client.generate_response(
                    model=self.llm_config.primary_model,
                    messages=test_messages,
                    temperature=0.1,
                    max_tokens=50
                )
                
                openrouter_healthy = test_response and "choices" in test_response
                health_status.update({
                    "openrouter_connected": openrouter_healthy,
                    "primary_model": self.llm_config.primary_model,
                    "rate_limit_remaining": getattr(self.openrouter_client, 'rate_limit_remaining', 'unknown')
                })
                
                if not openrouter_healthy:
                    health_status["overall_health"] = "unhealthy"
                    health_status["critical_error"] = "OpenRouter connection failed"
                    return health_status
                    
            except Exception as e:
                health_status.update({
                    "openrouter_connected": False,
                    "openrouter_error": str(e),
                    "overall_health": "unhealthy",
                    "critical_error": f"OpenRouter health check failed: {e}"
                })
                return health_status
            
            # 2. í•„ìˆ˜ MCP ë„êµ¬ ê²€ì¦
            essential_tools = ["g-search", "fetch", "filesystem"]
            tool_health = {}
            failed_tools = []
            
            for tool in essential_tools:
                try:
                    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                    if tool == "g-search":
                        test_result = await execute_tool(tool, {"query": "test", "max_results": 1})
                    elif tool == "fetch":
                        test_result = await execute_tool(tool, {"url": "https://httpbin.org/get"})
                    elif tool == "filesystem":
                        test_result = await execute_tool(tool, {"path": ".", "operation": "list"})
                    
                    tool_health[tool] = test_result.get('success', False)
                    if not test_result.get('success', False):
                        failed_tools.append(tool)
                        
                except Exception as e:
                    tool_health[tool] = False
                    failed_tools.append(tool)
                    logger.warning(f"Tool {tool} health check failed: {e}")
            
            health_status.update({
                "tool_health": tool_health,
                "failed_tools": failed_tools,
                "essential_tools_healthy": len(failed_tools) == 0
            })
            
            # 3. ì „ì²´ ìƒíƒœ ê²°ì •
            if len(failed_tools) > 0:
                health_status["overall_health"] = "unhealthy"
                health_status["critical_error"] = f"Essential tools failed: {', '.join(failed_tools)}"
            else:
                health_status["overall_health"] = "healthy"
            
            return health_status
            
        except Exception as e:
            return {
                "mcp_enabled": self.config.enabled,
                "tools_available": len(self.tools),
                "openrouter_connected": False,
                "error": str(e),
                "overall_health": "unhealthy",
                "critical_error": f"Health check failed: {e}",
                "timestamp": datetime.now().isoformat()
            }


# Global MCP Hub instance (lazy initialization)
_mcp_hub = None

def get_mcp_hub() -> 'UniversalMCPHub':
    """Get or initialize global MCP Hub."""
    global _mcp_hub
    if _mcp_hub is None:
        _mcp_hub = UniversalMCPHub()
    return _mcp_hub

async def get_available_tools() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ë°˜í™˜."""
    mcp_hub = get_mcp_hub()
    return mcp_hub.get_available_tools()


async def execute_tool(tool_name: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """MCP ë„êµ¬ ì‹¤í–‰ - UniversalMCPHubì˜ execute_tool ì‚¬ìš© (with caching)."""
    from src.core.result_cache import get_result_cache
    
    result_cache = get_result_cache()
    
    # ìºì‹œ í™•ì¸
    cached_result = await result_cache.get(
        tool_name=tool_name,
        parameters=parameters,
        check_similarity=True
    )
    
    if cached_result:
        logger.debug(f"[MCP][execute_tool] Cache hit for {tool_name}")
        return cached_result
    
    # MCP Hub ì‹¤í–‰
    mcp_hub = get_mcp_hub()
    
    # MCP Hubê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì´ˆê¸°í™”
    if not mcp_hub.mcp_sessions:
        logger.info("[MCP][execute_tool] MCP Hub not initialized, initializing...")
        await mcp_hub.initialize_mcp()
    
    result = await mcp_hub.execute_tool(tool_name, parameters)
    
    # ì„±ê³µí•œ ê²°ê³¼ë§Œ ìºì‹œì— ì €ì¥
    if result.get("success", False):
        # TTL ê²°ì •: ê²€ìƒ‰/ë°ì´í„° ë„êµ¬ëŠ” 1ì‹œê°„, ë‹¤ë¥¸ ë„êµ¬ëŠ” 30ë¶„
        ttl = 3600 if any(keyword in tool_name.lower() for keyword in ['search', 'fetch', 'data']) else 1800
        await result_cache.set(
            tool_name=tool_name,
            parameters=parameters,
            value=result,
            ttl=ttl
        )
        logger.debug(f"[MCP][execute_tool] Cached result for {tool_name}")
    
    return result


# ë™ê¸°í™” í—¬í¼ í•¨ìˆ˜ë“¤ (LangChain Toolìš©)
def _execute_search_tool_sync(tool_name: str, parameters: Dict[str, Any]) -> str:
    """ë™ê¸° ë²„ì „ - LangChain Toolì—ì„œ í˜¸ì¶œ."""
    try:
        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        import concurrent.futures
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, _execute_search_tool(tool_name, parameters))
                    # timeout ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
                    result = future.result(timeout=300)  # ìµœëŒ€ 5ë¶„
            else:
                result = loop.run_until_complete(_execute_search_tool(tool_name, parameters))
        except RuntimeError:
            # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            result = asyncio.run(_execute_search_tool(tool_name, parameters))
        
        if result.success:
            import json
            return json.dumps(result.data, ensure_ascii=False, indent=2)
        else:
            raise RuntimeError(result.error or "Tool execution failed")
    except Exception as e:
        raise RuntimeError(f"Tool execution failed: {str(e)}")

def _execute_academic_tool_sync(tool_name: str, parameters: Dict[str, Any]) -> str:
    """ë™ê¸° ë²„ì „ - LangChain Toolì—ì„œ í˜¸ì¶œ."""
    try:
        import concurrent.futures
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, _execute_academic_tool(tool_name, parameters))
                    # timeout ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
                    result = future.result(timeout=300)  # ìµœëŒ€ 5ë¶„
            else:
                result = loop.run_until_complete(_execute_academic_tool(tool_name, parameters))
        except RuntimeError:
            result = asyncio.run(_execute_academic_tool(tool_name, parameters))
        
        if result.success:
            import json
            return json.dumps(result.data, ensure_ascii=False, indent=2)
        else:
            raise RuntimeError(result.error or "Tool execution failed")
    except Exception as e:
        raise RuntimeError(f"Tool execution failed: {str(e)}")

def _execute_data_tool_sync(tool_name: str, parameters: Dict[str, Any]) -> str:
    """ë™ê¸° ë²„ì „ - LangChain Toolì—ì„œ í˜¸ì¶œ."""
    try:
        import concurrent.futures
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, _execute_data_tool(tool_name, parameters))
                    # timeout ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
                    result = future.result(timeout=300)  # ìµœëŒ€ 5ë¶„
            else:
                result = loop.run_until_complete(_execute_data_tool(tool_name, parameters))
        except RuntimeError:
            result = asyncio.run(_execute_data_tool(tool_name, parameters))
        
        if result.success:
            import json
            return json.dumps(result.data, ensure_ascii=False, indent=2)
        else:
            raise RuntimeError(result.error or "Tool execution failed")
    except Exception as e:
        raise RuntimeError(f"Tool execution failed: {str(e)}")

def _execute_code_tool_sync(tool_name: str, parameters: Dict[str, Any]) -> str:
    """ë™ê¸° ë²„ì „ - LangChain Toolì—ì„œ í˜¸ì¶œ."""
    try:
        import concurrent.futures
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, _execute_code_tool(tool_name, parameters))
                    # timeout ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
                    result = future.result(timeout=300)  # ìµœëŒ€ 5ë¶„
            else:
                result = loop.run_until_complete(_execute_code_tool(tool_name, parameters))
        except RuntimeError:
            result = asyncio.run(_execute_code_tool(tool_name, parameters))
        
        if result.success:
            import json
            return json.dumps(result.data, ensure_ascii=False, indent=2)
        else:
            raise RuntimeError(result.error or "Tool execution failed")
    except Exception as e:
        raise RuntimeError(f"Tool execution failed: {str(e)}")


# DuckDuckGo ìš”ì²­ ë¹ˆë„ ì œí•œì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
_ddg_last_request_time = {}
_ddg_request_lock = None

def _get_ddg_lock():
    """DuckDuckGo ìš”ì²­ ë½ì„ ì§€ì—° ì´ˆê¸°í™”."""
    global _ddg_request_lock
    if _ddg_request_lock is None:
        _ddg_request_lock = asyncio.Lock()
    return _ddg_request_lock

async def _fallback_to_ddg_search(query: str, max_results: int) -> ToolResult:
    """MCP ì„œë²„ ì‹¤íŒ¨ ì‹œ DDG searchë¡œ fallback."""
    try:
        from src.core.tools.native_search import search_duckduckgo_json
        
        logger.info(f"[MCP][fallback] Using DDG search fallback for query: {query}")
        result = search_duckduckgo_json(query, max_results)
        
        if result and isinstance(result, dict):
            results = result.get("results", [])
            if results:
                return ToolResult(
                    success=True,
                    data={"results": results, "total_results": len(results)},
                    tool_name="ddg_search",
                    source="native_ddg_fallback"
                )
        
        # ê²°ê³¼ê°€ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
        return ToolResult(
            success=False,
            data=None,
            error="DDG search fallback returned no results",
            tool_name="ddg_search",
            source="native_ddg_fallback"
        )
    except Exception as e:
        logger.error(f"[MCP][fallback] DDG search fallback failed: {e}")
        return ToolResult(
            success=False,
            data=None,
            error=f"DDG search fallback error: {str(e)}",
            tool_name="ddg_search",
            source="native_ddg_fallback"
        )

async def _execute_search_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """ê²€ìƒ‰ ë„êµ¬ ì‹¤í–‰ - src/utilsì—ì„œ ì§ì ‘ ì‚¬ìš©."""
    import time
    start_time = time.time()
    
    # src/utilsì—ì„œ ì§ì ‘ ì‚¬ìš© (MCP ì„œë²„ë¡œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)
    try:
        from src.utils.search_utils import search_duckduckgo
        
        query = parameters.get("query", "")
        num_results = parameters.get("num_results", 10) or parameters.get("max_results", 10)
        
        if not query:
            return ToolResult(
                success=False,
                data=None,
                error="query parameter is required",
                execution_time=time.time() - start_time,
                confidence=0.0
            )
        
        # src/utilsì˜ search_duckduckgo ì§ì ‘ í˜¸ì¶œ
        result = await search_duckduckgo(query, num_results)
        
        if result.get("success"):
            return ToolResult(
                success=True,
                data={
                    "query": query,
                    "results": result.get("results", []),
                    "count": result.get("count", 0),
                    "provider": result.get("provider", "duckduckgo"),
                    "source": "embedded_search"
                },
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        else:
            return ToolResult(
                success=False,
                data=None,
                error=result.get("error", "Search failed"),
                execution_time=time.time() - start_time,
                confidence=0.0
            )
    except ImportError:
        # embedded_mcp_serversê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        logger.debug("src.utils.search_utils not available, using existing MCP server logic")
    except Exception as e:
        logger.warning(f"Embedded search failed: {e}, falling back to MCP servers")
        # ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ fallback
    else:
        # src/utils ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë¨
        return
    
    # ê¸°ì¡´ ë¡œì§ (MCP ì„œë²„ ì—°ê²° ì‹œë„) - src/utils ì‹¤íŒ¨ ì‹œì—ë§Œ ì‹¤í–‰
    """MCP ì„œë²„ë¥¼ í†µí•œ ê²€ìƒ‰ ë„êµ¬ ì‹¤í–‰ (with caching and bot detection bypass)."""
    import time
    from src.core.result_cache import get_result_cache
    
    # ToolResultëŠ” ì´ë¯¸ íŒŒì¼ ìƒë‹¨ì—ì„œ ì •ì˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ import ë¶ˆí•„ìš”
    start_time = time.time()
    query = parameters.get("query", "")
    max_results = parameters.get("max_results", 10) or parameters.get("num_results", 10)
    
    # DuckDuckGo ìš”ì²­ ë¹ˆë„ ì œí•œ (ë™ì‹œ ìš”ì²­ ë°©ì§€)
    global _ddg_last_request_time
    
    # ìºì‹œ í™•ì¸
    result_cache = get_result_cache()
    cached_result = await result_cache.get(
        tool_name=tool_name,
        parameters=parameters,
        check_similarity=True
    )
    
    if cached_result:
        logger.debug(f"[MCP][_execute_search_tool] Cache hit for {tool_name}")
        # ToolResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return ToolResult(
            success=cached_result.get("success", False),
            data=cached_result.get("data"),
            error=cached_result.get("error"),
            execution_time=cached_result.get("execution_time", 0.0),
            confidence=cached_result.get("confidence", 0.8)
        )
    
    try:
        # ëª¨ë“  ê²€ìƒ‰ ë„êµ¬ë¥¼ g-searchì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
        if tool_name in ["g-search", "ddg_search", "mcp_search"]:
            # mcp_config.jsonì— ì •ì˜ëœ ëª¨ë“  MCP ì„œë²„ì—ì„œ ê²€ìƒ‰ ì‹œë„
            mcp_hub = get_mcp_hub()
            
            # MCP ì„œë²„ ì—°ê²° í™•ì¸ ë° ì¬ì—°ê²°
            if not mcp_hub.mcp_sessions:
                logger.warning("No MCP servers connected, attempting to initialize...")
                try:
                    await mcp_hub.initialize_mcp()
                except Exception as e:
                    logger.warning(f"Failed to initialize MCP servers: {e}")
            
            # ê²€ìƒ‰ ì„œë²„ ëª©ë¡ (github ë“± ì‹¤íŒ¨í•˜ëŠ” ì„œë²„ ì œì™¸)
            # fetch, docfork, context7-mcp, github ë“±ì€ search ë„êµ¬ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•˜ë¯€ë¡œ ì œì™¸
            non_search_servers = {"fetch", "docfork", "context7-mcp", "github", "financial_agent", "TodoList"}
            
            # ê²€ìƒ‰ ê°€ëŠ¥í•œ ì„œë²„ë§Œ í•„í„°ë§
            all_servers = list(mcp_hub.mcp_server_configs.keys())
            search_servers = [s for s in all_servers if s not in non_search_servers]
            
            # ì´ë¯¸ ì—°ê²°ëœ ì„œë²„ ìš°ì„  ì‚¬ìš©
            connected_servers = [s for s in search_servers if s in mcp_hub.mcp_sessions]
            unconnected_servers = [s for s in search_servers if s not in mcp_hub.mcp_sessions]
            server_order = connected_servers + unconnected_servers
            
            logger.info(f"[MCP][_execute_search_tool] Trying search servers: {server_order}")
            
            # MCP ì„œë²„ê°€ ì—†ê±°ë‚˜ ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ DDG searchë¡œ ì¦‰ì‹œ fallback
            if not server_order:
                logger.warning("[MCP][_execute_search_tool] No MCP search servers available, using DDG search fallback")
                return await _fallback_to_ddg_search(query, max_results)
            
            # mcp_config.jsonì— ì •ì˜ëœ ëª¨ë“  ì„œë²„ í™•ì¸ (ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ)
            failed_servers = []  # ì‹¤íŒ¨í•œ ì„œë²„ ì¶”ì 
            for server_name in server_order:
                logger.info(f"[MCP][_execute_search_tool] ğŸ” Attempting server {server_name} ({server_order.index(server_name) + 1}/{len(server_order)})")
                
                # ì—°ê²°ì´ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ì—°ê²° ì‹œë„ (íƒ€ì„ì•„ì›ƒ 10ì´ˆë¡œ ì œí•œ, ì¬ì‹œë„ ë¡œì§ í¬í•¨)
                if server_name not in mcp_hub.mcp_sessions:
                    logger.info(f"MCP server {server_name} not connected, attempting connection (timeout: 10s)...")
                    server_config = mcp_hub.mcp_server_configs[server_name]
                    
                    # ì¬ì‹œë„ ë¡œì§: íƒ€ì„ì•„ì›ƒì´ë‚˜ ì¼ì‹œì  ì—ëŸ¬ëŠ” ì¬ì‹œë„
                    max_connection_retries = 3
                    connection_success = False
                    
                    for retry_attempt in range(max_connection_retries):
                        try:
                            # íƒ€ì„ì•„ì›ƒ 10ì´ˆë¡œ ì œí•œí•˜ì—¬ ë¹ ë¥´ê²Œ ì‹¤íŒ¨
                            success = await asyncio.wait_for(
                                mcp_hub._connect_to_mcp_server(server_name, server_config),
                                timeout=10.0
                            )
                            if success:
                                connection_success = True
                                logger.info(f"[MCP][_execute_search_tool] âœ… Successfully connected to {server_name} (attempt {retry_attempt + 1}/{max_connection_retries})")
                                break
                            else:
                                # ì—°ê²° ì‹¤íŒ¨ (ì„œë²„ê°€ False ë°˜í™˜)
                                if retry_attempt < max_connection_retries - 1:
                                    wait_time = 2 ** retry_attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ
                                    logger.warning(f"[MCP][_execute_search_tool] âš ï¸ Connection to {server_name} failed (attempt {retry_attempt + 1}/{max_connection_retries}), retrying in {wait_time}s...")
                                    await asyncio.sleep(wait_time)
                                    continue
                                else:
                                    logger.warning(f"[MCP][_execute_search_tool] âŒ Failed to connect to MCP server {server_name} after {max_connection_retries} attempts")
                                    failed_servers.append({"server": server_name, "reason": "connection_failed"})
                                    break

                        except asyncio.TimeoutError:
                            # íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ëŠ” ì¬ì‹œë„ ê°€ëŠ¥
                            if retry_attempt < max_connection_retries - 1:
                                wait_time = 2 ** retry_attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ
                                logger.warning(f"[MCP][_execute_search_tool] âš ï¸ MCP server {server_name} connection timeout (10s, attempt {retry_attempt + 1}/{max_connection_retries}), retrying in {wait_time}s...")
                                await asyncio.sleep(wait_time)
                                continue
                            else:
                                logger.warning(f"[MCP][_execute_search_tool] âŒ MCP server {server_name} connection timeout after {max_connection_retries} attempts, skipping...")
                                failed_servers.append({"server": server_name, "reason": "timeout"})
                                break

                        except Exception as e:
                            error_str = str(e).lower()
                            error_msg = str(e)
                            
                            # npm ENOTEMPTY ì˜¤ë¥˜ëŠ” ë””ë ‰í† ë¦¬ ê´€ë ¨ ë¬¸ì œë¡œ, ì¬ì‹œë„ ë¶ˆí•„ìš”
                            is_npm_enotempty = "enotempty" in error_str or ("npm error" in error_str and "directory not empty" in error_str)
                            
                            # Connection closed ì˜¤ë¥˜ëŠ” ì„œë²„ ì—°ê²° ì‹¤íŒ¨ë¡œ, ì¬ì‹œë„ ë¶ˆí•„ìš”
                            is_connection_closed = "connection closed" in error_str or "client failed to connect" in error_str
                            
                            # ì¡°ìš©íˆ ì²˜ë¦¬í•  ì˜¤ë¥˜ë“¤ (ì¬ì‹œë„ ë¶ˆí•„ìš”)
                            if is_npm_enotempty or is_connection_closed:
                                logger.debug(f"[MCP][_execute_search_tool] server={server_name} connection issue, skipping")
                                failed_servers.append({"server": server_name, "reason": "connection_issue"})
                                break
                            
                            # 504, 502, 503 ë“± ì„œë²„ ì—ëŸ¬ëŠ” ì¬ì‹œë„
                            is_retryable = any(code in error_str for code in ["504", "502", "503", "500", "gateway", "timeout", "unavailable"])

                            if is_retryable and retry_attempt < max_connection_retries - 1:
                                wait_time = 2 ** retry_attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„: 1ì´ˆ, 2ì´ˆ
                                logger.warning(f"[MCP][_execute_search_tool] âš ï¸ Error connecting to {server_name} (attempt {retry_attempt + 1}/{max_connection_retries}): {error_msg[:100]}, retrying in {wait_time}s...")
                                await asyncio.sleep(wait_time)
                                continue
                            else:
                                logger.debug(f"[MCP][_execute_search_tool] Error connecting to MCP server {server_name}: {error_msg[:100]}, skipping...")
                                failed_servers.append({"server": server_name, "reason": f"connection_error: {error_msg[:100]}"})
                                break
                    
                    if not connection_success:
                        # ì—°ê²° ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ì„œë²„ ì‹œë„
                        logger.warning(f"[MCP][_execute_search_tool] Failed to connect to {server_name}, trying next server...")
                        failed_servers.append({"server": server_name, "reason": "connection_failed"})
                        continue
                
                # ë„êµ¬ ë§µ í™•ì¸
                if server_name not in mcp_hub.mcp_tools_map:
                    logger.warning(f"[MCP][_execute_search_tool] âŒ MCP server {server_name} has no tools map")
                    failed_servers.append({"server": server_name, "reason": "no_tools_map"})
                    continue
                
                try:
                    tools = mcp_hub.mcp_tools_map[server_name]
                    if not tools:
                        logger.warning(f"[MCP][_execute_search_tool] âŒ MCP server {server_name} has no tools available")
                        failed_servers.append({"server": server_name, "reason": "no_tools_available"})
                        continue
                    
                    search_tool_name = None
                    
                    # ê²€ìƒ‰ ë„êµ¬ ì°¾ê¸° (search, query, ddg, tavily, web_search ë“± í‚¤ì›Œë“œë¡œ)
                    # ì„œë²„ë³„ ìš°ì„ ìˆœìœ„ ë„êµ¬ ì´ë¦„
                    server_specific_tools = {
                        "tavily-mcp": ["tavily-search", "search"],
                        "exa": ["web_search_exa", "search"],
                        "WebSearch-MCP": ["web_search", "search"],
                        "ddg_search": ["search", "query"],
                    }
                    
                    # ì„œë²„ë³„ ìš°ì„ ìˆœìœ„ ë„êµ¬ ë¨¼ì € ì°¾ê¸°
                    if server_name in server_specific_tools:
                        for preferred_tool in server_specific_tools[server_name]:
                            if preferred_tool in tools:
                                search_tool_name = preferred_tool
                                logger.info(f"Found preferred search tool '{search_tool_name}' in server {server_name}")
                                break
                    
                    # ìš°ì„ ìˆœìœ„ ë„êµ¬ë¥¼ ëª» ì°¾ìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰
                    if not search_tool_name:
                        for tool_name_key in tools.keys():
                            tool_lower = tool_name_key.lower()
                            if any(keyword in tool_lower for keyword in ["search", "query", "ddg", "tavily", "web_search"]):
                                search_tool_name = tool_name_key
                                logger.info(f"Found search tool '{search_tool_name}' in server {server_name}")
                                break
                    
                    if not search_tool_name:
                        logger.warning(f"[MCP][_execute_search_tool] âŒ No search tool found in MCP server {server_name}, available tools: {list(tools.keys())}")
                        failed_servers.append({"server": server_name, "reason": f"no_search_tool_found (available: {list(tools.keys())})"})
                        continue
                    
                    # DuckDuckGo ë´‡ ê°ì§€ ìš°íšŒ: Skyvern ìŠ¤íƒ€ì¼ ê°œì„  (ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì²­ íŒ¨í„´)
                    if server_name == "ddg_search":
                        async with _get_ddg_lock():
                            current_time = time.time()
                            
                            # ìš”ì²­ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (ìµœê·¼ 10ê°œë§Œ ìœ ì§€)
                            if server_name not in mcp_hub.request_timing_history:
                                mcp_hub.request_timing_history[server_name] = []
                            history = mcp_hub.request_timing_history[server_name]
                            
                            # ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ ì œê±° (ìµœê·¼ 1ì‹œê°„ ì´ë‚´ë§Œ ìœ ì§€)
                            history[:] = [t for t in history if current_time - t < 3600]
                            
                            # ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ í™•ì¸
                            if "last_request" in _ddg_last_request_time:
                                time_since_last = current_time - _ddg_last_request_time["last_request"]
                                min_interval = 2.0  # ìµœì†Œ 2ì´ˆ ê°„ê²©
                                
                                if time_since_last < min_interval:
                                    wait_time = min_interval - time_since_last
                                    logger.debug(f"[MCP][_execute_search_tool] Rate limiting: waiting {wait_time:.2f}s before DuckDuckGo request")
                                    await asyncio.sleep(wait_time)
                            
                            # Skyvern ìŠ¤íƒ€ì¼: ì¸ê°„ í–‰ë™ íŒ¨í„´ ëª¨ë°© - ê°€ë³€ ë”œë ˆì´
                            # íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ í‰ê·  ê°„ê²©ì„ ê³„ì‚°í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë³€ë™ì„± ì¶”ê°€
                            if len(history) > 0:
                                # í‰ê·  ê°„ê²© ê³„ì‚°
                                intervals = [history[i+1] - history[i] for i in range(len(history)-1)]
                                avg_interval = sum(intervals) / len(intervals) if intervals else 3.0
                                
                                # í‰ê·  ê°„ê²©ì„ ê¸°ì¤€ìœ¼ë¡œ Â±50% ë³€ë™ (ìµœì†Œ 1.5ì´ˆ, ìµœëŒ€ 5ì´ˆ)
                                base_delay = max(1.5, min(5.0, avg_interval * random.uniform(0.5, 1.5)))
                            else:
                                # ì²« ìš”ì²­: 2~4ì´ˆ ëœë¤ ë”œë ˆì´
                                base_delay = random.uniform(2.0, 4.0)
                            
                            # ì¶”ê°€ ë³€ë™ì„±: Â±0.5ì´ˆ ëœë¤ ì¶”ê°€ (ë” ìì—°ìŠ¤ëŸ¬ìš´ íŒ¨í„´)
                            delay = base_delay + random.uniform(-0.5, 0.5)
                            delay = max(1.5, delay)  # ìµœì†Œ 1.5ì´ˆ ë³´ì¥
                            
                            logger.debug(f"[MCP][_execute_search_tool] Skyvern-style delay: {delay:.2f}s before DuckDuckGo request (history: {len(history)} requests)")
                            await asyncio.sleep(delay)
                            
                            # ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ ì—…ë°ì´íŠ¸
                            _ddg_last_request_time["last_request"] = time.time()
                            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                            history.append(time.time())
                    
                    # ê²€ìƒ‰ ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨, ë´‡ ê°ì§€ ìš°íšŒ)
                    logger.info(f"Using MCP server {server_name} with tool {search_tool_name} for search: {query}")
                    result = None
                    max_retries = 3 if server_name == "ddg_search" else 1
                    bot_detection_indicators = ["bot detection", "no results were found", "try again"]
                    
                    for retry_attempt in range(max_retries):
                        try:
                            result = await mcp_hub._execute_via_mcp_server(
                                server_name,
                                search_tool_name,
                                {"query": query, "max_results": max_results}
                            )

                            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¬ì‹œë„
                            if not result:
                                if retry_attempt < max_retries - 1:
                                    wait_time = 2 * (2 ** retry_attempt)
                                    logger.debug(f"[MCP][_execute_search_tool] No result from {server_name}, retrying after {wait_time}s")
                                    await asyncio.sleep(wait_time)
                                    continue
                                break
                            
                            # ë´‡ ê°ì§€ ë©”ì‹œì§€ í™•ì¸ (DuckDuckGoë§Œ) - ì¦‰ì‹œ í™•ì¸
                            if server_name == "ddg_search" and result:
                                result_str = str(result).lower() if isinstance(result, str) else str(result).lower()
                                is_bot_detected = any(indicator in result_str for indicator in bot_detection_indicators)
                                
                                if is_bot_detected:
                                    if retry_attempt < max_retries - 1:
                                        wait_time = 3 * (2 ** retry_attempt)  # ë´‡ ê°ì§€ ì‹œ ë” ê¸´ ë”œë ˆì´: 3ì´ˆ, 6ì´ˆ, 12ì´ˆ
                                        logger.warning(f"[MCP][_execute_search_tool] Bot detection detected from {server_name} (attempt {retry_attempt + 1}/{max_retries}), retrying after {wait_time}s")
                                        await asyncio.sleep(wait_time)
                                        result = None  # ì¬ì‹œë„ë¥¼ ìœ„í•´ Noneìœ¼ë¡œ ì„¤ì •
                                        continue
                                    else:
                                        logger.error(f"[MCP][_execute_search_tool] Bot detection persisted after {max_retries} attempts, skipping {server_name}")
                                        result = None  # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
                                        break
                            
                            # ìœ íš¨í•œ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„ ë£¨í”„ ì¢…ë£Œ
                            if result:
                                break
                                
                        except Exception as e:
                            logger.warning(f"[MCP][_execute_search_tool] Attempt {retry_attempt + 1}/{max_retries} failed for {server_name}: {e}")
                            if retry_attempt < max_retries - 1:
                                # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ, 8ì´ˆ
                                wait_time = 2 * (2 ** retry_attempt)
                                logger.debug(f"[MCP][_execute_search_tool] Retrying {server_name} after {wait_time}s delay")
                                await asyncio.sleep(wait_time)
                            else:
                                logger.error(f"[MCP][_execute_search_tool] All {max_retries} attempts failed for {server_name}")
                                result = None
                    
                    if not result:
                        logger.warning(f"[MCP][_execute_search_tool] âŒ MCP server {server_name} tool {search_tool_name} returned no result after {max_retries} attempts")
                        failed_servers.append({"server": server_name, "reason": "no_result_returned", "tool": search_tool_name})
                        continue
                    
                    # ê²°ê³¼ íŒŒì‹± - ì‹¤ì œ ì™¸ë¶€ ì„œë²„ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬ ë° ì—ëŸ¬ ì²´í¬
                    import json
                    import re
                    
                    # ì—ëŸ¬ ì‘ë‹µ ì²´í¬ (failed, 401, 404, 502 ë“±)
                    result_lower = str(result).lower() if result else ""
                    error_patterns = [
                        r'\b(failed|error|invalid_token|authentication failed)\b',
                        r'\b(401|404|500|502|503|504)\b',
                        r'bad gateway',
                        r'not found',
                        r'unauthorized',
                        r'<!doctype html>',  # HTML ì—ëŸ¬ í˜ì´ì§€
                        r'<html',
                        r'<title>.*error.*</title>'
                    ]
                    
                    is_error = False
                    error_msg = None
                    for pattern in error_patterns:
                        if re.search(pattern, result_lower):
                            is_error = True
                            if not error_msg:
                                # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ ì‹œë„
                                if '401' in result_lower or 'invalid_token' in result_lower:
                                    error_msg = "Authentication failed (401)"
                                elif '404' in result_lower:
                                    error_msg = "Not found (404)"
                                elif '502' in result_lower or 'bad gateway' in result_lower:
                                    error_msg = "Bad gateway (502) - Server temporarily unavailable"
                                elif '500' in result_lower:
                                    error_msg = "Internal server error (500)"
                                else:
                                    error_msg = "Server error detected in response"
                            break
                    
                    if is_error:
                        logger.error(f"[MCP][_execute_search_tool] âŒ MCP server {server_name} returned error response: {error_msg}")
                        failed_servers.append({"server": server_name, "reason": f"error_response: {error_msg}"})
                        continue  # ë‹¤ìŒ ì„œë²„ ì‹œë„
                    
                    # resultê°€ dictì´ê³  'result' í‚¤ê°€ ë¬¸ìì—´ì¸ ê²½ìš° (tavily-mcp ë“±)
                    if isinstance(result, dict) and "result" in result and isinstance(result.get("result"), str):
                        result_str = result.get("result", "")
                        logger.debug(f"[MCP][_execute_search_tool] Server {server_name} returned string result (length: {len(result_str)})")
                        # ë¬¸ìì—´ ê²°ê³¼ë¥¼ dictë¡œ ë³€í™˜
                        result = result_str
                    
                    if isinstance(result, str):
                        # í…ìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì‹± ì‹œë„
                        # 1. JSON í˜•ì‹ ì‹œë„
                        try:
                            result_data = json.loads(result)
                        except:
                            # 2. TAVILY í˜•ì‹ íŒŒì‹± ì‹œë„ ("Title: ... URL: ... Content: ...")
                            if "Title:" in result and "URL:" in result:
                                results = []
                                lines = result.strip().split('\n')
                                current_result = {}
                                
                                for line in lines:
                                    line = line.strip()
                                    if not line:
                                        # ë¹ˆ ì¤„ì´ë©´ í˜„ì¬ ê²°ê³¼ ì €ì¥í•˜ê³  ìƒˆë¡œ ì‹œì‘
                                        if current_result and current_result.get("title"):
                                            results.append(current_result)
                                            current_result = {}
                                        continue
                                    
                                    # TAVILY í˜•ì‹: "Title: ...", "URL: ...", "Content: ..."
                                    if line.startswith("Title:"):
                                        if current_result and current_result.get("title"):
                                            results.append(current_result)
                                        current_result = {"title": line[6:].strip(), "url": "", "snippet": ""}
                                    elif line.startswith("URL:"):
                                        if current_result:
                                            current_result["url"] = line[4:].strip()
                                    elif line.startswith("Content:"):
                                        if current_result:
                                            current_result["snippet"] = line[8:].strip()
                                    elif current_result:
                                        # Content ë‹¤ìŒ ì¤„ë“¤
                                        if current_result.get("snippet"):
                                            current_result["snippet"] += " " + line
                                        else:
                                            current_result["snippet"] = line
                                
                                # ë§ˆì§€ë§‰ ê²°ê³¼ ì¶”ê°€
                                if current_result and current_result.get("title"):
                                    results.append(current_result)
                                
                                if results:
                                    logger.debug(f"[MCP][_execute_search_tool] Parsed {len(results)} results from TAVILY format")
                                    result_data = {"results": results}
                                else:
                                    # TAVILY íŒŒì‹± ì‹¤íŒ¨, ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‹œë„
                                    results = []
                                    current_result = None
                                    
                                    for line in lines:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        
                                        # ë§ˆí¬ë‹¤ìš´ ë§í¬ íŒ¨í„´: [Title](url)
                                        link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', line)
                                        if link_match:
                                            if current_result:
                                                results.append(current_result)
                                            title = link_match.group(1)
                                            url = link_match.group(2)
                                            current_result = {
                                                "title": title,
                                                "url": url,
                                                "snippet": ""
                                            }
                                        elif current_result and line:
                                            if current_result["snippet"]:
                                                current_result["snippet"] += " " + line
                                            else:
                                                current_result["snippet"] = line
                                    
                                    if current_result:
                                        results.append(current_result)
                                    
                                    if results:
                                        result_data = {"results": results}
                                    else:
                                        logger.debug(f"[MCP][_execute_search_tool] Could not parse result format, using raw text: {result[:100]}")
                                        result_data = {"results": [{"title": "Search Results", "snippet": result[:500], "url": ""}]}
                            else:
                                # 3. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ í…ìŠ¤íŠ¸ íŒŒì‹± (ddg_search ë“±ì´ ë°˜í™˜í•˜ëŠ” í˜•ì‹)
                                # ì˜ˆ: "1. [Title](url)\n   Description..."
                                results = []
                                lines = result.strip().split('\n')
                            current_result = None
                            
                            for line in lines:
                                line = line.strip()
                                if not line:
                                    continue
                                
                                # ë§ˆí¬ë‹¤ìš´ ë§í¬ íŒ¨í„´: [Title](url)
                                link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', line)
                                if link_match:
                                    # ì´ì „ ê²°ê³¼ ì €ì¥
                                    if current_result:
                                        results.append(current_result)
                                    
                                    title = link_match.group(1)
                                    url = link_match.group(2)
                                    current_result = {
                                        "title": title,
                                        "url": url,
                                        "snippet": ""
                                    }
                                elif current_result and line:
                                    # ì„¤ëª… í…ìŠ¤íŠ¸
                                    if current_result["snippet"]:
                                        current_result["snippet"] += " " + line
                                    else:
                                        current_result["snippet"] = line
                            
                            # ë§ˆì§€ë§‰ ê²°ê³¼ ì¶”ê°€
                            if current_result:
                                results.append(current_result)
                            
                            if results:
                                result_data = {"results": results}
                            else:
                                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ snippetìœ¼ë¡œ ì‚¬ìš©
                                    logger.debug(f"[MCP][_execute_search_tool] Could not parse markdown format, using raw text: {result[:100]}")
                                    result_data = {"results": [{"title": "Search Results", "snippet": result[:500], "url": ""}]}
                    else:
                        result_data = result
                    
                    # ê²°ê³¼ í˜•ì‹ ì •ê·œí™”
                    results = result_data.get("results", [])
                    if not results and isinstance(result_data, dict):
                        # ë‹¤ë¥¸ í˜•ì‹ ì‹œë„
                        results = result_data.get("items", result_data.get("data", []))
                    
                    if results:
                        # ê²°ê³¼ ë‚´ìš© ê²€ì¦: ë´‡ ê°ì§€ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ê°€ í¬í•¨ëœ ê²°ê³¼ í•„í„°ë§
                        valid_results = []
                        invalid_indicators = [
                            "no results were found", "bot detection",
                            "no results", "not found", "try again",
                            "unable to", "error occurred", "no matches"
                        ]
                        
                        for result_item in (results if isinstance(results, list) else [results]):
                            if isinstance(result_item, dict):
                                snippet = result_item.get("snippet", result_item.get("content", result_item.get("description", "")))
                                title = result_item.get("title", result_item.get("name", ""))
                                
                                snippet_lower = str(snippet).lower() if snippet else ""
                                title_lower = str(title).lower() if title else ""
                                
                                # ì—ëŸ¬ ë©”ì‹œì§€ê°€ í¬í•¨ëœ ê²°ê³¼ í•„í„°ë§
                                is_invalid = False
                                matched_indicators = []
                                
                                for indicator in invalid_indicators:
                                    if indicator in snippet_lower:
                                        is_invalid = True
                                        matched_indicators.append(indicator)
                                    elif indicator in title_lower:
                                        is_invalid = True
                                        matched_indicators.append(indicator)
                                
                                # "Search Results" ì œëª© + ë¹ˆ ë‚´ìš© ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€ì¸ ê²½ìš°
                                if "search results" in title_lower and (not snippet or is_invalid):
                                    is_invalid = True
                                
                                if is_invalid:
                                    logger.warning(f"[MCP][_execute_search_tool] Filtering invalid result from {server_name}: matched indicators: {', '.join(matched_indicators)}")
                                    continue
                                
                                valid_results.append(result_item)
                            elif isinstance(result_item, str):
                                # ë¬¸ìì—´ ê²°ê³¼ë„ ê²€ì¦
                                result_lower = result_item.lower()
                                is_invalid = any(indicator in result_lower for indicator in invalid_indicators)
                                
                                if is_invalid:
                                    logger.warning(f"[MCP][_execute_search_tool] Filtering invalid string result from {server_name}: contains error message")
                                    continue
                                
                                # ë¬¸ìì—´ ê²°ê³¼ë¥¼ dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                                valid_results.append({
                                    "title": "Search Result",
                                    "snippet": result_item,
                                    "url": ""
                                })
                        
                        # ìœ íš¨í•œ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
                        if not valid_results:
                            original_count = len(results) if isinstance(results, list) else 1
                            logger.warning(f"[MCP][_execute_search_tool] âŒ All {original_count} results from {server_name} were filtered out (bot detection or error messages), trying next server...")
                            failed_servers.append({"server": server_name, "reason": f"all_results_filtered ({original_count} results filtered)"})
                            continue  # ë‹¤ìŒ ì„œë²„ ì‹œë„
                        
                        original_count = len(results) if isinstance(results, list) else 1
                        filtered_count = original_count - len(valid_results)
                        logger.info(f"âœ… Search successful via MCP server {server_name}: {len(valid_results)} valid results (filtered {filtered_count} invalid results)")
                        tool_result = ToolResult(
                            success=True,
                            data={
                                "query": query,
                                "results": valid_results,
                                "total_results": len(valid_results),
                                "source": f"{server_name}-mcp"
                            },
                            execution_time=time.time() - start_time,
                            confidence=0.9
                        )
                        
                        # ìºì‹œì— ì €ì¥ (TTL: 1ì‹œê°„)
                        cache_dict = {
                            "success": tool_result.success,
                            "data": tool_result.data,
                            "error": tool_result.error,
                            "execution_time": tool_result.execution_time,
                            "confidence": tool_result.confidence
                        }
                        await result_cache.set(
                            tool_name=tool_name,
                            parameters=parameters,
                            value=cache_dict,
                            ttl=3600  # 1 hour for search results
                        )
                        logger.debug(f"[MCP][_execute_search_tool] Cached result for {tool_name}")
                        
                        return tool_result
                    else:
                        logger.warning(f"[MCP][_execute_search_tool] âŒ MCP server {server_name} returned empty results")
                        failed_servers.append({"server": server_name, "reason": "empty_results"})
                        continue
                    
                except Exception as mcp_error:
                    error_str = str(mcp_error)
                    # ToolResult ê´€ë ¨ ì˜¤ë¥˜ëŠ” ëª…í™•íˆ ì²˜ë¦¬
                    if "ToolResult" in error_str or "cannot access local variable" in error_str:
                        logger.error(f"[MCP][_execute_search_tool] âŒ MCP ì„œë²„ {server_name} ê²€ìƒ‰ ì‹¤íŒ¨ (ì½”ë“œ ì˜¤ë¥˜): {mcp_error}")
                        failed_servers.append({"server": server_name, "reason": f"code_error: {str(mcp_error)[:100]}"})
                        # ë‹¤ìŒ ì„œë²„ë¡œ ê³„ì† ì§„í–‰
                        continue
                    else:
                        logger.warning(f"[MCP][_execute_search_tool] âŒ MCP ì„œë²„ {server_name} ê²€ìƒ‰ ì‹¤íŒ¨: {mcp_error}, ë‹¤ìŒ ì„œë²„ ì‹œë„")
                        failed_servers.append({"server": server_name, "reason": f"exception: {str(mcp_error)[:100]}"})
                        import traceback
                        logger.debug(f"Traceback: {traceback.format_exc()}")
                        continue
            
            # ëª¨ë“  MCP ì„œë²„ ì‹¤íŒ¨ ì‹œ duckduckgo_search ë¼ì´ë¸ŒëŸ¬ë¦¬ fallback ì‚¬ìš©
            logger.warning(f"[MCP][_execute_search_tool] âš ï¸ All {len(server_order)} MCP search servers failed for query: '{query}'")
            logger.info(f"[MCP][_execute_search_tool] ğŸ“‹ Failed servers summary:")
            for i, failed in enumerate(failed_servers, 1):
                logger.info(f"[MCP][_execute_search_tool]   {i}. {failed['server']}: {failed['reason']}")
            
            # ëª¨ë“  MCP ì„œë²„ ì‹¤íŒ¨ ì‹œ DDG searchë¡œ fallback
            logger.warning(f"[MCP][_execute_search_tool] ğŸ”„ Falling back to DDG search...")
            return await _fallback_to_ddg_search(query, max_results)
        
        elif tool_name == "tavily":
            # MCP ì„œë²„ë¥¼ í†µí•´ tavily ì‚¬ìš© (mcp_config.jsonì— ì •ì˜ëœ ì„œë²„)
            mcp_hub = get_mcp_hub()
            
            # ëª¨ë“  ì—°ê²°ëœ MCP ì„œë²„ì—ì„œ tavily ë„êµ¬ ì°¾ì•„ì„œ ì‹œë„
            for server_name in mcp_hub.mcp_sessions.keys():
                if server_name not in mcp_hub.mcp_tools_map:
                    continue
                
                try:
                    tools = mcp_hub.mcp_tools_map[server_name]
                    tavily_tool_name = None
                    
                    # tavily ë„êµ¬ ì°¾ê¸°
                    for tool_name_key in tools.keys():
                        tool_lower = tool_name_key.lower()
                        if "tavily" in tool_lower:
                            tavily_tool_name = tool_name_key
                            break
                    
                    if tavily_tool_name:
                        logger.info(f"Using MCP server {server_name} with tool {tavily_tool_name}")
                        result = await mcp_hub._execute_via_mcp_server(
                            server_name,
                            tavily_tool_name,
                            {"query": query, "max_results": max_results}
                        )
                        
                        if result:
                            import json
                            import re
                            
                            # ì—ëŸ¬ ì‘ë‹µ ì²´í¬
                            result_lower = str(result).lower() if result else ""
                            error_patterns = [
                                r'\b(failed|error|invalid_token|authentication failed)\b',
                                r'\b(401|404|500|502|503|504)\b',
                                r'bad gateway',
                                r'not found',
                                r'unauthorized',
                                r'<!doctype html>',
                                r'<html',
                                r'<title>.*error.*</title>'
                            ]
                            
                            is_error = False
                            for pattern in error_patterns:
                                if re.search(pattern, result_lower):
                                    is_error = True
                                    logger.warning(f"Error detected in tavily response, skipping")
                                    break
                            
                            if is_error:
                                continue  # ë‹¤ìŒ ì„œë²„ ì‹œë„
                            
                            if isinstance(result, str):
                                try:
                                    result_data = json.loads(result)
                                except:
                                    # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ íŒŒì‹±
                                    results = []
                                    lines = result.strip().split('\n')
                                    current_result = None
                                    
                                    for line in lines:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        
                                        link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', line)
                                        if link_match:
                                            if current_result:
                                                results.append(current_result)
                                            title = link_match.group(1)
                                            url = link_match.group(2)
                                            current_result = {"title": title, "url": url, "snippet": ""}
                                        elif current_result and line:
                                            if current_result["snippet"]:
                                                current_result["snippet"] += " " + line
                                            else:
                                                current_result["snippet"] = line
                                    
                                    if current_result:
                                        results.append(current_result)
                                    
                                    if results:
                                        result_data = {"results": results}
                                    else:
                                        result_data = {"results": [{"title": "Search Results", "snippet": result, "url": ""}]}
                            else:
                                result_data = result
                            
                            results = result_data.get("results", [])
                            if not results and isinstance(result_data, dict):
                                results = result_data.get("items", result_data.get("data", []))
                            
                            if results:
                                tool_result = ToolResult(
                                    success=True,
                                    data={
                                        "query": query,
                                        "results": results if isinstance(results, list) else [results],
                                        "total_results": len(results) if isinstance(results, list) else 1,
                                        "source": f"{server_name}-mcp"
                                    },
                                    execution_time=time.time() - start_time,
                                    confidence=0.85
                                )
                                
                                # ìºì‹œì— ì €ì¥ (TTL: 1ì‹œê°„)
                                cache_dict = {
                                    "success": tool_result.success,
                                    "data": tool_result.data,
                                    "error": tool_result.error,
                                    "execution_time": tool_result.execution_time,
                                    "confidence": tool_result.confidence
                                }
                                await result_cache.set(
                                    tool_name=tool_name,
                                    parameters=parameters,
                                    value=cache_dict,
                                    ttl=3600  # 1 hour for search results
                                )
                                logger.debug(f"[MCP][_execute_search_tool] Cached result for {tool_name}")
                                
                                return tool_result
                    
                except Exception as mcp_error:
                    logger.warning(f"MCP ì„œë²„ {server_name} tavily ì‹¤íŒ¨: {mcp_error}, ë‹¤ìŒ ì„œë²„ ì‹œë„")
                    continue
            
            # MCP ì„œë²„ì— tavilyê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ (fallback ì œê±°)
            raise ValueError("Tavily MCP server not found. Add tavily server to mcp_config.json")
        
        elif tool_name == "exa":
            # MCP ì„œë²„ë¥¼ í†µí•´ exa ì‚¬ìš© (mcp_config.jsonì— ì •ì˜ëœ ì„œë²„)
            mcp_hub = get_mcp_hub()
            
            # ëª¨ë“  ì—°ê²°ëœ MCP ì„œë²„ì—ì„œ exa ë„êµ¬ ì°¾ì•„ì„œ ì‹œë„
            for server_name in mcp_hub.mcp_sessions.keys():
                if server_name not in mcp_hub.mcp_tools_map:
                    continue
                
                try:
                    tools = mcp_hub.mcp_tools_map[server_name]
                    exa_tool_name = None
                    
                    # exa ë„êµ¬ ì°¾ê¸°
                    for tool_name_key in tools.keys():
                        tool_lower = tool_name_key.lower()
                        if "exa" in tool_lower:
                            exa_tool_name = tool_name_key
                            break
                    
                    if exa_tool_name:
                        logger.info(f"Using MCP server {server_name} with tool {exa_tool_name}")
                        result = await mcp_hub._execute_via_mcp_server(
                            server_name,
                            exa_tool_name,
                            {"query": query, "numResults": max_results}
                        )
                        
                        if result:
                            import json
                            import re
                            
                            # ì—ëŸ¬ ì‘ë‹µ ì²´í¬
                            result_lower = str(result).lower() if result else ""
                            error_patterns = [
                                r'\b(failed|error|invalid_token|authentication failed)\b',
                                r'\b(401|404|500|502|503|504)\b',
                                r'bad gateway',
                                r'not found',
                                r'unauthorized',
                                r'<!doctype html>',
                                r'<html',
                                r'<title>.*error.*</title>'
                            ]
                            
                            is_error = False
                            for pattern in error_patterns:
                                if re.search(pattern, result_lower):
                                    is_error = True
                                    logger.warning(f"Error detected in tavily response, skipping")
                                    break
                            
                            if is_error:
                                continue  # ë‹¤ìŒ ì„œë²„ ì‹œë„
                            
                            if isinstance(result, str):
                                try:
                                    result_data = json.loads(result)
                                except:
                                    # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ íŒŒì‹±
                                    results = []
                                    lines = result.strip().split('\n')
                                    current_result = None
                                    
                                    for line in lines:
                                        line = line.strip()
                                        if not line:
                                            continue
                                        
                                        link_match = re.match(r'^\d+\.\s*\[([^\]]+)\]\(([^\)]+)\)', line)
                                        if link_match:
                                            if current_result:
                                                results.append(current_result)
                                            title = link_match.group(1)
                                            url = link_match.group(2)
                                            current_result = {"title": title, "url": url, "snippet": ""}
                                        elif current_result and line:
                                            if current_result["snippet"]:
                                                current_result["snippet"] += " " + line
                                            else:
                                                current_result["snippet"] = line
                                    
                                    if current_result:
                                        results.append(current_result)
                                    
                                    if results:
                                        result_data = {"results": results}
                                    else:
                                        result_data = {"results": [{"title": "Search Results", "snippet": result, "url": ""}]}
                            else:
                                result_data = result
                            
                            results = result_data.get("results", [])
                            if not results and isinstance(result_data, dict):
                                results = result_data.get("items", result_data.get("data", []))
                            
                            if results:
                                tool_result = ToolResult(
                                    success=True,
                                    data={
                                        "query": query,
                                        "results": results if isinstance(results, list) else [results],
                                        "total_results": len(results) if isinstance(results, list) else 1,
                                        "source": f"{server_name}-mcp"
                                    },
                                    execution_time=time.time() - start_time,
                                    confidence=0.85
                                )
                                
                                # ìºì‹œì— ì €ì¥ (TTL: 1ì‹œê°„)
                                cache_dict = {
                                    "success": tool_result.success,
                                    "data": tool_result.data,
                                    "error": tool_result.error,
                                    "execution_time": tool_result.execution_time,
                                    "confidence": tool_result.confidence
                                }
                                await result_cache.set(
                                    tool_name=tool_name,
                                    parameters=parameters,
                                    value=cache_dict,
                                    ttl=3600  # 1 hour for search results
                                )
                                logger.debug(f"[MCP][_execute_search_tool] Cached result for {tool_name}")
                                
                                return tool_result
                    
                except Exception as mcp_error:
                    logger.warning(f"MCP ì„œë²„ {server_name} exa ì‹¤íŒ¨: {mcp_error}, ë‹¤ìŒ ì„œë²„ ì‹œë„")
                    continue
            
            # MCP ì„œë²„ì— exaê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ (fallback ì œê±°)
            raise ValueError("Exa MCP server not found. Add exa server to mcp_config.json")
        
        else:
            raise ValueError(f"Unknown search tool: {tool_name}")
            
    except Exception as e:
        logger.error(f"Search tool execution failed: {tool_name} - {e}")
        return ToolResult(
            success=False,
            data=None,
            error=f"Search tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_academic_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """í•™ìˆ  ë„êµ¬ ì‹¤í–‰ - src/utilsì—ì„œ ì§ì ‘ ì‚¬ìš©."""
    import time
    
    start_time = time.time()
    query = parameters.get("query", "")
    max_results = parameters.get("max_results", 10) or parameters.get("num_results", 10)
    
    # src/utilsì—ì„œ ì§ì ‘ ì‚¬ìš© (MCP ì„œë²„ë¡œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)
    if tool_name == "arxiv":
        try:
            from src.utils.academic_utils import search_arxiv
            
            if not query:
                return ToolResult(
                    success=False,
                    data=None,
                    error="query parameter is required",
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
            
            # src/utilsì˜ search_arxiv ì§ì ‘ í˜¸ì¶œ
            result = await search_arxiv(query, max_results)
            
            if result.get("success"):
                return ToolResult(
                    success=True,
                    data={
                        "query": query,
                        "results": result.get("results", []),
                        "total_results": result.get("total_results", 0),
                        "count": result.get("count", 0),
                        "source": "embedded_arxiv"
                    },
                    execution_time=time.time() - start_time,
                    confidence=0.95
                )
            else:
                return ToolResult(
                    success=False,
                    data=None,
                    error=result.get("error", "arXiv search failed"),
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
        except ImportError:
            logger.debug("src.utils.academic_utils not available, using existing logic")
        except Exception as e:
            logger.warning(f"Embedded arXiv search failed: {e}, falling back to existing logic")
    
    # ê¸°ì¡´ ë¡œì§ (src/utils ì‹¤íŒ¨ ì‹œ ë˜ëŠ” ë‹¤ë¥¸ tool_name)
    try:
        if tool_name == "arxiv":
            # arXiv API (100% ë¬´ë£Œ)
            import arxiv
            
            client = arxiv.Client()
            search = arxiv.Search(
                query=query,
                max_results=max_results,
                sort_by=arxiv.SortCriterion.Relevance
            )
            
            results = []
            for paper in client.results(search):
                results.append({
                    "title": paper.title,
                    "authors": [author.name for author in paper.authors],
                    "abstract": paper.summary,
                    "url": paper.entry_id,
                    "published": paper.published.isoformat(),
                    "pdf_url": paper.pdf_url
                })
            
            return ToolResult(
                success=True,
                data={
                    "query": query,
                    "results": results,
                    "total_results": len(results),
                    "source": "arxiv"
                },
                execution_time=time.time() - start_time,
                confidence=0.95
            )
        
        elif tool_name == "scholar":
            # Google Scholar (ë¬´ë£Œ, rate limit ìˆìŒ)
            from scholarly import scholarly
            
            search_query = scholarly.search_pubs(query)
            results = []
            
            for i, pub in enumerate(search_query):
                if i >= max_results:
                    break
                    
                results.append({
                    "title": pub.get("bib", {}).get("title", ""),
                    "authors": pub.get("bib", {}).get("author", ""),
                    "abstract": pub.get("bib", {}).get("abstract", ""),
                    "url": pub.get("pub_url", ""),
                    "year": pub.get("bib", {}).get("pub_year", ""),
                    "citations": pub.get("num_citations", 0)
                })
            
            return ToolResult(
                success=True,
                data={
                    "query": query,
                    "results": results,
                    "total_results": len(results),
                    "source": "scholar"
                },
                execution_time=time.time() - start_time,
                confidence=0.8
            )
        
        else:
            raise ValueError(f"Unknown academic tool: {tool_name}")
            
    except Exception as e:
        logger.error(f"Academic tool execution failed: {tool_name} - {e}")
        return ToolResult(
            success=False,
            data=None,
            error=f"Academic tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_data_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """ì‹¤ì œ ë°ì´í„° ë„êµ¬ ì‹¤í–‰."""
    import time
    
    start_time = time.time()
    
    try:
        if tool_name == "fetch":
            # src/utilsì—ì„œ ì§ì ‘ ì‚¬ìš©
            try:
                from src.utils.web_utils import fetch_url
                
                url = parameters.get("url", "")
                max_length = parameters.get("max_length", 50000)
                timeout = parameters.get("timeout", 30)
                
                if not url:
                    raise ValueError("URL parameter is required for fetch tool")
                
                # src/utilsì˜ fetch_url ì§ì ‘ í˜¸ì¶œ
                result = await fetch_url(url, max_length, timeout)
                
                if result.get("success"):
                    return ToolResult(
                        success=True,
                        data={
                            "url": url,
                            "content": result.get("content", ""),
                            "content_type": result.get("content_type", "unknown"),
                            "status_code": result.get("status_code", 200),
                            "character_count": result.get("character_count", 0),
                            "source": "embedded_fetch"
                        },
                        execution_time=time.time() - start_time,
                        confidence=0.9
                    )
                else:
                    return ToolResult(
                        success=False,
                        data=None,
                        error=result.get("error", "Fetch failed"),
                        execution_time=time.time() - start_time,
                        confidence=0.0
                    )
            except ImportError:
                logger.debug("src.utils.web_utils not available, using existing logic")
            except Exception as e:
                logger.warning(f"Embedded fetch failed: {e}, falling back to existing logic")
            
            # ê¸°ì¡´ ë¡œì§ (fallback)
            url = parameters.get("url", "")
            if not url:
                raise ValueError("URL parameter is required for fetch tool")
            
            import httpx
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(url)
                response.raise_for_status()
                
                return ToolResult(
                    success=True,
                    data={
                        "url": url,
                        "status": response.status_code,
                        "content": response.text[:10000],  # ì²˜ìŒ 10000ìë§Œ
                        "content_length": len(response.text),
                        "headers": dict(response.headers)
                    },
                    execution_time=time.time() - start_time,
                    confidence=0.9
                )
        
        elif tool_name == "filesystem":
            # íŒŒì¼ì‹œìŠ¤í…œ ì ‘ê·¼ (ì‹¤ì œ êµ¬í˜„)
            await _execute_file_tool(tool_name, parameters)

        elif tool_name == "browser":
            # ë¸Œë¼ìš°ì € ìë™í™” (ì‹¤ì œ êµ¬í˜„)
            await _execute_browser_tool(tool_name, parameters)

        elif tool_name == "shell":
            # ì‰˜ ëª…ë ¹ ì‹¤í–‰ (ì‹¤ì œ êµ¬í˜„)
            await _execute_shell_tool(tool_name, parameters)
        
        else:
            raise ValueError(f"Unknown data tool: {tool_name}")
            
    except Exception as e:
        logger.error(f"Data tool execution failed: {tool_name} - {e}")
        return ToolResult(
            success=False,
            data=None,
            error=f"Data tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_code_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """ì‹¤ì œ ì½”ë“œ ë„êµ¬ ì‹¤í–‰ - ERA ë˜ëŠ” Docker ìƒŒë“œë°•ìŠ¤ ì„ íƒ."""
    import time

    start_time = time.time()
    code = parameters.get("code", "")
    language = parameters.get("language", "python")
    sandbox_type = parameters.get("sandbox", "era")  # "era" or "docker"
    
    # 1. ë¦¬ì†ŒìŠ¤ ì œí•œ ì²´í¬
    try:
        from src.core.resource_limits import ResourceLimits, CodeSizeLimitError

        code_bytes = code.encode('utf-8')
        if ResourceLimits.exceeds_code_limit(len(code_bytes)):
            error_msg = (
                f"Code size ({ResourceLimits.format_bytes(len(code_bytes))}) exceeds limit "
                f"({ResourceLimits.MAX_CODE_SIZE_HUMAN}). "
                f"Please reduce the code size or split into smaller chunks."
            )
            logger.error(error_msg)
            return ToolResult(
                success=False,
                data=None,
                error=error_msg,
                execution_time=time.time() - start_time,
                confidence=0.0
            )
    except ImportError:
        # ResourceLimits ëª¨ë“ˆì´ ì—†ìœ¼ë©´ ê²½ê³ ë§Œ í•˜ê³  ê³„ì† ì§„í–‰
        logger.debug("ResourceLimits module not available, skipping size check")

    # 2. ìƒŒë“œë°•ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ì‹¤í–‰
    if sandbox_type == "docker":
        # Docker ìƒŒë“œë°•ìŠ¤ ì‚¬ìš©
        try:
            from src.core.sandbox.docker_sandbox import get_sandbox
            sandbox = get_sandbox()

            result = await sandbox.execute_code(code, language)
            execution_time = time.time() - start_time

            return ToolResult(
                success=result.success,
                data={
                    "code": code,
                    "language": language,
                    "output": result.output,
                    "error": result.error,
                    "exit_code": result.exit_code,
                    "sandbox_type": "docker",
                    "container_id": result.container_id
                },
                execution_time=execution_time,
                confidence=0.9 if result.success else 0.5
            )

        except Exception as e:
            logger.error(f"Docker sandbox execution failed: {e}")
            execution_time = time.time() - start_time
            return ToolResult(
                success=False,
                data=None,
                error=f"Docker sandbox failed: {str(e)}",
                execution_time=execution_time,
                confidence=0.0
            )

    # 3. ERA ì„¤ì • í™•ì¸ (ê¸°ë³¸ê°’)
    try:
        from src.core.researcher_config import get_era_config
        from src.core.era_client import ERAClient
        from src.core.era_server_manager import get_era_server_manager
        
        era_config = get_era_config()
        
        # ERAê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì—ëŸ¬ ë°˜í™˜
        if not era_config.enabled:
            error_msg = "ERA is disabled. Code execution requires ERA to be enabled for security."
            logger.error(error_msg)
            return ToolResult(
                success=False,
                data=None,
                error=error_msg,
                execution_time=time.time() - start_time,
                confidence=0.0
            )
        
        # ì‹±ê¸€í†¤ ERA ì„œë²„ ê´€ë¦¬ì ì‚¬ìš©
        server_manager = get_era_server_manager()
        
        # ê°•í™”ëœ ì„œë²„ ì‹œì‘ (ì¬ì‹œë„ í¬í•¨)
        if not await server_manager.ensure_server_running_with_retry():
            error_msg = (
                f"ERA server is not available after {server_manager.max_retries} retries. "
                f"Please ensure ERA Agent is installed and running. "
                f"Binary path: {server_manager.agent_binary_path or 'not found'}"
            )
            logger.error(error_msg)
            return ToolResult(
                success=False,
                data=None,
                error=error_msg,
                execution_time=time.time() - start_time,
                confidence=0.0
            )
        
        # ERA í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        era_client = ERAClient(
            base_url=era_config.server_url,
            api_key=era_config.api_key,
            timeout=float(era_config.default_timeout) + 10.0  # ì—¬ìœ  ì‹œê°„ ì¶”ê°€
        )
        
        try:
            # ì–¸ì–´ë³„ ëª…ë ¹ ìƒì„±
            # Cloudflare Worker ë°©ì‹: ì½”ë“œë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ commandì— í¬í•¨
            # ì´ ë°©ì‹ì´ ê°€ì¥ ì•ˆì „í•˜ê³  í™•ì‹¤í•¨ (ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ ì—†ìŒ)
            import base64
            import uuid
            
            # ì½”ë“œë¥¼ base64ë¡œ ì¸ì½”ë”©
            code_bytes = code.encode('utf-8')
            code_base64 = base64.b64encode(code_bytes).decode('ascii')
            
            # ì–¸ì–´ë³„ ì‹¤í–‰ ëª…ë ¹ ìƒì„±
            unique_id = uuid.uuid4().hex[:8]
            
            if language.lower() in ["python", "py"]:
                # Python: base64 ë””ì½”ë”© í›„ íŒŒì´í”„ë¡œ ì „ë‹¬
                # ê¸´ ì½”ë“œë‚˜ ë©€í‹°ë¼ì¸ ì½”ë“œëŠ” ì„ì‹œ íŒŒì¼ ì‚¬ìš©
                if len(code) > 1000 or code.count('\n') > 10:
                    # ê¸´ ì½”ë“œëŠ” ì„ì‹œ íŒŒì¼ë¡œ ì‹¤í–‰
                    tmp_file = f"/tmp/code_{unique_id}.py"
                    # base64 ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ ì „ë‹¬ (single quote ì‚¬ìš©)
                    command = f'sh -c "echo \'{code_base64}\' | base64 -d > {tmp_file} && python {tmp_file} && rm -f {tmp_file}"'
                else:
                    # ì§§ì€ ì½”ë“œëŠ” íŒŒì´í”„ë¡œ ì‹¤í–‰
                    command = f'sh -c "echo \'{code_base64}\' | base64 -d | python"'
                
                result = await era_client.run_temp(
                    language="python",
                    command=command,
                    cpu=era_config.default_cpu,
                    memory=era_config.default_memory,
                    network=era_config.network_mode,
                    timeout=era_config.default_timeout
                )
            elif language.lower() in ["javascript", "js", "node", "nodejs"]:
                # JavaScript/Node: base64 ë””ì½”ë”© í›„ íŒŒì´í”„ë¡œ ì „ë‹¬
                if len(code) > 1000 or code.count('\n') > 10:
                    # ê¸´ ì½”ë“œëŠ” ì„ì‹œ íŒŒì¼ë¡œ ì‹¤í–‰
                    tmp_file = f"/tmp/code_{unique_id}.js"
                    command = f'sh -c "echo \'{code_base64}\' | base64 -d > {tmp_file} && node {tmp_file} && rm -f {tmp_file}"'
                else:
                    # ì§§ì€ ì½”ë“œëŠ” íŒŒì´í”„ë¡œ ì‹¤í–‰
                    command = f'sh -c "echo \'{code_base64}\' | base64 -d | node"'
                
                result = await era_client.run_temp(
                    language="javascript",
                    command=command,
                    cpu=era_config.default_cpu,
                    memory=era_config.default_memory,
                    network=era_config.network_mode,
                    timeout=era_config.default_timeout
                )
            else:
                error_msg = f"Unsupported language for ERA: {language}"
                logger.error(error_msg)
                return ToolResult(
                    success=False,
                    data=None,
                    error=error_msg,
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
            
            # ERA ì‹¤í–‰ ê²°ê³¼ë¥¼ ToolResultë¡œ ë³€í™˜
            execution_time = time.time() - start_time
            
            return ToolResult(
                success=result.exit_code == 0,
                    data={
                        "code": code,
                        "language": language,
                        "output": result.stdout,
                        "error": result.stderr,
                        "return_code": result.exit_code,
                        "vm_id": result.vm_id,
                        "duration": result.duration,
                        "sandbox_type": "era"
                    },
                execution_time=execution_time,
                confidence=0.9 if result.exit_code == 0 else 0.5
                )
        finally:
            await era_client.close()
            
    except ImportError as e:
        # ERA ëª¨ë“ˆì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°˜í™˜
        error_msg = f"ERA modules not available: {e}. Please install ERA Agent dependencies."
        logger.error(error_msg)
        return ToolResult(
            success=False,
            data=None,
            error=error_msg,
            execution_time=time.time() - start_time,
            confidence=0.0
        )
    except ConnectionError as e:
        # ERA ì—°ê²° ì‹¤íŒ¨ - ì—ëŸ¬ ë°˜í™˜
        error_msg = f"ERA connection failed: {e}. Please ensure ERA server is running."
        logger.error(error_msg)
        return ToolResult(
            success=False,
            data=None,
            error=error_msg,
            execution_time=time.time() - start_time,
            confidence=0.0
        )
    except ValueError as e:
        # ERA ì„¤ì • ì˜¤ë¥˜ - ì—ëŸ¬ ë°˜í™˜
        error_msg = f"ERA configuration error: {e}"
        logger.error(error_msg)
        return ToolResult(
            success=False,
            data=None,
            error=error_msg,
            execution_time=time.time() - start_time,
            confidence=0.0
        )
    except Exception as e:
        # ê¸°íƒ€ ERA ì˜¤ë¥˜ - ì—ëŸ¬ ë°˜í™˜
        error_msg = f"ERA execution error: {e}"
        logger.error(error_msg, exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=error_msg,
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_browser_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """ë¸Œë¼ìš°ì € ìë™í™” ë„êµ¬ ì‹¤í–‰."""
    import time
    start_time = time.time()
    
    try:
        from src.automation.browser_manager import BrowserManager
        
        # BrowserManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹±ê¸€í†¤ íŒ¨í„´ ê³ ë ¤)
        browser_manager = BrowserManager()
        
        # ë¸Œë¼ìš°ì € ì´ˆê¸°í™” (ì•„ì§ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´)
        if not browser_manager.browser_available:
            await browser_manager.initialize_browser()
        
        if tool_name == "browser_navigate":
            # URLë¡œ ì´ë™ ë° ì½˜í…ì¸  ì¶”ì¶œ
            url = parameters.get("url", "")
            extraction_goal = parameters.get("extraction_goal", "extract_all_content")
            
            if not url:
                raise ValueError("URL parameter is required for browser_navigate")
            
            result = await browser_manager.navigate_and_extract(url, extraction_goal)
            
            return ToolResult(
                success=result.get("success", False),
                data=result,
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "browser_extract":
            # íŠ¹ì • ëª©í‘œì— ë§ëŠ” ì½˜í…ì¸  ì¶”ì¶œ
            url = parameters.get("url", "")
            extraction_goal = parameters.get("extraction_goal", "extract_all_content")
            
            if not url:
                raise ValueError("URL parameter is required for browser_extract")
            
            result = await browser_manager.navigate_and_extract(url, extraction_goal)
            
            return ToolResult(
                success=result.get("success", False),
                data=result,
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "browser_screenshot":
            # ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
            url = parameters.get("url", "")
            output_path = parameters.get("output_path", None)
            
            if not url:
                raise ValueError("URL parameter is required for browser_screenshot")
            
            # Playwrightë¥¼ ì‚¬ìš©í•œ ìŠ¤í¬ë¦°ìƒ·
            try:
                from playwright.async_api import async_playwright
                PLAYWRIGHT_AVAILABLE = True
            except ImportError:
                PLAYWRIGHT_AVAILABLE = False
            
            if PLAYWRIGHT_AVAILABLE:
                from playwright.async_api import async_playwright
                
                async with async_playwright() as p:
                    browser = await p.chromium.launch(headless=True)
                    page = await browser.new_page()
                    await page.goto(url, wait_until="networkidle")
                    
                    if output_path:
                        await page.screenshot(path=output_path, full_page=True)
                    else:
                        # ì„ì‹œ íŒŒì¼ì— ì €ì¥
                        import tempfile
                        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
                            output_path = tmp.name
                            await page.screenshot(path=output_path, full_page=True)
                    
                    await browser.close()
                    
                    return ToolResult(
                        success=True,
                        data={"screenshot_path": output_path, "url": url},
                        execution_time=time.time() - start_time,
                        confidence=0.9
                    )
            else:
                raise RuntimeError("Playwright not available for screenshot")
        
        elif tool_name == "browser_interact":
            # ë²„íŠ¼ í´ë¦­, í¼ ì‘ì„± ë“± ìƒí˜¸ì‘ìš©
            url = parameters.get("url", "")
            actions = parameters.get("actions", [])  # List of action dicts
            
            if not url:
                raise ValueError("URL parameter is required for browser_interact")
            
            if not actions:
                raise ValueError("actions parameter is required for browser_interact")
            
            # Playwrightë¥¼ ì‚¬ìš©í•œ ìƒí˜¸ì‘ìš©
            try:
                from playwright.async_api import async_playwright
                PLAYWRIGHT_AVAILABLE = True
            except ImportError:
                PLAYWRIGHT_AVAILABLE = False
            
            if PLAYWRIGHT_AVAILABLE:
                from playwright.async_api import async_playwright
                
                async with async_playwright() as p:
                    browser = await p.chromium.launch(headless=True)
                    page = await browser.new_page()
                    await page.goto(url, wait_until="networkidle")
                    
                    results = []
                    for action in actions:
                        action_type = action.get("type")
                        selector = action.get("selector")
                        value = action.get("value")
                        
                        try:
                            if action_type == "click":
                                await page.click(selector)
                                results.append({"type": "click", "selector": selector, "success": True})
                            elif action_type == "fill":
                                await page.fill(selector, value)
                                results.append({"type": "fill", "selector": selector, "success": True})
                            elif action_type == "select":
                                await page.select_option(selector, value)
                                results.append({"type": "select", "selector": selector, "success": True})
                            elif action_type == "wait":
                                await page.wait_for_selector(selector, timeout=5000)
                                results.append({"type": "wait", "selector": selector, "success": True})
                            else:
                                results.append({"type": action_type, "success": False, "error": "Unknown action type"})
                        except Exception as e:
                            results.append({"type": action_type, "success": False, "error": str(e)})
                    
                    # ìµœì¢… í˜ì´ì§€ ì½˜í…ì¸  ì¶”ì¶œ
                    final_content = await page.content()
                    
                    await browser.close()
                    
                    return ToolResult(
                        success=all(r.get("success", False) for r in results),
                        data={
                            "url": url,
                            "actions": results,
                            "final_content": final_content[:10000]  # ì²˜ìŒ 10000ìë§Œ
                        },
                        execution_time=time.time() - start_time,
                        confidence=0.8 if all(r.get("success", False) for r in results) else 0.5
                    )
            else:
                raise RuntimeError("Playwright not available for browser interaction")
        
        else:
            raise ValueError(f"Unknown browser tool: {tool_name}")
            
    except Exception as e:
        logger.error(f"Browser tool execution failed: {tool_name} - {e}", exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=f"Browser tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_document_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """ë¬¸ì„œ ìƒì„± ë„êµ¬ ì‹¤í–‰."""
    import time
    start_time = time.time()
    
    try:
        from src.generation.report_generator import ReportGenerator
        
        generator = ReportGenerator()
        research_data = parameters.get("research_data", {})
        report_type = parameters.get("report_type", "comprehensive")
        
        if not research_data:
            raise ValueError("research_data parameter is required for document generation")
        
        # ë„êµ¬ ì´ë¦„ì—ì„œ í˜•ì‹ ì¶”ì¶œ
        if tool_name == "generate_pdf":
            output_format = "pdf"
        elif tool_name == "generate_docx":
            output_format = "docx"
        elif tool_name == "generate_pptx":
            output_format = "pptx"
        elif tool_name == "generate_html":
            output_format = "html"
        elif tool_name == "generate_markdown":
            output_format = "markdown"
        else:
            raise ValueError(f"Unknown document tool: {tool_name}")
        
        # ë¬¸ì„œ ìƒì„±
        file_path = await generator.generate_research_report(
            research_data=research_data,
            report_type=report_type,
            output_format=output_format
        )
        
        return ToolResult(
            success=True,
            data={
                "file_path": file_path,
                "format": output_format,
                "report_type": report_type
            },
            execution_time=time.time() - start_time,
            confidence=0.9
        )
        
    except Exception as e:
        logger.error(f"Document tool execution failed: {tool_name} - {e}", exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=f"Document tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_git_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """Git ì›Œí¬í”Œë¡œìš° ë„êµ¬ ì‹¤í–‰."""
    import time
    start_time = time.time()
    
    try:
        from src.core.git_workflow import GitWorkflow
        from pathlib import Path
        
        # ì €ì¥ì†Œ ê²½ë¡œ í™•ì¸
        repo_path = parameters.get("repo_path")
        if repo_path:
            repo_path = Path(repo_path)
        else:
            repo_path = None
        
        # GitWorkflow ìƒì„±
        git_workflow = GitWorkflow(repo_path=repo_path)
        
        if tool_name == "git_status":
            result = await git_workflow.git_status()
            return ToolResult(
                success=True,
                data=result,
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "git_commit":
            message = parameters.get("message")
            auto_stage = parameters.get("auto_stage", True)
            result = await git_workflow.git_commit(message=message, auto_stage=auto_stage)
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "git_push":
            branch = parameters.get("branch")
            force = parameters.get("force", False)
            result = await git_workflow.git_push(branch=branch, force=force)
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "git_create_pr":
            title = parameters.get("title")
            body = parameters.get("body")
            base = parameters.get("base", "main")
            
            if not title:
                return ToolResult(
                    success=False,
                    data=None,
                    error="title parameter is required",
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
            
            result = await git_workflow.git_create_pr(title=title, body=body, base=base)
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "git_commit_push_pr":
            commit_message = parameters.get("commit_message")
            pr_title = parameters.get("pr_title")
            pr_body = parameters.get("pr_body")
            base = parameters.get("base", "main")
            
            result = await git_workflow.git_commit_push_pr(
                commit_message=commit_message,
                pr_title=pr_title,
                pr_body=pr_body,
                base=base
            )
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        else:
            return ToolResult(
                success=False,
                data=None,
                error=f"Unknown git tool: {tool_name}",
                execution_time=time.time() - start_time,
                confidence=0.0
            )
    
    except Exception as e:
        logger.error(f"Git tool execution failed: {tool_name} - {e}", exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=f"Git tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_shell_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """Shell ëª…ë ¹ ì‹¤í–‰ ë„êµ¬ (ì™„ì „ ìë™í˜• SparkleForge)."""
    import time
    start_time = time.time()
    
    try:
        from src.core.shell_executor import ShellExecutor
        from pathlib import Path
        
        # ì‘ì—… ë””ë ‰í† ë¦¬ í™•ì¸
        working_dir = parameters.get("working_dir")
        if working_dir:
            working_dir = Path(working_dir)
        else:
            working_dir = None
        
        # ShellExecutor ìƒì„±
        executor = ShellExecutor(
            require_confirmation=parameters.get("require_confirmation", False),
            max_execution_time=parameters.get("timeout", 300)
        )
        
        if tool_name == "run_shell_command":
            command = parameters.get("command")
            if not command:
                return ToolResult(
                    success=False,
                    data=None,
                    error="command parameter is required",
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
            
            confirm = parameters.get("confirm")
            timeout = parameters.get("timeout")
            result = await executor.run(
                command=command,
                working_dir=working_dir,
                confirm=confirm,
                timeout=timeout
            )
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "run_interactive_command":
            command = parameters.get("command")
            if not command:
                return ToolResult(
                    success=False,
                    data=None,
                    error="command parameter is required",
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
            
            input_data = parameters.get("input")
            result = await executor.run_interactive(
                command=command,
                working_dir=working_dir,
                input_data=input_data
            )
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "run_background_command":
            command = parameters.get("command")
            if not command:
                return ToolResult(
                    success=False,
                    data=None,
                    error="command parameter is required",
                    execution_time=time.time() - start_time,
                    confidence=0.0
                )
            
            result = await executor.run_background(
                command=command,
                working_dir=working_dir
            )
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        else:
            return ToolResult(
                success=False,
                data=None,
                error=f"Unknown shell tool: {tool_name}",
                execution_time=time.time() - start_time,
                confidence=0.0
            )
    
    except Exception as e:
        logger.error(f"Shell tool execution failed: {e}", exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=str(e),
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_git_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """Git ì›Œí¬í”Œë¡œìš° ë„êµ¬ ì‹¤í–‰ (ì™„ì „ ìë™í˜• SparkleForge)."""
    import time
    start_time = time.time()
    
    try:
        from src.core.git_workflow import GitWorkflow
        from pathlib import Path
        
        # ì €ì¥ì†Œ ê²½ë¡œ í™•ì¸
        repo_path = parameters.get("repo_path")
        if repo_path:
            repo_path = Path(repo_path)
        else:
            repo_path = None  # í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        
        git_workflow = GitWorkflow(repo_path=repo_path)
        
        if tool_name == "git_status":
            result = await git_workflow.git_status()
            return ToolResult(
                success=True,
                data=result,
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "git_commit":
            message = parameters.get("message")
            auto_stage = parameters.get("auto_stage", True)
            result = await git_workflow.git_commit(message=message, auto_stage=auto_stage)
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "git_push":
            branch = parameters.get("branch")
            force = parameters.get("force", False)
            result = await git_workflow.git_push(branch=branch, force=force)
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "git_create_pr":
            title = parameters.get("title")
            body = parameters.get("body")
            base = parameters.get("base", "main")
            result = await git_workflow.git_create_pr(title=title, body=body, base=base)
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        elif tool_name == "git_commit_push_pr":
            commit_message = parameters.get("commit_message")
            pr_title = parameters.get("pr_title")
            pr_body = parameters.get("pr_body")
            base = parameters.get("base", "main")
            result = await git_workflow.git_commit_push_pr(
                commit_message=commit_message,
                pr_title=pr_title,
                pr_body=pr_body,
                base=base
            )
            return ToolResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time=time.time() - start_time,
                confidence=0.9 if result.get("success") else 0.0
            )
        
        else:
            return ToolResult(
                success=False,
                data=None,
                error=f"Unknown git tool: {tool_name}",
                execution_time=time.time() - start_time,
                confidence=0.0
            )
    
    except Exception as e:
        logger.error(f"Git tool execution failed: {e}", exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=str(e),
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def _execute_file_tool(tool_name: str, parameters: Dict[str, Any]) -> ToolResult:
    """íŒŒì¼ ì‘ì—… ë„êµ¬ ì‹¤í–‰."""
    import time
    start_time = time.time()
    
    try:
        from pathlib import Path
        import os
        
        # ì•ˆì „ì„± ê²€ì¦: ì‘ì—… ë””ë ‰í† ë¦¬ ì œí•œ
        allowed_dirs = [
            Path.cwd(),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
            Path("./outputs"),  # ì¶œë ¥ ë””ë ‰í† ë¦¬
            Path("./workspace"),  # ì›Œí¬ìŠ¤í˜ì´ìŠ¤
            Path("./temp"),  # ì„ì‹œ ë””ë ‰í† ë¦¬
        ]
        
        def _is_safe_path(file_path: str) -> bool:
            """ê²½ë¡œ ì•ˆì „ì„± ê²€ì¦."""
            try:
                path = Path(file_path).resolve()
                # ìƒëŒ€ ê²½ë¡œë§Œ í—ˆìš©
                if path.is_absolute() and not any(path.is_relative_to(allowed) for allowed in allowed_dirs):
                    # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš° í—ˆìš©ëœ ë””ë ‰í† ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                    for allowed in allowed_dirs:
                        try:
                            path.relative_to(allowed.resolve())
                            return True
                        except ValueError:
                            continue
                    return False
                # ìƒëŒ€ ê²½ë¡œëŠ” í—ˆìš©
                return True
            except Exception:
                return False
        
        if tool_name == "create_file":
            file_path = parameters.get("file_path", "")
            content = parameters.get("content", "")
            
            if not file_path:
                raise ValueError("file_path parameter is required")
            if not _is_safe_path(file_path):
                raise ValueError(f"Unsafe file path: {file_path}")
            
            path = Path(file_path)
            path.parent.mkdir(parents=True, exist_ok=True)
            path.write_text(content, encoding='utf-8')
            
            return ToolResult(
                success=True,
                data={"file_path": str(path), "size": len(content)},
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "read_file":
            file_path = parameters.get("file_path", "")
            
            if not file_path:
                raise ValueError("file_path parameter is required")
            if not _is_safe_path(file_path):
                raise ValueError(f"Unsafe file path: {file_path}")
            
            path = Path(file_path)
            if not path.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            content = path.read_text(encoding='utf-8')
            
            return ToolResult(
                success=True,
                data={"file_path": str(path), "content": content, "size": len(content)},
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "write_file":
            file_path = parameters.get("file_path", "")
            content = parameters.get("content", "")
            
            if not file_path:
                raise ValueError("file_path parameter is required")
            if not _is_safe_path(file_path):
                raise ValueError(f"Unsafe file path: {file_path}")
            
            path = Path(file_path)
            path.parent.mkdir(parents=True, exist_ok=True)
            path.write_text(content, encoding='utf-8')
            
            return ToolResult(
                success=True,
                data={"file_path": str(path), "size": len(content)},
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "edit_file":
            file_path = parameters.get("file_path", "")
            old_string = parameters.get("old_string", "")
            new_string = parameters.get("new_string", "")
            
            if not file_path:
                raise ValueError("file_path parameter is required")
            if not _is_safe_path(file_path):
                raise ValueError(f"Unsafe file path: {file_path}")
            
            path = Path(file_path)
            if not path.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            content = path.read_text(encoding='utf-8')
            if old_string not in content:
                raise ValueError(f"Old string not found in file: {file_path}")
            
            new_content = content.replace(old_string, new_string)
            path.write_text(new_content, encoding='utf-8')
            
            return ToolResult(
                success=True,
                data={"file_path": str(path), "replacements": content.count(old_string)},
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "list_files":
            directory_path = parameters.get("directory_path", ".")
            recursive = parameters.get("recursive", False)
            
            if not _is_safe_path(directory_path):
                raise ValueError(f"Unsafe directory path: {directory_path}")
            
            path = Path(directory_path)
            if not path.exists():
                raise FileNotFoundError(f"Directory not found: {directory_path}")
            if not path.is_dir():
                raise ValueError(f"Path is not a directory: {directory_path}")
            
            files = []
            if recursive:
                for item in path.rglob("*"):
                    files.append({
                        "name": item.name,
                        "path": str(item.relative_to(path)),
                        "is_file": item.is_file(),
                        "size": item.stat().st_size if item.is_file() else 0
                    })
            else:
                for item in path.iterdir():
                    files.append({
                        "name": item.name,
                        "path": item.name,
                        "is_file": item.is_file(),
                        "size": item.stat().st_size if item.is_file() else 0
                    })
            
            return ToolResult(
                success=True,
                data={"directory": str(path), "files": files, "count": len(files)},
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        elif tool_name == "delete_file":
            file_path = parameters.get("file_path", "")
            
            if not file_path:
                raise ValueError("file_path parameter is required")
            if not _is_safe_path(file_path):
                raise ValueError(f"Unsafe file path: {file_path}")
            
            path = Path(file_path)
            if not path.exists():
                raise FileNotFoundError(f"File or directory not found: {file_path}")
            
            if path.is_file():
                path.unlink()
            elif path.is_dir():
                import shutil
                shutil.rmtree(path)
            
            return ToolResult(
                success=True,
                data={"file_path": str(path), "deleted": True},
                execution_time=time.time() - start_time,
                confidence=0.9
            )
        
        else:
            raise ValueError(f"Unknown file tool: {tool_name}")
            
    except Exception as e:
        logger.error(f"File tool execution failed: {tool_name} - {e}", exc_info=True)
        return ToolResult(
            success=False,
            data=None,
            error=f"File tool execution failed: {str(e)}",
            execution_time=time.time() - start_time,
            confidence=0.0
        )


async def get_tool_for_category(category: ToolCategory) -> Optional[str]:
    """ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë„êµ¬ ë°˜í™˜."""
    mcp_hub = get_mcp_hub()
    return mcp_hub.get_tool_for_category(category)


async def health_check() -> Dict[str, Any]:
    """í—¬ìŠ¤ ì²´í¬."""
    mcp_hub = get_mcp_hub()
    return await mcp_hub.health_check()


# CLI ì‹¤í–‰ í•¨ìˆ˜ë“¤
async def run_mcp_hub():
    """MCP Hub ì‹¤í–‰ (CLI)."""
    mcp_hub = get_mcp_hub()
    print("ğŸš€ Starting Universal MCP Hub...")
    try:
        await mcp_hub.initialize_mcp()
        print("âœ… MCP Hub started successfully")
        print(f"Available tools: {len(mcp_hub.tools)}")
        
        # Hub ìœ ì§€
        try:
            while True:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            print("\nâœ… MCP Hub stopped")
    except Exception as e:
        print(f"âŒ MCP Hub failed to start: {e}")
        await mcp_hub.cleanup()
        sys.exit(1)


async def list_tools():
    """ë„êµ¬ ëª©ë¡ ì¶œë ¥ (CLI)."""
    print("ğŸ”§ Available MCP Tools:")
    available_tools = await get_available_tools()
    for tool_name in available_tools:
        print(f"  - {tool_name}")

async def check_mcp_servers():
    """MCP ì„œë²„ ìƒíƒœ í™•ì¸ (CLI)."""
    mcp_hub = get_mcp_hub()
    try:
        # ì´ˆê¸°í™” (ì´ë¯¸ ì´ˆê¸°í™”ë˜ì–´ ìˆìœ¼ë©´ ì¬ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ)
        if not mcp_hub.mcp_sessions:
            logger.info("Initializing MCP Hub to check servers...")
            await mcp_hub.initialize_mcp()
        
        server_status = await mcp_hub.check_mcp_servers()
        
        print("\n" + "=" * 80)
        print("ğŸ“Š MCP ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸")
        print("=" * 80)
        print(f"ì „ì²´ ì„œë²„ ìˆ˜: {server_status['total_servers']}")
        print(f"ì—°ê²°ëœ ì„œë²„: {server_status['connected_servers']}")
        print(f"ì—°ê²°ë¥ : {server_status['summary']['connection_rate']}")
        print(f"ì „ì²´ ì‚¬ìš© ê°€ëŠ¥í•œ Tool ìˆ˜: {server_status['summary']['total_tools_available']}")
        print("\n")
        
        for server_name, info in server_status["servers"].items():
            status_icon = "âœ…" if info["connected"] else "âŒ"
            print(f"{status_icon} ì„œë²„: {server_name}")
            print(f"   íƒ€ì…: {info['type']}")
            
            if info["type"] == "http":
                print(f"   URL: {info.get('url', 'unknown')}")
            else:
                cmd = info.get('command', 'unknown')
                args_preview = ' '.join(info.get('args', [])[:3])
                print(f"   ëª…ë ¹ì–´: {cmd} {args_preview}...")
            
            print(f"   ì—°ê²° ìƒíƒœ: {'ì—°ê²°ë¨' if info['connected'] else 'ì—°ê²° ì•ˆ ë¨'}")
            print(f"   ì œê³µ Tool ìˆ˜: {info['tools_count']}")
            
            if info["tools"]:
                print(f"   Tool ëª©ë¡:")
                for tool in info["tools"][:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                    registered_name = f"{server_name}::{tool}"
                    print(f"     - {registered_name}")
                if len(info["tools"]) > 5:
                    print(f"     ... ë° {len(info['tools']) - 5}ê°œ ë”")
            
            if info.get("error"):
                print(f"   âš ï¸ ì˜¤ë¥˜: {info['error']}")
            print()
        
        print("=" * 80)
        
    except Exception as e:
        print(f"âŒ ì„œë²„ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ì •ë¦¬í•˜ì§€ ì•Šê³  ì„¸ì…˜ ìœ ì§€ (ë‹¤ë¥¸ ì‘ì—…ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
        pass


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Universal MCP Hub - MCP Only")
    parser.add_argument("--start", action="store_true", help="Start MCP Hub")
    parser.add_argument("--list-tools", action="store_true", help="List available tools")
    parser.add_argument("--health", action="store_true", help="Show health status")
    parser.add_argument("--check-servers", action="store_true", help="Check all MCP server connections")
    
    args = parser.parse_args()
    
    if args.start:
        asyncio.run(run_mcp_hub())
    elif args.list_tools:
        asyncio.run(list_tools())
    elif args.check_servers:
        asyncio.run(check_mcp_servers())
    elif args.health:
        async def show_health():
            mcp_hub = get_mcp_hub()
            try:
                await mcp_hub.initialize_mcp()
                health = await health_check()
                print("ğŸ¥ Health Status:")
                for key, value in health.items():
                    print(f"  {key}: {value}")
                await mcp_hub.cleanup()
            except Exception as e:
                print(f"âŒ Health check failed: {e}")
        asyncio.run(show_health())
    else:
        parser.print_help()